[
  {
    "page": 1,
    "text": "1\nPsychologically Grounded Student Agents for\nReliable Classroom Simulation with LLMs\nPARTHA SARATHI PURKAYASTHA (25-960-329)\nPractical Work Proposal\nSupervised by: Professor Mrinmaya Sachan\nCo-supervised by: Dr. Heejin Do\nOctober 1, 2025\nI. INTRODUCTION\nThe integration of Large Language Models (LLMs) in educational simulations offers a transformative method for\nunderstanding classroom dynamics, allowing for the creation of dynamic, interactive agents that can realistically\nmimic the complex behaviors of students and teachers. Recent advancements, such as the PEERS (Peer Enhanced\nEducational Realistic Simulation) [2] and EduAgent frameworks [67], highlight the potential of LLM-powered\nagents to fill these roles within simulated educational environments by deploying autonomous agents that can\nsimulate students learning advanced concepts by asking nuanced questions or a teacher agent experimenting with\ndifferent pedagogical strategies in real-time. These contributions are foundational in creating controlled settings\nwhere educators can explore various teaching strategies to identify potential flaws in their teaching methods, practice\ntimely interventions for specific student concerns, and refine their strategies in a replicable and scalable environment.\nHowever, current LLM-based educational simulations suffer from a significant \u201cfidelity gap\u201d, limiting their\npsychological authenticity in genuinely reflecting the internal cognitive and emotional states that drive human\nbehavior [65]. Educational psychology has long recognized that learners adopt different approaches, often described\nas deep, surface, and strategic styles, each with distinct motivations and behaviors [27], [53], [16]. Further research\nbuilding up on this show that these styles are not rigid categories but points along a spectrum, with learners fluidly\nshifting between them based on context and cognitive-emotional states [27], [63], [53]. Cumulative evidence from\ninterdisciplinary studies across psychology, neuroscience, and education consistently point towards the idea that\nlearning is powerfully shaped by the interaction of three main dimensions identified as affect, attention, and\nmemory [63], [26], [20], [12], [7], where affect drives motivation, attention governs information processing, and\nmemory anchors knowledge construction [29], [8], [3], [63]. Beyond these individual explorations, studies have also\nexamined their crucial interplay as research on the link between affect and attention has shown how emotional\nstates can direct or impair focus [63], [17], [39], while studies on attention and memory have confirmed that\nfocused attention is essential for effective memory encoding [46], [54], [36], [14]. Works also demonstrate how\nthese interactions create compounding effects, particularly for diverse learners, where heightened anxiety (affect)\ncan disrupt attentional control, which in turn compromises working memory, making it exceedingly difficult for\na student to follow multi-step instructions or comprehend complex texts [39]. Furthermore, studies focusing on\nlearning disabilities demonstrate that issues regarding attention or memory are often exacerbated by emotional\ndysregulation, making a unified framework essential to accurately simulate the significant barriers diverse learners\nface. [26], [36], [59], [62], [42], [55], [38]. This evidence of compounding effects due to interplay reinforces a\ncritical conclusion from cognitive and clinical research: Any model aiming to be psychologically authentic must\nintegrate all three components and simulate their dynamic interplay to reflect how they function interdependently\nwithin a natural cognitive system.\nA primary issue in the current implementations is the reliance on uniform, static student representations that\nfail to model the above core cognitive dimensions driving student behavior. [65]. Frameworks like PEERS [2] use\nlimited behavioral parameters that model only on-task actions, ignoring off-task behaviors driven by boredom or\nfrustration while even advanced systems like EduAgent [67] and SimClass [68] struggle to capture the full spectrum\nof individual differences related to these cognitive aspects, as they are yet unable to simulate how a student with\nanxiety might freeze up when called upon (affect), how another with attentional deficits might frequently disengage"
  },
  {
    "page": 2,
    "text": "2\n(attention), or how different learning styles impact knowledge retention (memory) [4], [18], [41]. While cognitive\narchitectures like NEOLAF and the Unified Mind Model [21][22], ACT-R [51], CLARION [60], Sigma [13],\nand MalAlgoPy [58] have hinted at unified systems, there remains a clear gap in models that holistically integrate\nall three components on a dynamic basis for modeling learning [39], [13], [28], [45]. To address this, we propose a\nnovel, layered agent architecture that grounds agent behavior in validated educational psychology by formalizing\nstudent archetypes [4], [18], [41], [53], made feasible by advances in persona-based prompting [31], [37], [1] and\ncognitive digital twins [23], [24]. By implementing specialized cognitive layers for affect, attention and memory,\nthis approach will aim to bridge the fidelity gap where the primary goal will be the development of authentic\npsychological diversity, transforming simulations into powerful training tools to better prepare educators for the\nunpredictable dynamics of a live classroom, ensuring they are equipped to manage diverse student needs effectively.\nII. OBJECTIVES\nThe primary goal of this research is to develop and validate a psychologically-grounded architecture for creating\nrealistic student agents in educational simulations, focusing on three main objectives:\n1) Develop a Novel Cognitive Agent Architecture: Create a layered agent system that integrates empirically-\nderived student archetypes from educational psychology literature with programmatic cognitive processing\nlayers to simulate authentic student behaviors and learning patterns.\n2) Implement Psychologically-Authentic Simulation Components: Design and validate specialized cognitive\nprocessing modules including an Affective module to dynamically modulate emotional states based on estab-\nlished psychological theories of student motivation and anxiety, an Attention module modeling variations in\nexecutive function and attention, such as distractibility and sustained focus [6][56][56], and a Memory and\nDecoding module with memory filtering mechanisms simulating variations in phonological and orthographic\nprocessing, such as character-level decoding fidelity and working memory for text [33][43][19].\n3) Demonstrate Superior Simulation Fidelity: Validate the architecture\u2019s effectiveness through comprehensive\nevaluation including human expert assessment of agent believability, quantitative analysis of behavioral pattern\ndifferentiation between agent archetypes, and comparative analysis with existing student modeling approaches\nin terms of predictive accuracy and educational insight generation.\nIII. PROPOSED IMPLEMENTATION\nOur implementation strategy consists of four integrated phases designed to create a comprehensive psychologically-\ngrounded educational simulation framework:\na) Phase 1: Literature Review and Archetype Formalization: We begin with a systematic review of educational\npsychology literature to identify and formalize 3-5 empirically-validated student archetypes, building upon estab-\nlished frameworks such as the Deep/Surface/Strategic learning approaches [4][18][41][53]. Each archetype will be\ncharacterized through comprehensive behavioral profiles including learning motivations, communication patterns,\ncognitive processing preferences, and response tendencies to different pedagogical interventions. This phase will\nalso incorporate findings from student modeling research using Bayesian Knowledge Tracing [32][64][66] and\ncognitive agent computing models [61] to ensure compatibility with existing educational technologies.\nb) Phase 2: Disposition Layer Implementation: For each identified archetype, we will engineer sophisticated\n\u201cmeta-prompts\u201d that serve as the agent\u2019s psychological constitution. These prompts will define core motivations,\ncommunication styles, and worldviews that establish the baseline parameters for the cognitive modules in the next\nphase. (e.g., \u201cYou are a \u2018Surface Learner.\u2019 Your primary goal is to pass assessments with minimal effort. You prefer\nclear, factual information and avoid deep, open-ended discussions that require extensive cognitive processing...\u201d).\nThe meta-prompting approach will draw from recent advances in persona-based LLM control [31][37][1][67] and\npsychological authenticity research in conversational agents [30][57]."
  },
  {
    "page": 3,
    "text": "3\nc) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules\nthat dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM\nthat is trained to read this Control Panel and generate behavior that matches the specified cognitive state to simulate\ncore cognitive functions and individual differences. The modules function as follows:\n\u2022 Affect Module (Emotional State Modulator): A state-machine implementation tracking dynamic emotional\nstates (confident, confused, anxious, engaged) based on interaction history and performance outcomes. This\nmodule will modify LLM prompt components in real-time to reflect emotional influences on communication\nstyle, response length, and cognitive processing approach. Here we update the emotion field of the Control\nPanel (e.g., \u201cemotion\u201d: \u201cprimary\u201d: \u201canxious\u201d, \u201cconfidence\u201d: 0.3), which the LLM interprets to modulate its\ncommunication style, response length, and cognitive processing approach.\n\u2022 Attention Module (Focus Manager): A dynamic attention modeling system that simulates varying atten-\ntion spans and distractibility patterns. Drawing from cognitive models of attention and executive function\n[6][56][56], this module will implement time-decay functions for attention, threshold-based coherence degra-\ndation, and attention reset mechanisms triggered by direct engagement or environmental changes. Here we\nupdate the focus field of the Control Panel in real-time (e.g., \u201cfocus\u201d: \u201clevel\u201d: 0.4), which instructs the LLM\nto adjust its response coherence and relevance.\n\u2022 Memory and Decoding Module (Memory Filter): A cognitive processing filter that models information\nprocessing variations, particularly those reflecting a spectrum of information processing speeds and accuracies\n[33][43][19]. This system will introduce controlled character-level noise (e.g., b/d reversals, transposition errors)\nwith probability distributions calibrated to diverse reading patterns, affecting information encoding and retrieval\naccuracy. Here we update the memory field of the Control Panel (e.g., \u201cmemory\u201d: \u201cdecoding fidelity\u201d: 0.85),\naffecting information encoding and retrieval accuracy.\nd) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation\nthrough multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis-\ntency, quantitative analysis of behavioral differentiation between agent types, and integration testing within educa-\ntional simulation environments. We will also explore the proposed \u201cCommittee of Agents\u201d alternative architecture as\nan ablation study, implementing student agents as coordinating processes managing multiple trait-specific sub-agents\nto compare monolithic versus composable persona approaches.\nA. Core Cognitive Module Architecture\nThis section details the design of the three core cognitive modules that form the foundation of our psychologically-\ngrounded student agents. Each module is designed to be a programmable \u201dwrapper\u201d that shapes the LLM\u2019s generative\nprocess, with parameters derived from formalized student archetypes.\n1) The Affective Module (Emotional State Modulator):\nTheoretical Grounding: This module is grounded in Pekrun\u2019s Control-Value Theory of Achievement Emotions\n[47] [48], which links emotions to an individual\u2019s perceived control over and valuation of a task. It also incorporates\nAppraisal Theory [52][44], suggesting that emotions arise from our interpretation of events. This framework allows\nus to model how a \u201cDeep Learner\u201d might react to a challenge with curiosity, while a \u201cSurface Learner\u201d might react\nwith anxiety, based on their underlying motivations [15][25].\nOperational Definition: The module will be a state-machine where states are key achievement emotions (e.g.,\nConfident, Anxious, Engaged, Bored). State transitions are governed by:\n\u2022 Control Appraisal: An internal variable representing perceived self-efficacy, which changes based on perfor-\nmance outcomes and feedback.\n\u2022 Value Appraisal: A parameter derived from the agent\u2019s archetype that defines the intrinsic or extrinsic value\nof a task.\n\u2022 Affective Influence: The current emotional state will dynamically modify the LLM\u2019s meta-prompt in real-time.\nAn \u2018Anxious\u2019 state may add instructions for shorter, more hesitant responses, while an \u2018Engaged\u2019 state may\nprompt for more proactive and detailed contributions."
  },
  {
    "page": 4,
    "text": "4\nEvaluation Metrics:\n\u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts.\n\u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and\nproactive questioning.\n\u2022 Human Expert Ratings: Educators will evaluate the authenticity of the agent\u2019s emotional and motivational\ntrajectory.\nTestable Hypotheses:\n\u2022 H1 : An agent whose \u2018Control Appraisal\u2019 is systematically lowered through negative feedback will transition\nto negative emotional states (e.g., frustration, anxiety) and exhibit a corresponding increase in negative-valence\nlanguage.\n\u2022 H2 : Agents equipped with the Affective Module will be perceived by human raters as demonstrating more\nbelievable and differentiated student personalities than agents defined only by a static dispositional prompt.\n2) The Attention Module (Focus Manager):\nTheoretical Grounding: This module is grounded in hierarchical models of attention that differentiate between\nsustained attention (maintaining focus over time) and selective attention (filtering distractions) [10][50]. It also\ndraws from cognitive models of executive function, such as Baddeley\u2019s model of working memory [5], which\nincludes a central executive responsible for attentional control, and Load Theory of Attention [34] which posits that\nthe ability to ignore distractions depends on the perceptual load of the current task. These concepts are quite central\nto understanding various underlying conditions that affect Attention, such as ADHD [9]. Our model operationalizes\nthese concepts to simulate how an agent\u2019s focus can decay, be captured by competing stimuli, or be reset by direct\nengagement.\nOperational Definition: The module will be a state-based system governed by the following parameters:\n\u2022 Attention Span: A numerical value representing the number of conversational turns an agent can maintain\nfocus on a single topic before a potential \u201cattention lapse.\u201d This will be implemented as a timer that resets\nupon re-engagement.\n\u2022 Distractibility Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the agent\u2019s output is semantically relevant to the\nongoing topic.\n\u2022 Frequency of Off-Topic Utterances: A count of instances where the agent\u2019s output deviates from the\nestablished topic.\n\u2022 Human Expert Ratings: Blind evaluators will rate the believability of an agent\u2019s attentional patterns.\nTestable Hypotheses:\n\u2022 H3 : Agents with a lower \u2018Attention Span\u2019 parameter will exhibit a statistically significant higher frequency\nof off-topic utterances compared to agents with higher attention spans.\n\u2022 H4 : Agents with a lower \u2018Distractibility Threshold\u2019 will show greater performance degradation in simulated\nenvironments with high levels of external distractions.\n3) The Memory and Decoding Module (Memory Filter):\nTheoretical Grounding: The module is based on the Dual-Route Cascade Model of Reading [11][35], which\nexplains how individuals decode familiar and unfamiliar words. Deficiencies in phonological (sound-based) and\northographic (visual-based) processing, which are often implicated in dyslexia, will be modeled [40]. Furthermore,\nit incorporates principles from Verbal Efficiency Theory [49], which posits that effortful decoding consumes finite\nworking memory resources needed for comprehension.\nOperational Definition: This module acts as a filter that pre-processes text input to the LLM. It is defined by:"
  },
  {
    "page": 5,
    "text": "5\n\u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into\nthe agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties.\n\u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to hold information. Effortful\ndecoding, as dictated by the noise parameter, will consume space in this buffer, reducing the resources available\nfor higher-level comprehension.\nEvaluation Metrics:\n\u2022 Reading Comprehension Accuracy: Agent performance on simulated comprehension tasks.\n\u2022 Error Analysis: Classification of agent errors into phonological, orthographic, or semantic categories.\n\u2022 Information Recall Fidelity: The accuracy with which an agent can recall facts presented in a passage, testing\nthe integrity of its working memory.\nTestable Hypotheses:\n\u2022 H5 : Agents with a high \u2018Phonological Noise\u2019 parameter will make significantly more phonologically-based\nerrors than agents with a low parameter.\n\u2022 H6 : A reduction in the \u2018Working Memory Buffer\u2019 size will be negatively correlated with an agent\u2019s ability\nto answer questions about long passages of text.\nIV. EXPECTED MILESTONES\nThe project is envisioned as a four-month intensive research program with clearly defined deliverables and\nevaluation checkpoints:\n\u2022 Month 1: Foundation and Architecture\nComplete a systematic review of educational psychology to formalize student archetypes, followed by the\ndesign of the complete Cognitive Twin architecture and development of initial meta-prompts.\nDeliverables: Comprehensive literature analysis, formal archetype specifications, and a complete architectural\ndesign with an initial meta-prompt library.\n\u2022 Month 2: Implementation and Preliminary Validation\nDevelop and implement the three core cognitive processing modules (Affect, Attention, Memory and Decod-\ning). Integrate all system components and conduct preliminary validation studies, including agent behavior\nconsistency testing.\nDeliverables: A functional, integrated system with documented performance characteristics and preliminary\nvalidation results.\n\u2022 Month 3: Comprehensive Evaluation and Alternative Architecture Exploration\nConduct full validation study including human expert evaluation, behavioral differentiation analysis, and\nCommittee of Agents implementation as a comparative study.\nDeliverables: Complete validation results and architectural comparison analysis.\n\u2022 Month 4: Analysis, Documentation, and Dissemination\nAnalyze all collected data, optimize system parameters based on evaluation results, and prepare comprehensive\ndocumentation, including academic paper preparation for submission to relevant conferences (AIED, EDM, or\nsimilar venues).\nDeliverables: Final thesis document and prepared academic publication.\nREFERENCES\n[1] J. M. Arana et al. Persona-based prompting has an effect on theory-of-mind reasoning in LLMs. arXiv preprint, 2024.\n[2] Jose M. Arana, Kyle Adrian M. Carandang, Enrico R. Casin, Charlene Alis, Dominic S. Tan, Erika F. Legara, and Christopher Monterola.\nFoundations of PEERS: Assessing LLM role performance in educational simulations. In Proceedings of the 63rd Annual Meeting of\nthe Association for Computational Linguistics (Volume 4: Student Research Workshop), pages 908\u2013918, 2025.\n[3] I. et al. Arroyo. Teachable agent improves affect regulation. Frontiers in ICT, 2014.\n[4] J. Atherton. Learning and teaching: Deep and surface learning. [Online], 2009.\n[5] Alan D. Baddeley. The episodic buffer: a new component of working memory? Trends in Cognitive Sciences, 4(11):417\u2013423, 2000.\n[6] BetterHelp. How an ADHD simulation can help you focus on a task, 2025. Accessed: 2024-10-03.\n[7] D. Bj\u00a8orklund and K. Stolpe. The dual memory systems model and its implications for technology education. 2010."
  },
  {
    "page": 6,
    "text": "6\n[8] Z. Cai.\nModeling cognitive load and affect to support adaptive learning environments.\nIn Proceedings of the 15th International\nConference on Educational Data Mining (EDM 2022), 2022.\n[9] Francisco X. Castellanos and Rosemary Tannock. Neuroscience of attention-deficit/hyperactivity disorder: the search for endophenotypes.\nNature Reviews Neuroscience, 3:617\u2013628, 2002.\n[10] Marvin M. Chun, Julie D. Golomb, and Nicholas B. Turk-Browne. A taxonomy of external and internal attention. Annual Review of\nPsychology, 62:73\u2013101, 2011.\n[11] Max Coltheart, Kathleen Rastle, Conrad Perry, Robyn Langdon, and Johannes Ziegler. Drc: A dual route cascaded model of visual\nword recognition and reading aloud. Psychological Review, 108(1):204\u2013256, 2001.\n[12] N Cowan. Working memory underpins cognitive development, learning, and education. Educational Psychology Review, 26:197\u2013223,\n2014.\n[13] M. R. Damgaard, R. Pedersen, and T. Bak. Toward an idiomatic framework for cognitive robotics. Patterns (N Y), 3(7):100533, July\n2022.\n[14] G. Deco and ET Rolls. Attention, short-term memory, and action selection: a unifying theory. Progress in Neurobiology, 76:236\u2013256,\n2005.\n[15] Diana H J M Dolmans, Sofie M M Loyens, H\u00b4el`ene Marcq, and David Gijbels. Deep and surface learning in problem-based learning:\na review of the literature. Advances in Health Sciences Education, 21(1):11\u201339, 2015.\n[16] Oprescu F. Donnison, S. and M. Alphonse. Surface or deep approaches to learning? The International Journal of the First Year in\nHigher Education, 2012.\n[17] JB Engelmann and L. Pessoa. Combined effects of attention and motivation on visual processing. Cerebral Cortex, 20:1432\u20131440,\n2009.\n[18] N. Entwistle. Motivation and learning strategies: Effective learning. Educational and Child Psychology, 5(3):5\u201320, 1988.\n[19] R. Hancock et al. Neural noise hypothesis of developmental dyslexia. Developmental Cognitive Neuroscience, 25:43\u201352, 2017.\n[20] M. Hermida. Attention and its importance for education. IBE-UNESCO Science of Learning Portal, 2024.\n[21] P. Hu and X. Ying. NEOLAF, an LLM-powered neural-symbolic cognitive architecture. arXiv preprint, 2023.\n[22] P. Hu and X. Ying. Unified mind model: Reimagining autonomous agents in the LLM era. arXiv preprint, 2025.\n[23] IEEE Computer Society.\nEnhancing cognitive digital twin interaction using an LLM agent.\nIEEE Xplore Digital Library, 2024.\nDocument ID: 10569919.\n[24] IEEE Computer Society. A cognitive digital twin for industry 5.0 based on a large language model agent. IEEE Xplore Digital Library,\n2025. Document ID: 11154278.\n[25] Evangelia Karagiannopoulou and Noel Entwistle.\nAssociations between defense styles, approaches to learning and academic\nachievement. Frontiers in Education, 3:53, 2018.\n[26] AS Keller, I Davidesco, and KD Tanner. How orchestrating attention may relate to classroom learning. CBE Life Sciences Education,\n19(3), 2020.\n[27] ML Khong and JA Tanner. Surface and deep learning: a blended learning approach in preclinical years of medical school. BMC\nMedical Education, 2024.\n[28] I. Kotseruba and J.K. Tsotsos. Cognitive architectures: Where do we go from here? In Proceedings of AGI-2016 Workshop, 2016.\n[29] L.F. et al. Koziol. Consensus paper: The cerebellum\u2019s role in movement and cognition. Cerebellum, 13:50\u2013561, 2014.\n[30] L. O. H. Kroczek et al. The influence of persona and conversational task on social presence in LLM-controlled embodied conversational\nagents. Computers in Human Behavior, 2025.\n[31] L. O. H. Kroczek et al. LLM agents in interaction: Measuring personality consistency and linguistic alignment in interacting populations\nof large language models. arXiv preprint, 2025.\n[32] T. K\u00a8aser, S. Klingler, A. G. Schwing, and M. Gross. Modeling skill topologies with bayesian networks. Technical report, Computer\nGraphics Laboratory, ETH Zurich, 2014.\n[33] O. H. M. Lasnick et al. Sensory temporal sampling in time: an integrated model of dyslexia. Frontiers in Human Neuroscience, 17,\n2024.\n[34] Nilli Lavie. Distracted and confused?: Selective attention under load. Trends in Cognitive Sciences, 9(2):75\u201382, 2005.\n[35] Jonathan Levy, Tenniel Wydell, Mathew Thomas, John Duncan, Julie Wilson, Michael Richardson, and Catherine J. Mummery. Testing\nfor the dual-route cascade reading model in the brain: An fmri effective connectivity account of an efficient reading style. PLoS ONE,\n4(8):e6675, 2009.\n[36] GW Lindsay. Attention in psychology, neuroscience, and machine learning. Frontiers in Computational Neuroscience, 14:29, 2020.\n[37] Y. Liu et al. No for some, yes for others: Persona prompts and other sources of false refusal in language models. Semantic Scholar,\n2025.\n[38] M. Llorens-G\u00b4amez and L. Vicent. The impact of the design of learning spaces on attention and memory. Building and Environment,\n207:108483, 2022.\n[39] JM Lodge and G Kennedy. The role of attention in learning in the digital age. NPJ Science of Learning, 4:9, 2019.\n[40] Steven G. Luke, Hazel I. Blythe, James Kirkby, and Gordon Kambe. Dyslexics exhibit an orthographic, not a phonological, deficit:\nEvidence from lexical decision. Frontiers in Psychology, 14:1200329, 2023.\n[41] F. Marton and R. S\u00a8alj\u00a8o. On qualitative differences in learning: Outcome and process. British Journal of Educational Psychology,\n46(1):4\u201311, 1976.\n[42] S. Mart\u00b4\u0131nez-Briones and L. D. Shriberg. Working memory in children with learning disorders. European Child Adolescent Psychiatry,\n2020.\n[43] M. S. Mihaylova et al. Visual noise effect on reading in three developmental disorders: autism spectrum disorder, attention deficit\nhyperactivity disorder, and dyslexia. Scientific Reports, 12(1):18306, 2022.\n[44] Agnes Moors. Appraisal theories of emotion: State of the art and future development. Emotion Review, 5(2):119\u2013124, 2013.\n[45] JP et al. Morais. A general framework for reinforcement learning in cognitive architectures. Journal of Cognitive Neuroscience, 2025.\n[46] M. et al. Muhmenthaler. How attention and knowledge modulate memory. Frontiers in Cognition, 3:1125700, 2023."
  },
  {
    "page": 7,
    "text": "7\n[47] Reinhard Pekrun. The control-value theory of achievement emotions: Assumptions, corollaries, and implications for educational research\nand practice. Educational Psychology Review, 18(4):315\u2013341, 2006.\n[48] Reinhard Herrmann Pekrun. Control-value theory: From achievement emotion to a general theory of human emotions. Educational\nPsychology Review, 36(3):1\u201336, 2024.\n[49] Charles A. Perfetti. Verbal efficiency in reading ability. Educational Psychology, 21:106\u2013112, 1988.\n[50] Michael I. Posner and Steven E. Petersen. The attention system of the human brain. Annual Review of Neuroscience, 13:25\u201342, 1990.\n[51] et al. Ritter, FE. Act-r: A cognitive architecture for modeling cognition. Wiley Interdisciplinary Reviews: Cognitive Science, 10(3):e1488,\n2019.\n[52] Ira J. Roseman and Craig A. Smith. Appraisal theory overview, assumptions, varieties, controversies. In Klaus R. Scherer, Angela\nSchorr, and Tom Johnstone, editors, Appraisal Processes in Emotion: Theory, Methods, Research, pages 3\u201319. Oxford University Press,\n2001.\n[53] S. M. Rutherford. Correlations between deep, surface or strategic learning approaches and student preferences for group vs individual\nstudy. Technical report, Cardiff University, 2016.\n[54] L. Sahakyan and K. J. Malmberg. Divided attention during encoding causes separate memory representations. Journal of Memory and\nLanguage, 101:73\u201386, 2018.\n[55] S. et al. Sankalaite. The association between working memory, teacher-student relationship, and academic outcomes. Frontiers in\nPsychology, 14:1240741, 2023.\n[56] G. Sarai et al.\nExploring virtual reality and exercise simulator interventions for individuals with ADHD.\nJMIR Serious Games,\n13:e57297, 2025.\n[57] T. Sch\u00a8urmann et al. Personalizing human-agent interaction through cognitive modeling. Frontiers in Psychology, 11:569569, 2020.\n[58] Shashank Sonkar, Xinghe Chen, Naiming Liu, Richard G. Baraniuk, and Mrinmaya Sachan. Llm-based cognitive models of students\nwith misconceptions, 2024.\n[59] J.P. et al. Spencer. Integrating attention, working memory, and word learning in the classroom: Implications from a neural systems\napproach. Current Opinion in Behavioral Sciences, 2025.\n[60] R. Sun, E. Merrill, and T. Peterson. From implicit skills to explicit knowledge: A bottom-up model of skill learning. Cognitive Science,\n25(2):203\u2013244, 2001.\n[61] M. Tausif. A cognitive agent computing-based model for the primary school student migration problem using a descriptive agent-based\napproach. arXiv preprint, 2023.\n[62] S. Turker and K. et al. Poon. Cognitive and behavioural weaknesses in children with reading difficulties and/or adhd: A multicentre\nstudy. Scientific Reports, 9(1):14620, 2019.\n[63] CM Tyng, HU Amin, MNM Saad, and AS Malik. The influences of emotion on learning and memory. Front. Psychol., 8:1454, 2017.\n[64] B. van de Sande. Properties of the bayesian knowledge tracing model. Technical report, Arizona State University, 2013.\n[65] Qian Wang, Jiaying Wu, Zhenheng Tang, Bingqiao Luo, Nuo Chen, Wei Chen, and Bingsheng He. What limits llm-based human\nsimulation: Llms or our design?, 2025.\n[66] Wikipedia Contributors. Bayesian knowledge tracing. Wikipedia, 2015. Accessed: 2024-10-03.\n[67] S. Xu, X. Zhang, and L. Qin. EduAgent: Generative student agents in learning. arXiv preprint, 2024.\n[68] Zheyuan Zhang, Daniel Zhang-Li, Jifan Yu, Linlu Gong, Jinchang Zhou, Zhanxin Hao, Jianxiao Jiang, Jie Cao, Huiqin Liu, Zhiyuan\nLiu, Lei Hou, and Juanzi Li.\nSimulating classroom education with LLM-empowered agents.\nIn Luis Chiruzzo, Alan Ritter, and\nLu Wang, editors, Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational\nLinguistics: Human Language Technologies (Volume 1: Long Papers), pages 10364\u201310379, Albuquerque, New Mexico, April 2025.\nAssociation for Computational Linguistics."
  }
]