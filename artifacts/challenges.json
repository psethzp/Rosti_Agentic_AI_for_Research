[
  {
    "id": "r0001",
    "topic": "What are some areas in which LLms today fail?",
    "claim_id": "c0001",
    "claim_text": "LLMs trained on biased data can produce unfair or discriminatory results, negatively impacting teaching and learning processes. This bias can lead to the fading of local knowledge about minorities, such as small ethnic groups or cultures. Addressing bias requires continuous model updates with diverse, unbiased data and expert human supervision to review results. Educators need training to recognize and address potential biases and other failures in model outputs.",
    "summary": "LLMs can exacerbate educational disparities due to access and cost barriers, particularly for non-English speakers.",
    "detail": "The claim focuses on bias within LLMs leading to the fading of local knowledge. However, E1 highlights a more fundamental failure: LLMs can widen the education gap due to financial barriers for access, training, and maintenance, and also due to unfair access for non-English speaking users. This suggests a systemic issue of inequity that predates or coexists with data bias, potentially impacting a broader range of users and institutions.",
    "evidence": [
      {
        "source_id": "1-ChatGPT_for_Good",
        "page": 10,
        "char_start": 1938,
        "char_end": 4252,
        "quote": "users, causing unfair access to such education technologies for non-English speaking users. Despite the efforts of various research communities to address multilingualism fairness for AI technologies, there is still much room for improvement. Lastly, the unfairness related to financial means for access- ing, trainin...",
        "chunk_id": "1-ChatGPT_for_Good:p0010:c0001",
        "chunk_text": "users, causing unfair access to such education technologies\nfor non-English speaking users. Despite the efforts of various\nresearch communities to address multilingualism fairness for\nAI technologies, there is still much room for improvement.\nLastly, the unfairness related to financial means for access-\ning, training and maintaining large language models may need\nto be regulated by governmental organisations with the aim\nto provide equity-oriented means to all educational entities\ninterested in using these modern technologies. Without fair\naccess, this AI technology may seriously widen the education\ngap like no other technology before it.\nWe therefore conclude with UNESCO\u2019s call to ensure that\nAI does not widen the technological and educational divides\nwithin and between countries, and recommended important\nstrategies for the use of AI in a responsible and fair way to\nreduce this existing gap instead. According to the UNESCO\neducation 2030 Agenda [67]: \u201cUNESCO\u2019s mandate calls in-\nherently for a human-centred approach to AI. It aims to shift\nthe conversation to include AI\u2019s role in addressing current\ninequalities regarding access to knowledge, research and the\ndiversity of cultural expressions and to ensure AI does not\nwiden the technological divides within and between countries.\nThe promise of \u201cAI for all\u201d must be that everyone can take ad-\nvantage of the technological revolution under way and access\nits fruits, notably in terms of innovation and knowledge.\u201d\n6. Concluding Remarks\nThe use of large language models in education is a promising\narea of research that offers many opportunities to enhance the\nlearning experience for students and support the work of teach-\ners. However, to unleash their full potential for education, it is\ncrucial to approach the use of these models with caution and\nto critically evaluate their limitations and potential biases. In-\ntegrating large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in"
      }
    ],
    "severity": "High",
    "actions": [
      "Investigate the extent to which financial and linguistic barriers limit LLM access in education.",
      "Explore potential regulatory or governmental interventions to ensure equitable access to LLM technology for educational purposes.",
      "Research the impact of LLM use on non-English speaking students and communities."
    ]
  },
  {
    "id": "r0005",
    "topic": "What are some areas in which LLms today fail?",
    "claim_id": "c0003",
    "claim_text": "LLMs can create unfair access for non-English speaking users, and significant improvements are still needed in multilingual fairness for AI technologies. Financial burdens associated with accessing, training, and maintaining LLMs may require governmental regulation to ensure equitable access for all educational entities. Further research is necessary in Human-Computer Interaction and User Interface Design to effectively integrate LLMs into educational workflows, considering user maturity and skills. Educators require professional training and resources to understand LLM capabilities, limitations, and how to integrate them effectively into teaching practices.",
    "summary": "The claim asserts LLMs create unfair access for non-English speakers, but the provided evidence does not directly address multilingual fairness.",
    "detail": "The claim (c0003) explicitly states that LLMs can create unfair access for non-English speaking users and that significant improvements are needed in multilingual fairness. However, neither E1 nor E2 offers any information or discussion regarding the performance or fairness of LLMs across different languages. The evidence focuses on sustainable usage, computational demands, energy consumption, ethical data collection, and the potential of LLMs to integrate digital applications and create immersive educational experiences.",
    "evidence": [
      {
        "source_id": "1-ChatGPT_for_Good",
        "page": 9,
        "char_start": 0,
        "char_end": 2392,
        "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 9/13 Sustainable usage. Large language models have high com- putational demands, which can result in high energy consump- tion. Hence, energy-efficient hardware and shared (e.g., cloud) infrastructure based on renewable energy...",
        "chunk_id": "1-ChatGPT_for_Good:p0009:c0000",
        "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 9/13\nSustainable usage.\nLarge language models have high com-\nputational demands, which can result in high energy consump-\ntion. Hence, energy-efficient hardware and shared (e.g., cloud)\ninfrastructure based on renewable energy are crucial for their\nenvironmentally sustainable operation and scaling needed in\nthe context of education.\nFor model training and updates, only data that has been\ncollected and annotated in a regulatory compliant and ethical\nway should be considered. Therefore, governance frameworks\nthat include policies, procedures, and controls to ensure such\nappropriate use of such models are key to their successful\nadoption.\nLikewise, for the long-term trustworthy and responsible\nuse of the models, transparency, bias mitigation, and ongoing\nmonitoring are indispensable.\nIn summary, the mitigation strategy for this risk would\ninclude:\n\u2022 Energy-efficient hardware and shared infrastructure\nbased on renewable energy as well as research on reduc-\ning the cost of training and maintenance (i.e., efficient\nalgorithms, representation, and storage)\n\u2022 Collection, annotation, storage, and processing of data\nin a regulatory compliant and ethical way\n\u2022 Transparency and explanation techniques to identify\nand mitigate biases and prevent unfairness\n\u2022 Governance frameworks that include policies, proce-\ndures, and controls to ensure the above points and the\nappropriate use in education\nCost to verify information and maintain integrity.\nIt is\nimportant to verify the information provided by the model by\nconsulting external authoritative sources to ensure accuracy\nand integrity. Additionally, there may be financial costs asso-\nciated with maintaining and updating the model to ensure it is\nproviding accurate up-to-date information.\nA responsible mitigation strategy for this risk would con-\nsider the following key aspects:\n\u2022 Regularly updates of the model with new and accurate\ninformation to ensure it is providing up-to-date and\naccurate information\n\u2022 Use of multiple authoritative sources to verify the in-\nformation provided by the model to ensure correctness\nand integrity\n\u2022 Use of the model in conjunction with human expertise,\ne.g., teachers or subject matter experts, who review and\nvalidate the information provided by the model\n\u2022 Development of protocol and standards for"
      },
      {
        "source_id": "1-ChatGPT_for_Good",
        "page": 6,
        "char_start": 1977,
        "char_end": 4238,
        "quote": "users. Fur- thermore, their ability to answer natural language questions across various domains can facilitate the integration of diverse digital applications into a unified framework or application, which is also critical for expanding the bounds of educational possibilities and experiences [52, 49]. In general, th...",
        "chunk_id": "1-ChatGPT_for_Good:p0006:c0001",
        "chunk_text": "users. Fur-\nthermore, their ability to answer natural language questions\nacross various domains can facilitate the integration of diverse\ndigital applications into a unified framework or application,\nwhich is also critical for expanding the bounds of educational\npossibilities and experiences [52, 49].\nIn general, the ability of these models to generate contextu-\nalized natural language texts, code for various implementation\ntasks [53] as well as various types of multimedia content\n(e.g., in combination with other AI systems, such as DALL-\nE [54]) can enable and scale the creation of compelling and\nimmersive digital (e.g., AR/VR) experiences. From gamifica-\ntion to detailed simulations for immersive learning in digital\nenvironments, large language models are a key enabling tech-\nnology. To fully realize this potential, however, it is important\nto consider not only technical aspects but also ethical, legal,\necological and social implications.\nIn the following section, we take a brief look at the risks re-\nlated to the application on large language models in education\nand provide corresponding mitigation strategies.\n4. Key Challenges and Risks Related to\nthe Application of Large Language\nModels in Education\nCopyright Issues.\nWhen we train large language models on\na task to produce education-related content \u2013 course syllabus,\nquizzes, scientific paper \u2013 the mode should be trained on\nexamples of such texts. During the generation for a new\nprompt, the answer may contain a full sentence or even a\nparagraph seen in the training set, leading to copyright and\nplagiarism issues.\nImportant steps to responsibly mitigate such an issue can\nbe the following:\n\u2022 Asking the authors of the original documents trans-\nparently (i.e., purpose and policy of data usage) for\npermission to use their content for training the model\n\u2022 Compliance with copyright terms for open-source con-\ntent\n\u2022 Inheritance and detailed terms of use for the content\ngenerated by the model\n\u2022 Informing and raising awareness of the users about\nthese policies\nBias and fairness.\nLarge language models can perpetuate\nand amplify existing biases and unfairness in society, which\ncan negatively impact teaching and learning processes and\noutcomes. For example, if a model is trained"
      }
    ],
    "severity": "High",
    "actions": [
      "Seek evidence that directly addresses the multilingual capabilities and fairness of LLMs.",
      "Investigate if LLMs exhibit biases or performance disparities based on language."
    ]
  },
  {
    "id": "r0007",
    "topic": "What are some areas in which LLms today fail?",
    "claim_id": "c0004",
    "claim_text": "It is crucial to use multiple authoritative sources to verify the information provided by LLMs to ensure its correctness and integrity. LLMs should be used in conjunction with human expertise, such as teachers or subject matter experts, who can review and validate the model's output. Clear and transparent information about the model's performance, capabilities, and limitations is essential for responsible use. Protocols and standards for fact-checking and corroborating information from LLMs need to be developed.",
    "summary": "LLMs can negatively impact critical thinking and problem-solving skills by providing effortless answers.",
    "detail": "The effortless generation of information by LLMs can lead learners to rely too heavily on the model, potentially hindering the development of their critical thinking and problem-solving abilities. This ease of access to answers might discourage independent investigation and the process of reaching conclusions or solutions through personal effort, thus amplifying laziness and diminishing the learner's intrinsic interest in the subject matter.",
    "evidence": [
      {
        "source_id": "1-ChatGPT_for_Good",
        "page": 7,
        "char_start": 0,
        "char_end": 2297,
        "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13 \u2022 Professional training and resources to educators on how to recognize and address potential biases and other fail- ures in the model\u2019s output \u2022 Continuous updates of the model with diverse, unbiased data, and supervision...",
        "chunk_id": "1-ChatGPT_for_Good:p0007:c0000",
        "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13\n\u2022 Professional training and resources to educators on how\nto recognize and address potential biases and other fail-\nures in the model\u2019s output\n\u2022 Continuous updates of the model with diverse, unbiased\ndata, and supervision of human experts to review the\nresults\nLearners may rely too heavily on the model.\nThe effort-\nlessly generated information could negatively impact their\ncritical thinking and problem-solving skills. This is because\nthe model simplifies the acquisition of answers or informa-\ntion, which can amplify laziness and counteract the learners\u2019\ninterest to conduct their own investigations and come to their\nown conclusions or solutions.\nTo encounter this risk, it is important to be aware of the\nlimitations of large language models and use them only as\na tool to support and enhance learning [55], rather than as\na replacement for human authorities and other authoritative\nsources. Thus a responsible mitigation strategy would focus\non the following key aspects:\n\u2022 Raising awareness of the limitations and unexpected\nbrittleness of large language models and AI systems in\ngeneral (i.e., experimenting with the model to build an\nown understanding of the workings and limitations)\n\u2022 Using language models to generate hypotheses and ex-\nplore different perspectives, rather than just to generate\nanswers\n\u2022 Strategies to use other educational resources (e.g., books,\narticles) and other authoritative sources to evaluate and\ncorroborate the factual correctness of the information\nprovided by the model (i.e., encouraging learners to\nquestion the generated content)\n\u2022 Incorporating critical thinking and problem-solving ac-\ntivities into the curriculum, to help students develop\nthese skills\n\u2022 Incorporating human expertise and teachers to review,\nvalidate and explain the information provided by the\nmodel\nIt is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand"
      }
    ],
    "severity": "High",
    "actions": [
      "Emphasize the importance of independent research and critical evaluation of LLM outputs.",
      "Design learning activities that require higher-order thinking skills beyond simple information retrieval.",
      "Educate learners on the potential downsides of over-reliance on LLMs."
    ]
  },
  {
    "id": "r0002",
    "topic": "What are some areas in which LLms today fail?",
    "claim_id": "c0001",
    "claim_text": "LLMs trained on biased data can produce unfair or discriminatory results, negatively impacting teaching and learning processes. This bias can lead to the fading of local knowledge about minorities, such as small ethnic groups or cultures. Addressing bias requires continuous model updates with diverse, unbiased data and expert human supervision to review results. Educators need training to recognize and address potential biases and other failures in model outputs.",
    "summary": "Over-reliance on LLMs by educators could diminish critical thinking and problem-solving skills.",
    "detail": "The claim mentions the need for educators to be trained to recognize biases and other failures. E3 introduces a related but distinct failure: teachers becoming too reliant on LLMs, potentially replacing human instruction and hindering the development of crucial skills like creativity, critical thinking, and problem-solving. This suggests a risk of LLMs undermining core educational objectives if not used as a supplement rather than a replacement.",
    "evidence": [
      {
        "source_id": "1-ChatGPT_for_Good",
        "page": 7,
        "char_start": 1918,
        "char_end": 4277,
        "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
        "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
        "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
      }
    ],
    "severity": "Medium",
    "actions": [
      "Assess the prevalence of teacher over-reliance on LLMs in educational settings.",
      "Develop pedagogical strategies and training programs to ensure LLMs are used as complementary tools that enhance, rather than replace, human instruction.",
      "Evaluate the impact of LLM integration on students' development of creativity, critical thinking, and problem-solving skills."
    ]
  },
  {
    "id": "r0003",
    "topic": "What are some areas in which LLms today fail?",
    "claim_id": "c0002",
    "claim_text": "Learners may become too reliant on LLMs, negatively impacting their critical thinking and problem-solving abilities. The effortless generation of information by LLMs can simplify the acquisition of answers, potentially reducing the need for deeper cognitive engagement. LLMs cannot replace the creativity, critical thinking, and problem-solving skills developed through human instruction. Curricula should encourage the creative and complementary use of LLMs rather than their complete replacement of human instruction.",
    "summary": "The claim that LLMs negatively impact critical thinking is not directly contradicted, but the evidence suggests mitigation strategies focus on complementary use rather than outright replacement.",
    "detail": "The claim (c0002) posits that learners may become too reliant on LLMs, hindering their critical thinking and problem-solving skills due to the effortless generation of information. While none of the provided evidence snippets directly refute this claim, they consistently emphasize the importance of using LLMs in conjunction with human expertise and instruction. Evidence E1, E2, and E3 all highlight strategies like \"use of the model in conjunction with human expertise,\" \"hybrid approaches, which combine the strengths of both human teachers and language models,\" and understanding LLM \"capabilities and limitations, as well as how to effectively use them to supplement or enhance specific learning processes.\" This suggests a consensus that LLMs should be integrated as tools to support, rather than replace, human-led development of these cognitive skills, aligning with the claim's concern about over-reliance.",
    "evidence": [
      {
        "source_id": "1-ChatGPT_for_Good",
        "page": 9,
        "char_start": 2010,
        "char_end": 4288,
        "quote": "it is providing up-to-date and accurate information \u2022 Use of multiple authoritative sources to verify the in- formation provided by the model to ensure correctness and integrity \u2022 Use of the model in conjunction with human expertise, e.g., teachers or subject matter experts, who review and validate the information p...",
        "chunk_id": "1-ChatGPT_for_Good:p0009:c0001",
        "chunk_text": "it is providing up-to-date and\naccurate information\n\u2022 Use of multiple authoritative sources to verify the in-\nformation provided by the model to ensure correctness\nand integrity\n\u2022 Use of the model in conjunction with human expertise,\ne.g., teachers or subject matter experts, who review and\nvalidate the information provided by the model\n\u2022 Development of protocol and standards for fact-checking\nand corroborating information provided by the model\n\u2022 Provide clear and transparent information on the model\u2019s\nperformance, what it is or is not capable of, and the con-\nditions under which it operates.\n\u2022 Training and resources for educators and learners on\nhow to use the model, interpret its results and evaluate\nthe information provided\n\u2022 Regular review and evaluation of the model with trans-\nparent reporting on the model\u2019s performance, i.e., what\nit is or is not capable of and the identification of con-\nditions under which inaccuracies or other issues may\narise\nDifficulty to distinguish between real knowledge and con-\nvincingly written but unverified model output.\nThe abil-\nity of large language models to generate human-like text can\nmake it difficult for students to distinguish between real knowl-\nedge and unverified information. This can lead to students\naccepting false or misleading information as true, without\nquestioning its validity.\nTo mitigate this risk, in addition to the above verification-\nand integrity-related mitigation strategy, it is important to pro-\nvide education on how information can be evaluated critically\nand teach students exploration, investigation, verification, and\ncorroboration strategies.\nLack of adaptability.\nLarge language models are not able to\nadapt to the diverse needs of students and teachers, and may\nnot be able to provide the level of personalization required for\neffective learning. This is a limitation of the current technol-\nogy, but it is conceivable that with more advanced models, the\nadaptability will increase.\nMore specifically, a sensible mitigation strategy would be\ncomprised of:\n\u2022 Use of adaptive learning technologies to personalize the\noutput of the model to the needs of individual students\nby using student data (e.g., about learning style, prior\nknowledge, and performance, etc.)\n\u2022 Customization of the"
      },
      {
        "source_id": "1-ChatGPT_for_Good",
        "page": 9,
        "char_start": 3895,
        "char_end": 5102,
        "quote": "ogy, but it is conceivable that with more advanced models, the adaptability will increase. More specifically, a sensible mitigation strategy would be comprised of: \u2022 Use of adaptive learning technologies to personalize the output of the model to the needs of individual students by using student data (e.g., about lea...",
        "chunk_id": "1-ChatGPT_for_Good:p0009:c0002",
        "chunk_text": "ogy, but it is conceivable that with more advanced models, the\nadaptability will increase.\nMore specifically, a sensible mitigation strategy would be\ncomprised of:\n\u2022 Use of adaptive learning technologies to personalize the\noutput of the model to the needs of individual students\nby using student data (e.g., about learning style, prior\nknowledge, and performance, etc.)\n\u2022 Customization of the language model\u2019s output to align\nwith the teaching style and curriculum (by using data\nprovided by the teacher)\n\u2022 Use of multi-modal learning and teaching approaches,\nwhich combine text, audio, video, and experimentation\nto provide a more engaging and personalized experience\nfor students and teachers\n\u2022 Use of hybrid approaches, which combine the strengths\nof both human teachers and language models to gener-\nate targeted and personalized learning materials (based\non feedback, guidance, and support provided by the\nteachers)\n\u2022 Regular review of the model and continual improve-\nment for curriculum-related uses cases to ensure ade-\nquate and accurate functioning for education purposes\n\u2022 Research and development to create more advanced\nmodels that can better adapt to the diverse needs of\nstudents and teachers"
      },
      {
        "source_id": "1-ChatGPT_for_Good",
        "page": 7,
        "char_start": 3847,
        "char_end": 5202,
        "quote": "in their teaching [56]. This particularly applies to the use and integration of large language models into teaching practice. Educational theory has long since suggested ways of integrating novel tools into educational practice (e.g., [57]). As with any other technological innovation, integrating large language mode...",
        "chunk_id": "1-ChatGPT_for_Good:p0007:c0002",
        "chunk_text": "in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to effectively use\nthem to supplement or enhance specific learning processes.\nThere are several ways to address these challenges and\nencounter this risk:\n\u2022 Research on the challenges of large language models in\neducation by investigating existing educational models\nof technology integration, students\u2019 learning processes\nand transfer them to the context of large language mod-\nels, as well as developing a new educational theory\nspecifically for the context of large language models\n\u2022 Assessing the needs of the educators and students and\nprovide case-based guidance (e.g., for the secure ethical\nuse of large language models in education scenarios)\n\u2022 Demand-oriented Training and professional develop-\nment opportunities for educators and institutions to\nlearn about the capabilities and potential uses of large\nlanguage models in education, as well as providing\nbest practices for integrating them into their teaching\nmethods"
      }
    ],
    "severity": "Medium",
    "actions": [
      "Investigate how the proposed mitigation strategies in the evidence (e.g., hybrid approaches, human oversight) directly address the risk of reduced critical thinking.",
      "Explore research that quantifies the impact of LLM use on critical thinking skills in educational settings."
    ]
  }
]