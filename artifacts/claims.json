[
  {
    "id": "c0001",
    "topic": "What are some areas in which LLms today fail?",
    "summary": "LLMs can struggle with maintaining focus and relevance in conversations, particularly when faced with complex tasks or external distractions.",
    "text": "The probability of an LLM agent losing focus increases as cognitive load, a measure of task complexity, rises, simulating mental fatigue. A 'threshold' parameter can determine how easily an LLM agent is distracted by off-topic comments or complex thoughts, impacting its ability to stay on task. Evaluation metrics like 'Time-on-Task' measure the percentage of conversational turns where an LLM's output remains semantically relevant to the ongoing topic, highlighting potential failures in maintaining focus. The frequency of off-topic utterances serves as a direct count of instances where an LLM deviates from the established conversation, indicating a failure in sustained attention.",
    "subpoints": [
      "The probability of an LLM agent losing focus increases as cognitive load, a measure of task complexity, rises, simulating mental fatigue.",
      "A 'threshold' parameter can determine how easily an LLM agent is distracted by off-topic comments or complex thoughts, impacting its ability to stay on task.",
      "Evaluation metrics like 'Time-on-Task' measure the percentage of conversational turns where an LLM's output remains semantically relevant to the ongoing topic, highlighting potential failures in maintaining focus.",
      "The frequency of off-topic utterances serves as a direct count of instances where an LLM deviates from the established conversation, indicating a failure in sustained attention."
    ],
    "citations": [
      {
        "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
        "page": 4,
        "char_start": 2056,
        "char_end": 3798,
        "quote": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an off-topic comment, a complex thought) shifting the agent\u2019s focus. \u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum, the probability of an attention lapse increases...",
        "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0001",
        "chunk_text": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the agent\u2019s output is semantically relevant to the\nongoing topic.\n\u2022 Frequency of Off-Topic Utterances: A count of instances where the agent\u2019s output deviates from the\nestablished topic.\n\u2022 Human Expert Ratings: Blind evaluators will rate the believability of an agent\u2019s attentional patterns.\nTestable Hypotheses:\n\u2022 H3 : Agents with a lower \u2018Attention Span\u2019 parameter will exhibit a statistically significant higher frequency\nof off-topic utterances compared to agents with higher attention spans.\n\u2022 H4 : Agents with a lower \u2018Distractibility Threshold\u2019 will show greater performance degradation in simulated\nenvironments with high levels of external distractions.\n3) The Memory and Decoding Module (Memory Filter):\nTheoretical Grounding: The module is based on the Dual-Route Cascade Model of Reading [11][35], which\nexplains how individuals decode familiar and unfamiliar words. Deficiencies in phonological (sound-based) and\northographic (visual-based) processing, which are often implicated in dyslexia, will be modeled [40]. Furthermore,\nit incorporates principles from Verbal Efficiency Theory [49], which posits that effortful decoding consumes finite\nworking memory resources needed for comprehension.\nOperational Definition: This module acts as a filter that pre-processes text input to the LLM. It is defined by:"
      }
    ],
    "confidence": 0.9,
    "status": "draft"
  },
  {
    "id": "c0002",
    "topic": "What are some areas in which LLms today fail?",
    "summary": "LLMs may exhibit limitations in accurately processing and comprehending text due to simulated decoding difficulties and limited working memory capacity.",
    "text": "A 'Phonological Noise Parameter' can introduce character-level errors into an LLM's internal text processing, mimicking decoding challenges. These simulated decoding difficulties consume space in a fixed-size 'Working Memory Buffer,' reducing the LLM's capacity for higher-level comprehension. Reading comprehension accuracy is a key metric used to evaluate an LLM's performance on simulated comprehension tasks, revealing potential weaknesses in text processing. The LLM's ability to handle phonological and orthographic processing, including character-level decoding fidelity and working memory for text, is crucial for its overall accuracy.",
    "subpoints": [
      "A 'Phonological Noise Parameter' can introduce character-level errors into an LLM's internal text processing, mimicking decoding challenges.",
      "These simulated decoding difficulties consume space in a fixed-size 'Working Memory Buffer,' reducing the LLM's capacity for higher-level comprehension.",
      "Reading comprehension accuracy is a key metric used to evaluate an LLM's performance on simulated comprehension tasks, revealing potential weaknesses in text processing.",
      "The LLM's ability to handle phonological and orthographic processing, including character-level decoding fidelity and working memory for text, is crucial for its overall accuracy."
    ],
    "citations": [
      {
        "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
        "page": 5,
        "char_start": 0,
        "char_end": 2714,
        "quote": "5 \u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into the agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties. \u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to ...",
        "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0005:c0000",
        "chunk_text": "5\n\u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into\nthe agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties.\n\u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to hold information. Effortful\ndecoding, as dictated by the noise parameter, will consume space in this buffer, reducing the resources available\nfor higher-level comprehension.\nEvaluation Metrics:\n\u2022 Reading Comprehension Accuracy: Agent performance on simulated comprehension tasks.\n\u2022 Error Analysis: Classification of agent errors into phonological, orthographic, or semantic categories.\n\u2022 Information Recall Fidelity: The accuracy with which an agent can recall facts presented in a passage, testing\nthe integrity of its working memory.\nTestable Hypotheses:\n\u2022 H5 : Agents with a high \u2018Phonological Noise\u2019 parameter will make significantly more phonologically-based\nerrors than agents with a low parameter.\n\u2022 H6 : A reduction in the \u2018Working Memory Buffer\u2019 size will be negatively correlated with an agent\u2019s ability\nto answer questions about long passages of text.\nIV. EXPECTED MILESTONES\nThe project is envisioned as a four-month intensive research program with clearly defined deliverables and\nevaluation checkpoints:\n\u2022 Month 1: Foundation and Architecture\nComplete a systematic review of educational psychology to formalize student archetypes, followed by the\ndesign of the complete Cognitive Twin architecture and development of initial meta-prompts.\nDeliverables: Comprehensive literature analysis, formal archetype specifications, and a complete architectural\ndesign with an initial meta-prompt library.\n\u2022 Month 2: Implementation and Preliminary Validation\nDevelop and implement the three core cognitive processing modules (Affect, Attention, Memory and Decod-\ning). Integrate all system components and conduct preliminary validation studies, including agent behavior\nconsistency testing.\nDeliverables: A functional, integrated system with documented performance characteristics and preliminary\nvalidation results.\n\u2022 Month 3: Comprehensive Evaluation and Alternative Architecture Exploration\nConduct full validation study including human expert evaluation, behavioral differentiation analysis, and\nCommittee of Agents implementation as a comparative study.\nDeliverables: Complete validation results and architectural comparison analysis.\n\u2022 Month 4: Analysis, Documentation, and Dissemination\nAnalyze all collected data, optimize system parameters based on evaluation results, and prepare comprehensive\ndocumentation, including academic paper preparation for submission to relevant conferences"
      },
      {
        "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
        "page": 2,
        "char_start": 2133,
        "char_end": 4362,
        "quote": "phonological and orthographic processing, such as character-level decoding fidelity and working memory for text [33][43][19]. 3) Demonstrate Superior Simulation Fidelity: Validate the architecture\u2019s effectiveness through comprehensive evaluation including human expert assessment of agent believability, quantitative ...",
        "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0002:c0001",
        "chunk_text": "phonological and orthographic\nprocessing, such as character-level decoding fidelity and working memory for text [33][43][19].\n3) Demonstrate Superior Simulation Fidelity: Validate the architecture\u2019s effectiveness through comprehensive\nevaluation including human expert assessment of agent believability, quantitative analysis of behavioral pattern\ndifferentiation between agent archetypes, and comparative analysis with existing student modeling approaches\nin terms of predictive accuracy and educational insight generation.\nIII. PROPOSED IMPLEMENTATION\nOur implementation strategy consists of four integrated phases designed to create a comprehensive psychologically-\ngrounded educational simulation framework:\na) Phase 1: Literature Review and Archetype Formalization: We begin with a systematic review of educational\npsychology literature to identify and formalize 3-5 empirically-validated student archetypes, building upon estab-\nlished frameworks such as the Deep/Surface/Strategic learning approaches [4][18][41][53]. Each archetype will be\ncharacterized through comprehensive behavioral profiles including learning motivations, communication patterns,\ncognitive processing preferences, and response tendencies to different pedagogical interventions. This phase will\nalso incorporate findings from student modeling research using Bayesian Knowledge Tracing [32][64][66] and\ncognitive agent computing models [61] to ensure compatibility with existing educational technologies.\nb) Phase 2: Disposition Layer Implementation: For each identified archetype, we will engineer sophisticated\n\u201cmeta-prompts\u201d that serve as the agent\u2019s psychological constitution. These prompts will define core motivations,\ncommunication styles, and worldviews that establish the baseline parameters for the cognitive modules in the next\nphase. (e.g., \u201cYou are a \u2018Surface Learner.\u2019 Your primary goal is to pass assessments with minimal effort. You prefer\nclear, factual information and avoid deep, open-ended discussions that require extensive cognitive processing...\u201d).\nThe meta-prompting approach will draw from recent advances in persona-based LLM control [31][37][1][67] and\npsychological authenticity research in conversational agents [30][57]."
      }
    ],
    "confidence": 0.85,
    "status": "draft"
  },
  {
    "id": "c0003",
    "topic": "What are some areas in which LLms today fail?",
    "summary": "Current LLM architectures may not holistically integrate core cognitive functions like affect, attention, and memory in a dynamic and unified manner.",
    "text": "While some cognitive architectures hint at unified systems, there's a gap in models that dynamically integrate affect, attention, and memory for comprehensive learning modeling. Affect, attention, and memory are recognized as crucial components influencing motivation, information processing, and knowledge construction, respectively. The interplay between these cognitive functions is significant, with emotional states directing or impairing focus, and focused attention being essential for memory encoding. Existing LLM implementations often focus on individual cognitive aspects rather than a holistic, dynamic integration of all three.",
    "subpoints": [
      "While some cognitive architectures hint at unified systems, there's a gap in models that dynamically integrate affect, attention, and memory for comprehensive learning modeling.",
      "Affect, attention, and memory are recognized as crucial components influencing motivation, information processing, and knowledge construction, respectively.",
      "The interplay between these cognitive functions is significant, with emotional states directing or impairing focus, and focused attention being essential for memory encoding.",
      "Existing LLM implementations often focus on individual cognitive aspects rather than a holistic, dynamic integration of all three."
    ],
    "citations": [
      {
        "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
        "page": 1,
        "char_start": 2198,
        "char_end": 4370,
        "quote": "[26], [20], [12], [7], where affect drives motivation, attention governs information processing, and memory anchors knowledge construction [29], [8], [3], [63]. Beyond these individual explorations, studies have also examined their crucial interplay as research on the link between affect and attention has shown how ...",
        "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0001:c0001",
        "chunk_text": "[26], [20], [12], [7], where affect drives motivation, attention governs information processing, and\nmemory anchors knowledge construction [29], [8], [3], [63]. Beyond these individual explorations, studies have also\nexamined their crucial interplay as research on the link between affect and attention has shown how emotional\nstates can direct or impair focus [63], [17], [39], while studies on attention and memory have confirmed that\nfocused attention is essential for effective memory encoding [46], [54], [36], [14]. Works also demonstrate how\nthese interactions create compounding effects, particularly for diverse learners, where heightened anxiety (affect)\ncan disrupt attentional control, which in turn compromises working memory, making it exceedingly difficult for\na student to follow multi-step instructions or comprehend complex texts [39]. Furthermore, studies focusing on\nlearning disabilities demonstrate that issues regarding attention or memory are often exacerbated by emotional\ndysregulation, making a unified framework essential to accurately simulate the significant barriers diverse learners\nface. [26], [36], [59], [62], [42], [55], [38]. This evidence of compounding effects due to interplay reinforces a\ncritical conclusion from cognitive and clinical research: Any model aiming to be psychologically authentic must\nintegrate all three components and simulate their dynamic interplay to reflect how they function interdependently\nwithin a natural cognitive system.\nA primary issue in the current implementations is the reliance on uniform, static student representations that\nfail to model the above core cognitive dimensions driving student behavior. [65]. Frameworks like PEERS [2] use\nlimited behavioral parameters that model only on-task actions, ignoring off-task behaviors driven by boredom or\nfrustration while even advanced systems like EduAgent [67] and SimClass [68] struggle to capture the full spectrum\nof individual differences related to these cognitive aspects, as they are yet unable to simulate how a student with\nanxiety might freeze up when called upon (affect), how another with attentional deficits might frequently disengage"
      },
      {
        "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
        "page": 2,
        "char_start": 0,
        "char_end": 2658,
        "quote": "2 (attention), or how different learning styles impact knowledge retention (memory) [4], [18], [41]. While cognitive architectures like NEOLAF and the Unified Mind Model [21][22], ACT-R [51], CLARION [60], Sigma [13], and MalAlgoPy [58] have hinted at unified systems, there remains a clear gap in models that holisti...",
        "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0002:c0000",
        "chunk_text": "2\n(attention), or how different learning styles impact knowledge retention (memory) [4], [18], [41]. While cognitive\narchitectures like NEOLAF and the Unified Mind Model [21][22], ACT-R [51], CLARION [60], Sigma [13],\nand MalAlgoPy [58] have hinted at unified systems, there remains a clear gap in models that holistically integrate\nall three components on a dynamic basis for modeling learning [39], [13], [28], [45]. To address this, we propose a\nnovel, layered agent architecture that grounds agent behavior in validated educational psychology by formalizing\nstudent archetypes [4], [18], [41], [53], made feasible by advances in persona-based prompting [31], [37], [1] and\ncognitive digital twins [23], [24]. By implementing specialized cognitive layers for affect, attention and memory,\nthis approach will aim to bridge the fidelity gap where the primary goal will be the development of authentic\npsychological diversity, transforming simulations into powerful training tools to better prepare educators for the\nunpredictable dynamics of a live classroom, ensuring they are equipped to manage diverse student needs effectively.\nII. OBJECTIVES\nThe primary goal of this research is to develop and validate a psychologically-grounded architecture for creating\nrealistic student agents in educational simulations, focusing on three main objectives:\n1) Develop a Novel Cognitive Agent Architecture: Create a layered agent system that integrates empirically-\nderived student archetypes from educational psychology literature with programmatic cognitive processing\nlayers to simulate authentic student behaviors and learning patterns.\n2) Implement Psychologically-Authentic Simulation Components: Design and validate specialized cognitive\nprocessing modules including an Affective module to dynamically modulate emotional states based on estab-\nlished psychological theories of student motivation and anxiety, an Attention module modeling variations in\nexecutive function and attention, such as distractibility and sustained focus [6][56][56], and a Memory and\nDecoding module with memory filtering mechanisms simulating variations in phonological and orthographic\nprocessing, such as character-level decoding fidelity and working memory for text [33][43][19].\n3) Demonstrate Superior Simulation Fidelity: Validate the architecture\u2019s effectiveness through comprehensive\nevaluation including human expert assessment of agent believability, quantitative analysis of behavioral pattern\ndifferentiation between agent archetypes, and comparative analysis with existing student modeling approaches\nin terms of predictive accuracy and educational insight generation."
      }
    ],
    "confidence": 0.95,
    "status": "draft"
  },
  {
    "id": "c0004",
    "topic": "What are some areas in which LLms today fail?",
    "summary": "LLMs can struggle to accurately simulate complex human emotional states and behavioral responses, particularly in dynamic interactive environments.",
    "text": "An 'Affect Module' can be implemented to track dynamic emotional states like confidence, confusion, anxiety, and engagement based on interaction history. The emotional valence in an LLM's generated language, assessed through sentiment analysis, can track shifts in its simulated emotional state. Behavioral indicators such as help-seeking frequency, response length, and proactive questioning are used to measure the LLM's simulated behaviors. Human experts, such as educators, evaluate the authenticity of an LLM agent's emotional and motivational trajectory, providing a measure of its simulation fidelity.",
    "subpoints": [
      "An 'Affect Module' can be implemented to track dynamic emotional states like confidence, confusion, anxiety, and engagement based on interaction history.",
      "The emotional valence in an LLM's generated language, assessed through sentiment analysis, can track shifts in its simulated emotional state.",
      "Behavioral indicators such as help-seeking frequency, response length, and proactive questioning are used to measure the LLM's simulated behaviors.",
      "Human experts, such as educators, evaluate the authenticity of an LLM agent's emotional and motivational trajectory, providing a measure of its simulation fidelity."
    ],
    "citations": [
      {
        "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
        "page": 3,
        "char_start": 0,
        "char_end": 2687,
        "quote": "3 c) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules that dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM that is trained to read this Control Panel and generate behavior that matches the specified cognit...",
        "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0003:c0000",
        "chunk_text": "3\nc) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules\nthat dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM\nthat is trained to read this Control Panel and generate behavior that matches the specified cognitive state to simulate\ncore cognitive functions and individual differences. The modules function as follows:\n\u2022 Affect Module (Emotional State Modulator): A state-machine implementation tracking dynamic emotional\nstates (confident, confused, anxious, engaged) based on interaction history and performance outcomes. This\nmodule will modify LLM prompt components in real-time to reflect emotional influences on communication\nstyle, response length, and cognitive processing approach. Here we update the emotion field of the Control\nPanel (e.g., \u201cemotion\u201d: \u201cprimary\u201d: \u201canxious\u201d, \u201cconfidence\u201d: 0.3), which the LLM interprets to modulate its\ncommunication style, response length, and cognitive processing approach.\n\u2022 Attention Module (Focus Manager): A dynamic attention modeling system that simulates varying atten-\ntion spans and distractibility patterns. Drawing from cognitive models of attention and executive function\n[6][56][56], this module will implement time-decay functions for attention, threshold-based coherence degra-\ndation, and attention reset mechanisms triggered by direct engagement or environmental changes. Here we\nupdate the focus field of the Control Panel in real-time (e.g., \u201cfocus\u201d: \u201clevel\u201d: 0.4), which instructs the LLM\nto adjust its response coherence and relevance.\n\u2022 Memory and Decoding Module (Memory Filter): A cognitive processing filter that models information\nprocessing variations, particularly those reflecting a spectrum of information processing speeds and accuracies\n[33][43][19]. This system will introduce controlled character-level noise (e.g., b/d reversals, transposition errors)\nwith probability distributions calibrated to diverse reading patterns, affecting information encoding and retrieval\naccuracy. Here we update the memory field of the Control Panel (e.g., \u201cmemory\u201d: \u201cdecoding fidelity\u201d: 0.85),\naffecting information encoding and retrieval accuracy.\nd) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation\nthrough multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis-\ntency, quantitative analysis of behavioral differentiation between agent types, and integration testing within educa-\ntional simulation environments. We will also explore the proposed \u201cCommittee of Agents\u201d alternative architecture as\nan ablation study,"
      },
      {
        "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
        "page": 4,
        "char_start": 0,
        "char_end": 2483,
        "quote": "4 Evaluation Metrics: \u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts. \u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and proactive questioning. \u2022 Human Expert Ratings: Educators will evaluate the authenti...",
        "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0000",
        "chunk_text": "4\nEvaluation Metrics:\n\u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts.\n\u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and\nproactive questioning.\n\u2022 Human Expert Ratings: Educators will evaluate the authenticity of the agent\u2019s emotional and motivational\ntrajectory.\nTestable Hypotheses:\n\u2022 H1 : An agent whose \u2018Control Appraisal\u2019 is systematically lowered through negative feedback will transition\nto negative emotional states (e.g., frustration, anxiety) and exhibit a corresponding increase in negative-valence\nlanguage.\n\u2022 H2 : Agents equipped with the Affective Module will be perceived by human raters as demonstrating more\nbelievable and differentiated student personalities than agents defined only by a static dispositional prompt.\n2) The Attention Module (Focus Manager):\nTheoretical Grounding: This module is grounded in hierarchical models of attention that differentiate between\nsustained attention (maintaining focus over time) and selective attention (filtering distractions) [10][50]. It also\ndraws from cognitive models of executive function, such as Baddeley\u2019s model of working memory [5], which\nincludes a central executive responsible for attentional control, and Load Theory of Attention [34] which posits that\nthe ability to ignore distractions depends on the perceptual load of the current task. These concepts are quite central\nto understanding various underlying conditions that affect Attention, such as ADHD [9]. Our model operationalizes\nthese concepts to simulate how an agent\u2019s focus can decay, be captured by competing stimuli, or be reset by direct\nengagement.\nOperational Definition: The module will be a state-based system governed by the following parameters:\n\u2022 Attention Span: A numerical value representing the number of conversational turns an agent can maintain\nfocus on a single topic before a potential \u201cattention lapse.\u201d This will be implemented as a timer that resets\nupon re-engagement.\n\u2022 Distractibility Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the"
      }
    ],
    "confidence": 0.8,
    "status": "draft"
  }
]