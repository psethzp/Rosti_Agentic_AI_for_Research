{
  "insights": [
    {
      "id": "i0001",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_ids": [
        "c0001",
        "c0003",
        "c0004",
        "c0011",
        "c0012"
      ],
      "summary": "LLMs are valuable tools for educators, streamlining administrative tasks and enhancing pedagogical approaches.",
      "text": "LLMs can significantly reduce the burden of grading, with reported efficiency gains of up to 85% while maintaining high accuracy and improving student perception of quality. They also assist teachers in creating inclusive lesson plans and activities by generating syllabi, topic descriptions, and critical thinking-focused questions. Furthermore, LLMs can provide teachers with up-to-date resources, summaries, and explanations of new teaching methodologies and technologies, helping them stay current in their field. For group and remote learning, LLMs can facilitate discussions by offering structure, real-time feedback, and personalized guidance to students.",
      "confidence": 1.0,
      "provenance": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 1952,
          "char_end": 4293,
          "quote": "also as- sist teachers in the creation of (inclusive) lesson plans and activities. Teachers can input to the models the corpus of document based on which they want to build a course. The output can be a course syllabus with short description of each topic. Language models can also generate questions and prompts that...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0001",
          "chunk_text": "also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at different\nknowledge and ability levels, and elicit critical thinking and\nproblem-solving. Moreover, they can be used to generate tar-\ngeted and personalized practice problems and quizzes, which\ncan help to ensure that students are mastering the material.\nFor language learning, teachers of language classes can\nuse large language models in an assistive way, e.g., to high-\nlight important phrases, generate summaries and translations,\nprovide explanations of grammar and vocabulary, suggest\ngrammatical or style improvements and assist in conversation\npractice. Language models can also provide teachers with\nadaptive and personalized means to assist students in their\nlanguage learning journey, which can make language learning\nmore engaging and effective for students.\nFor research and writing, large language models can\nassist teachers of university and high school classes to com-\nplete research and writing tasks (e.g., in seminar works, paper\nwriting, and feedback to students) more efficiently and effec-\ntively. The most basic help can happen at a syntactic level,\ni.e., identifying and correcting typos. At a semantic level,\nlarge language models can be used to highlight (potential)\ngrammatical inconsistencies and suggest adequate and person-\nalized improvement strategies. Going further, these models\ncan be used to identify possibilities for topic-specific style\nimprovement. They can also be used to generate summaries\nand outlines of challenging texts, which can help teachers and\nresearchers to highlight the main points of a text in a way\nthat is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 3858,
          "char_end": 6173,
          "quote": "a text and to organize their thoughts for writing. Additionally, large language models can also assist in the development of research skills by providing students with information and re- sources on a particular topic and hinting at unexplored aspects and current research topics, which can help them to better unders...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0002",
          "chunk_text": "a\ntext and to organize their thoughts for writing. Additionally,\nlarge language models can also assist in the development of\nresearch skills by providing students with information and re-\nsources on a particular topic and hinting at unexplored aspects\nand current research topics, which can help them to better\nunderstand and analyze the material.\nFor group & remote learning, large language models\ncan be used to facilitate group discussions and debates by\nproviding a discussion structure, real-time feedback and per-\nsonalized guidance to students during the discussion. This\ncan help to improve student engagement and participation. In\ncollaborative writing activities, where multiple students work\ntogether to write a document or a project, language models\ncan assist by providing style and editing suggestions as well\nas other integrative co-writing features. For research purposes,\nsuch models can be used to span the range of open research\nquestions in relation to already researched topics and to au-\ntomatically assign the questions and topics to the involved\nteam members. For remote tutoring purposes, they can be\nused to automatically generate questions and provide practice\nproblems, explanations, and assessments that are tailored to\nthe students\u2019 level of knowledge so that they can learn at their\nown pace.\nTo empower learners with disabilities, large language\nmodels can be used in combination with speech-to-text or text-\nto-speech solutions to help people with visual impairment. In\ncombination with the previously mentioned group and remote\ntutoring opportunities, language models can be used to de-\nvelop inclusive learning strategies with adequate support in\ntasks such as adaptive writing, translating, and highlighting\nof important content in various formats. However, it is im-\nportant to note that the use of large language models should\nbe accompanied by the help of professionals such as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 5605,
          "char_end": 6603,
          "quote": "student answers in large courses, where grading effort could be reduced by up to 85% with a high precision and an improved quality perceived by the students. Large language models can not only support the assess- ment of student\u2019s solutions but also assist in the automatic generation of exercises. Using few-shot lea...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0003",
          "chunk_text": "student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is able to provide a variety of\nprogramming tasks together with the correct solution, auto-\nmated tests to verify the student\u2019s solutions, and additional\ncode explanations. With regard to testing factual knowledge\nin general, [41] proposed a framework to automatically gen-\nerate question-answer pairs. This can be used in the creation\nof teaching materials, e.g., for reading comprehension tasks.\nBeyond the generation of the correct answer, transformer\nmodels are also able to create distractor answers, as needed\nfor the generation of multiple choice questionnaires [42, 43].\nBringing language models to mathematics education, sev-"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 0,
          "char_end": 2181,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 5/13 ing by a trained GPT-3 model and manual reviews by human experts. The authors reported that the generated questions were rated favorably by human experts, promoting thus the usage of large language models in data science ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 5/13\ning by a trained GPT-3 model and manual reviews by human\nexperts. The authors reported that the generated questions\nwere rated favorably by human experts, promoting thus the\nusage of large language models in data science education [20].\nStudents can learn from each other by peer-reviewing and\nassessing each other\u2019s solutions. This, of course, has the best\neffect when the given feedback is comprehensive and of high\nquality. For example, Jia et al. [21] showed how BERT can\nbe used to evaluate the peer assessments so that students can\nlearn to improve their feedback.\nIn a recent review on conversational AI in language edu-\ncation, the authors found that there are five main applications\nof conversational AI during teaching [22], the most common\none being the use of large language models as a conversa-\ntional partner in a written or oral form, e.g., in the context\nof a task-oriented dialogue that provides language practice\nopportunities such as pronunciation [23]. Another application\nis to support students when they experience foreign language\nlearning anxiety [24] or have a lower willingness to commu-\nnicate [25]. In [26], the application of providing feedback, as\na needs analyst, and evaluator when primary school students\npractice their vocabulary was explored. The authors of [27]\nfound that a chatbot that is guided by a mind map is more suc-\ncessful in supporting students by providing scaffolds during\nlanguage learning than a conventional AI chatbot.\nA recent work in the area of medical education by Kung et\nal. [28] explored the performance of ChatGPT on the United\nStates Medical Licensing Exam. According to the evaluation\nresults, the performance of ChatGPT on this test was at or\nnear the passing threshold without any domain fine-tuning.\nBased on these results, the authors argue that large language\nmodels might be a powerful tool to assist medical education\nand eventually clinical decision-making processes [28].\nTeachers\u2019 perspective.\nAs the rate of adoption of AI in\neducation is still slow compared to other fields, such as indus-\ntrial applications"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 5697,
          "char_end": 6291,
          "quote": "to generate code explanations. Despite several open research and pedagogical questions that need to be further explored, this work has successfully demon- strated the potential of GPT-3 to support learning by explain- ing aspects of a given code snippet. For a data science course, Bhat et al. [20] proposed a pipelin...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0003",
          "chunk_text": "to generate code explanations.\nDespite several open research and pedagogical questions that\nneed to be further explored, this work has successfully demon-\nstrated the potential of GPT-3 to support learning by explain-\ning aspects of a given code snippet.\nFor a data science course, Bhat et al. [20] proposed a\npipeline for generating assessment questions based on a fine-\ntuned GPT3 model on text-based learning materials. The gen-\nerated questions were further evaluated with regard to their\nusefulness to the learning outcome based on automated label-\n3https://huggingface.co/bigscience/bloom"
        }
      ]
    },
    {
      "id": "i0002",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_ids": [
        "c0002",
        "c0005",
        "c0008",
        "c0010",
        "c0015"
      ],
      "summary": "LLMs support student learning and skill development across various subjects and levels.",
      "text": "LLMs can aid in the development of research skills by providing students with information, resources, and suggestions for unexplored aspects of a topic. They can assist elementary school students in developing reading and writing skills through syntactic and grammatical corrections, and foster writing style and critical thinking. LLMs are also capable of generating math word problems that require an understanding of equations and their contextualization. For programming education, models like OpenAI Codex can generate programming tasks, correct solutions, automated tests, and code explanations. Moreover, LLMs can be used to generate personalized practice materials, summaries, and explanations to aid in the development of various skills, including reading, writing, math, science, and language.",
      "confidence": 1.0,
      "provenance": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 3858,
          "char_end": 6173,
          "quote": "a text and to organize their thoughts for writing. Additionally, large language models can also assist in the development of research skills by providing students with information and re- sources on a particular topic and hinting at unexplored aspects and current research topics, which can help them to better unders...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0002",
          "chunk_text": "a\ntext and to organize their thoughts for writing. Additionally,\nlarge language models can also assist in the development of\nresearch skills by providing students with information and re-\nsources on a particular topic and hinting at unexplored aspects\nand current research topics, which can help them to better\nunderstand and analyze the material.\nFor group & remote learning, large language models\ncan be used to facilitate group discussions and debates by\nproviding a discussion structure, real-time feedback and per-\nsonalized guidance to students during the discussion. This\ncan help to improve student engagement and participation. In\ncollaborative writing activities, where multiple students work\ntogether to write a document or a project, language models\ncan assist by providing style and editing suggestions as well\nas other integrative co-writing features. For research purposes,\nsuch models can be used to span the range of open research\nquestions in relation to already researched topics and to au-\ntomatically assign the questions and topics to the involved\nteam members. For remote tutoring purposes, they can be\nused to automatically generate questions and provide practice\nproblems, explanations, and assessments that are tailored to\nthe students\u2019 level of knowledge so that they can learn at their\nown pace.\nTo empower learners with disabilities, large language\nmodels can be used in combination with speech-to-text or text-\nto-speech solutions to help people with visual impairment. In\ncombination with the previously mentioned group and remote\ntutoring opportunities, language models can be used to de-\nvelop inclusive learning strategies with adequate support in\ntasks such as adaptive writing, translating, and highlighting\nof important content in various formats. However, it is im-\nportant to note that the use of large language models should\nbe accompanied by the help of professionals such as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 5605,
          "char_end": 6603,
          "quote": "student answers in large courses, where grading effort could be reduced by up to 85% with a high precision and an improved quality perceived by the students. Large language models can not only support the assess- ment of student\u2019s solutions but also assist in the automatic generation of exercises. Using few-shot lea...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0003",
          "chunk_text": "student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is able to provide a variety of\nprogramming tasks together with the correct solution, auto-\nmated tests to verify the student\u2019s solutions, and additional\ncode explanations. With regard to testing factual knowledge\nin general, [41] proposed a framework to automatically gen-\nerate question-answer pairs. This can be used in the creation\nof teaching materials, e.g., for reading comprehension tasks.\nBeyond the generation of the correct answer, transformer\nmodels are also able to create distractor answers, as needed\nfor the generation of multiple choice questionnaires [42, 43].\nBringing language models to mathematics education, sev-"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 6,
          "char_start": 0,
          "char_end": 2405,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 6/13 eral works discuss the automatic generation of math word problems [44, 45, 46], which combines the challenge of un- derstanding equations and putting them into the appropriate context. Finally, another recent work [47] in...",
          "chunk_id": "1-ChatGPT_for_Good:p0006:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 6/13\neral works discuss the automatic generation of math word\nproblems [44, 45, 46], which combines the challenge of un-\nderstanding equations and putting them into the appropriate\ncontext.\nFinally, another recent work [47] investigated the capabil-\nity of state-of-the-art conversational agents to adequately reply\nto a student in an educational dialogue. Both models used in\nthis work (Blender and GPT-3) were capable of replying to\na student adequately and generated conversational dialogues\nthat conveyed the impression that these models understand the\nlearner (in particular Blender). They are however well behind\nhuman performance when it comes to helping the student [47],\nthus emphasizing the need for further research.\n3. Opportunities for Innovative\nEducational Technologies\nLooking forward, large language models bear the potential to\nconsiderably improve digital ecosystems for education, such\nas environments based on Augmented Reality (AR), Virtual\nReality (VR) [48, 49], and other related digital experiences.\nSpecifically, they can be used to amplify several key fac-\ntors, which are crucial for the immersive interaction of users\nwith digital content. For example, large language models\ncan considerably improve the natural language processing\nand understanding capabilities of an AR/VR system to enable\nan effective natural communication and interaction between\nusers and the system (e.g., virtual teacher or virtual peers).\nThe latter has been identified early on as a key usability aspect\nfor immersive educational technologies [50] and is in general\nseen as a key factor for improving the interaction between\nhumans and AI systems [51].\nLarge language models can also be used to develop more\nnatural and sophisticated user interfaces by exploiting their\nability to generate contextualized, personalized, and diverse\nresponses to natural language questions asked by users. Fur-\nthermore, their ability to answer natural language questions\nacross various domains can facilitate the integration of diverse\ndigital applications into a unified framework or application,\nwhich is also critical for expanding the bounds of educational\npossibilities and experiences [52, 49].\nIn general, the ability of these models to generate contextu-\nalized natural language texts, code for various implementation"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 1901,
          "char_end": 4241,
          "quote": "these mod- els, opportunities for enhancement of learning and teaching experiences may be possible for individuals at all levels of edu- cation, including primary, secondary, tertiary and professional development. For elementary school students, large language models can assist in the development of reading and writ...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0001",
          "chunk_text": "these mod-\nels, opportunities for enhancement of learning and teaching\nexperiences may be possible for individuals at all levels of edu-\ncation, including primary, secondary, tertiary and professional\ndevelopment.\nFor elementary school students, large language models\ncan assist in the development of reading and writing skills\n(e.g., by suggesting syntactic and grammatical corrections), as\nwell as in the development of writing style and critical think-\ning skills. These models can be used to generate questions\nand prompts that encourage students to think critically about\nwhat they are reading and writing, and to analyze and inter-\npret the information presented to them. Additionally, large\nlanguage models can also assist in the development of reading\ncomprehension skills by providing students with summaries\nand explanations of complex texts, which can make reading\nand understanding the material easier.\nFor middle and high school students, large language\nmodels can assist in the learning of a language and of writ-\ning styles for various subjects and topics, e.g., mathematics,\nphysics, language and literature, and other subjects. These\nmodels can be used to generate practice problems and quizzes,\nwhich can help students to better understand, contextual-\nize and retain the material they are learning. Additionally,\nlarge language models can also assist in the development of\nproblem-solving skills by providing students with explana-\ntions, step-by-step solutions, and interesting related questions\nto problems, which can help them to understand the reasoning\nbehind the solutions and develop analytical and out-of-the-box\nthinking.\nFor university students, large language models can assist\nin the research and writing tasks, as well as in the development\nof critical thinking and problem-solving skills. These models\ncan be used to generate summaries and outlines of texts, which\ncan help students to quickly understand the main points of a\ntext and to organize their thoughts for writing. Additionally,\nlarge language models can also assist in the development of\nresearch skills by providing students with information and re-\nsources on a particular topic and hinting at unexplored aspects\nand current research topics, which can help them to better\nunderstand and analyze the material.\nFor group & remote learning, large"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 0,
          "char_end": 2311,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 3/13 They can also generate questions and prompts that encourage learners to think critically about their work and to analyze and interpret the information presented to them. In conclusion, large language models have the poten...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 3/13\nThey can also generate questions and prompts that encourage\nlearners to think critically about their work and to analyze and\ninterpret the information presented to them.\nIn conclusion, large language models have the potential to\nprovide a wide range of benefits and opportunities for students\nand professionals at all stages of education. They can assist\nin the development of reading, writing, math, science, and\nlanguage skills, as well as providing students with personal-\nized practice materials, summaries and explanations, which\ncan help to improve student performance and contribute to en-\nhanced learning experiences. Additionally, large language\nmodels can also assist in research, writing, and problem-\nsolving tasks, and provide domain-specific language skills\nand other skills for professional training. However, as pre-\nviously mentioned, the use of these models should be done\nwith caution, as they also have limitations such as lack of\ninterpretability and potential for bias, unexpected brittleness\nin relatively simple tasks [9] which need to be addressed.\n1.2 Opportunities for Teaching\nLarge language models, such as ChatGPT, have the potential\nto revolutionize teaching and assist in teaching processes.\nBelow we provide only a few examples of how these models\ncan benefit teachers:\nFor personalized learning, teachers can use large lan-\nguage models to create personalized learning experiences for\ntheir students. These models can analyze student\u2019s writing\nand responses, and provide tailored feedback and suggest ma-\nterials that align with the student\u2019s specific learning needs.\nSuch support can save teachers\u2019 time and effort in creating\npersonalized materials and feedback, and also allow them to\nfocus on other aspects of teaching, such as creating engaging\nand interactive lessons.\nFor lesson planning, large language models can also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at"
        }
      ]
    },
    {
      "id": "i0003",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_ids": [
        "c0007",
        "c0009",
        "c0013"
      ],
      "summary": "LLMs are versatile in generating diverse content and facilitating communication.",
      "text": "LLMs can generate human-like text, answer questions, and perform tasks like translation and summarization. They can also generate contextualized natural language texts and code for various implementation tasks, and in conjunction with other AI systems, can create multimedia content. Conversational agents, powered by LLMs, can adequately respond to students in educational dialogues, generating conversational exchanges.",
      "confidence": 1.0,
      "provenance": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 0,
          "char_end": 2228,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 4/13 2. Current Research and Applications of Language Models in Education 2.1 Overview of Current Large Language Models The GPT (Generative Pre-trained Transformer) [10] model developed by OpenAI was the first large language m...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 4/13\n2. Current Research and Applications of\nLanguage Models in Education\n2.1 Overview of Current Large Language Models\nThe GPT (Generative Pre-trained Transformer) [10] model\ndeveloped by OpenAI was the first large language model that\nwas publicly released in 2018. GPT was able to generate\nhuman-like text, answer questions, and assist in tasks, such as\ntranslation and summarization, through human-like comple-\ntion. Based on this initial model, OpenAI later released the\nGPT-2 and GPT-3 models with more advanced capabilities.\nIt can be argued that the release of GPT marked a significant\nmilestone in the field of NLP and has opened up many ways\nfor dissemination, both in research and industrial applications.\nAnother model that was released by Google Research in\n2018 is BERT (Bidirectional Encoder Representations from\nTransformers [2]), which is also based on a transformer ar-\nchitecture and is pre-trained on a massive dataset of text data\non two unsupervised tasks, namely masked language mod-\neling (to predict missing parts in a sentence and learn their\ncontext) and next sentence prediction (to learn plausible sub-\nsequent sentences of a given sentence) with the aim to learn\nthe broader context of words in various topics.\nOne year later in 2019, Google AI released XLNet [11],\nwhich is trained using a process called permutation language\nmodeling and enables XLNet to cope with tasks that involve\nunderstanding the dependencies between words in a sentence,\ne.g., natural language inference and question answering. An-\nother model developed by Google Research was T5 (Text-to-\nText Transfer Transformer) [12], which was released in 2020.\nLike the predecessor models, T5 is also transformer-based\nmodel trained on a massive text dataset with the key feature\nbeing its ability to perform many NLP tasks with a single\npre-training and fine-tuning pipeline.\nIn parallel with Open AI and Google, Facebook AI devel-\noped a large language model called RoBERTa (Robustly Opti-\nmized BERT Pre-training) [13], which was released in 2019.\nRoBERTa is a variant of the BERT model which uses dynamic\nmasking instead of static masking"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 6,
          "char_start": 0,
          "char_end": 2405,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 6/13 eral works discuss the automatic generation of math word problems [44, 45, 46], which combines the challenge of un- derstanding equations and putting them into the appropriate context. Finally, another recent work [47] in...",
          "chunk_id": "1-ChatGPT_for_Good:p0006:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 6/13\neral works discuss the automatic generation of math word\nproblems [44, 45, 46], which combines the challenge of un-\nderstanding equations and putting them into the appropriate\ncontext.\nFinally, another recent work [47] investigated the capabil-\nity of state-of-the-art conversational agents to adequately reply\nto a student in an educational dialogue. Both models used in\nthis work (Blender and GPT-3) were capable of replying to\na student adequately and generated conversational dialogues\nthat conveyed the impression that these models understand the\nlearner (in particular Blender). They are however well behind\nhuman performance when it comes to helping the student [47],\nthus emphasizing the need for further research.\n3. Opportunities for Innovative\nEducational Technologies\nLooking forward, large language models bear the potential to\nconsiderably improve digital ecosystems for education, such\nas environments based on Augmented Reality (AR), Virtual\nReality (VR) [48, 49], and other related digital experiences.\nSpecifically, they can be used to amplify several key fac-\ntors, which are crucial for the immersive interaction of users\nwith digital content. For example, large language models\ncan considerably improve the natural language processing\nand understanding capabilities of an AR/VR system to enable\nan effective natural communication and interaction between\nusers and the system (e.g., virtual teacher or virtual peers).\nThe latter has been identified early on as a key usability aspect\nfor immersive educational technologies [50] and is in general\nseen as a key factor for improving the interaction between\nhumans and AI systems [51].\nLarge language models can also be used to develop more\nnatural and sophisticated user interfaces by exploiting their\nability to generate contextualized, personalized, and diverse\nresponses to natural language questions asked by users. Fur-\nthermore, their ability to answer natural language questions\nacross various domains can facilitate the integration of diverse\ndigital applications into a unified framework or application,\nwhich is also critical for expanding the bounds of educational\npossibilities and experiences [52, 49].\nIn general, the ability of these models to generate contextu-\nalized natural language texts, code for various implementation"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 6,
          "char_start": 1977,
          "char_end": 4238,
          "quote": "users. Fur- thermore, their ability to answer natural language questions across various domains can facilitate the integration of diverse digital applications into a unified framework or application, which is also critical for expanding the bounds of educational possibilities and experiences [52, 49]. In general, th...",
          "chunk_id": "1-ChatGPT_for_Good:p0006:c0001",
          "chunk_text": "users. Fur-\nthermore, their ability to answer natural language questions\nacross various domains can facilitate the integration of diverse\ndigital applications into a unified framework or application,\nwhich is also critical for expanding the bounds of educational\npossibilities and experiences [52, 49].\nIn general, the ability of these models to generate contextu-\nalized natural language texts, code for various implementation\ntasks [53] as well as various types of multimedia content\n(e.g., in combination with other AI systems, such as DALL-\nE [54]) can enable and scale the creation of compelling and\nimmersive digital (e.g., AR/VR) experiences. From gamifica-\ntion to detailed simulations for immersive learning in digital\nenvironments, large language models are a key enabling tech-\nnology. To fully realize this potential, however, it is important\nto consider not only technical aspects but also ethical, legal,\necological and social implications.\nIn the following section, we take a brief look at the risks re-\nlated to the application on large language models in education\nand provide corresponding mitigation strategies.\n4. Key Challenges and Risks Related to\nthe Application of Large Language\nModels in Education\nCopyright Issues.\nWhen we train large language models on\na task to produce education-related content \u2013 course syllabus,\nquizzes, scientific paper \u2013 the mode should be trained on\nexamples of such texts. During the generation for a new\nprompt, the answer may contain a full sentence or even a\nparagraph seen in the training set, leading to copyright and\nplagiarism issues.\nImportant steps to responsibly mitigate such an issue can\nbe the following:\n\u2022 Asking the authors of the original documents trans-\nparently (i.e., purpose and policy of data usage) for\npermission to use their content for training the model\n\u2022 Compliance with copyright terms for open-source con-\ntent\n\u2022 Inheritance and detailed terms of use for the content\ngenerated by the model\n\u2022 Informing and raising awareness of the users about\nthese policies\nBias and fairness.\nLarge language models can perpetuate\nand amplify existing biases and unfairness in society, which\ncan negatively impact teaching and learning processes and\noutcomes. For example, if a model is trained"
        }
      ]
    },
    {
      "id": "i0004",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_ids": [
        "c0006",
        "c0014"
      ],
      "summary": "LLMs show potential in professional training and specialized domains.",
      "text": "LLMs can assist in professional training by developing field-specific language skills and aiding in the acquisition of skills such as programming, report writing, project management, decision making, and problem-solving. They have also demonstrated the potential to assist in medical education and clinical decision-making processes, performing at or near passing thresholds without domain-specific fine-tuning.",
      "confidence": 1.0,
      "provenance": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 5772,
          "char_end": 6441,
          "quote": "as speech therapists, educators, and other specialists that can adapt the technology to the specific needs of the learner\u2019s disabilities. For professional training, large language models can assist in the development of language skills that are specific to a particular field of work. They can also assist in the deve...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0003",
          "chunk_text": "as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision making and problem-solving.\nFor example, large language models can be fine-tuned on\na domain-specific corpus (e.g. legal, medical, IT) in order\nto generate domain-specific language and assist learners in\nwriting technical reports, legal documents, medical records etc."
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 1794,
          "char_end": 4059,
          "quote": "was at or near the passing threshold without any domain fine-tuning. Based on these results, the authors argue that large language models might be a powerful tool to assist medical education and eventually clinical decision-making processes [28]. Teachers\u2019 perspective. As the rate of adoption of AI in education is s...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0001",
          "chunk_text": "was at or\nnear the passing threshold without any domain fine-tuning.\nBased on these results, the authors argue that large language\nmodels might be a powerful tool to assist medical education\nand eventually clinical decision-making processes [28].\nTeachers\u2019 perspective.\nAs the rate of adoption of AI in\neducation is still slow compared to other fields, such as indus-\ntrial applications (e.g., finance, e-commerce, automotive) or\nmedicine, there are less studies considering the use of large\nlanguage models in education [29]. A recent review of oppor-\ntunities and challenges of chatbots in education pointed out\nthat the studies related to chatbots in education are still in an\nearly stage, with few empirical studies investigating the use of\neffective learning designs or learning strategies [30]. There-\nfore, we discuss first the teachers\u2019 perspectives concerning AI\nand Learning Analytics in education and transfer these on the\nmuch newer field of large language models.\nIn this view, a pilot study with European teachers indi-\ncates a positive attitude towards AI for education and a high\nmotivation to introduce AI-related content at school. Overall,\nthe teachers from the study seemed to have a basic level of\ndigital skills but low AI-related skills [31]. Another study\nwith Nigerian teachers emphasized that the willingness and\nreadiness of teachers to promote AI are key prerequisites for\nthe integration of AI-based technologies in education [32].\nAlong the same lines, the results of a study with teachers from\nSouth Korea indicate that teachers with constructivist beliefs\nare more likely to integrate educational AI-based tools than\nteachers with transmissive orientations [33]. Furthermore, per-\nceived usefulness, perceived ease of use, and perceived trust in\nthese AI-based tools are determinants to be considered when\npredicting their acceptance by the teachers. Similar results\nconcerning teachers attitudes towards chatbots in education\nwere reported in [34]: perceiving the AI chatbot as easy-to-\nuse and useful leads to greater acceptance of the chatbot. As\nfor the chatbots\u2019 features, formal language by a chatbot leads\nto a higher intention of using it.\nAs it seems that teachers\u2019 perspectives on the general use\nof AI in education have a"
        }
      ]
    }
  ],
  "actions": [
    {
      "id": "a0001",
      "topic": "What are some tasks that LLMs today are used for?",
      "title": "Quantify the impact of LLM-assisted grading on student learning outcomes.",
      "detail": "While c0004 states LLMs can reduce grading effort and maintain high precision, it would be beneficial to investigate if this efficiency translates to improved student learning outcomes. Does the time saved by educators lead to more personalized feedback or instructional time, and how does this impact student performance?.",
      "tag": "Clarification",
      "related_claims": [
        "c0004"
      ]
    },
    {
      "id": "a0002",
      "topic": "What are some tasks that LLMs today are used for?",
      "title": "Explore the efficacy of LLM-generated personalized practice materials.",
      "detail": "Claim c0015 suggests LLMs can generate personalized practice materials. A next step would be to design and conduct studies to empirically validate the effectiveness of these materials across different subjects and student demographics, comparing their impact to traditional practice methods.",
      "tag": "NextStep",
      "related_claims": [
        "c0015"
      ]
    },
    {
      "id": "a0003",
      "topic": "What are some tasks that LLMs today are used for?",
      "title": "Hypothesize the optimal integration points for LLMs in remote and group learning environments.",
      "detail": "Given that LLMs can facilitate discussions in group and remote learning (c0003), a hypothesis could be that LLMs are most effective when integrated as a structured facilitator, providing prompts and feedback, rather than as a primary source of information, to encourage genuine student interaction.",
      "tag": "Hypothesis",
      "related_claims": [
        "c0003"
      ]
    },
    {
      "id": "a0004",
      "topic": "What are some tasks that LLMs today are used for?",
      "title": "Investigate the scalability and cost-effectiveness of LLM deployment in educational institutions.",
      "detail": "The claims highlight numerous benefits of LLMs in education. A crucial next step is to assess the practicalities of widespread adoption. This includes understanding the infrastructure requirements, potential costs, and the scalability of LLM solutions for diverse educational settings, from small classrooms to large universities.",
      "tag": "NextStep",
      "related_claims": [
        "c0001",
        "c0002",
        "c0003",
        "c0004",
        "c0005",
        "c0006",
        "c0007",
        "c0008",
        "c0009",
        "c0010",
        "c0011",
        "c0012",
        "c0013",
        "c0014",
        "c0015"
      ]
    },
    {
      "id": "a0005",
      "topic": "What are some tasks that LLMs today are used for?",
      "title": "Clarify the ethical considerations and potential biases in LLM-generated educational content.",
      "detail": "While LLMs can generate diverse content (c0007, c0013) and assist in creating inclusive lesson plans (c0001), it's essential to clarify the potential for biases in this generated content. Further investigation is needed to understand how to mitigate these biases and ensure equitable and accurate educational materials.",
      "tag": "Clarification",
      "related_claims": [
        "c0001",
        "c0007",
        "c0013"
      ]
    }
  ],
  "challenges": [
    {
      "id": "r0001",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0001",
      "claim_text": "Large language models (LLMs) can assist teachers in creating inclusive lesson plans and activities by generating course syllabi, topic descriptions, and questions that encourage critical thinking and participation from students of varying abilities. (E1).",
      "summary": "The claim states LLMs can assist teachers in creating inclusive lesson plans and activities, but the evidence focuses more on general teaching assistance and professional development.",
      "detail": "The claim specifically mentions LLMs assisting teachers in creating inclusive lesson plans and activities by generating course syllabi, topic descriptions, and questions that encourage critical thinking and participation from students of varying abilities. While the evidence snippets (E1, E3) do mention LLMs assisting with lesson planning, personalized content creation, and differentiation, they do not explicitly detail the generation of specific elements like course syllabi or questions designed for varying abilities to encourage critical thinking and participation. The evidence leans more towards providing resources, summaries, explanations of new methodologies, and on-the-job training modules (E1), and general lesson planning and personalized instruction (E3).",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 5792,
          "char_end": 6400,
          "quote": "acquaint students early on with potential societal biases, and risks of AI application. In conclusion, large language models have the potential to revolutionize teaching from a teacher\u2019s perspective by pro- viding teachers with a wide range of tools and resources that can assist with lesson planning, personalized co...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0003",
          "chunk_text": "acquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language models\nhave the potential to be a powerful tool in education, and\nthere are a number of ongoing research efforts exploring its\npotential applications in this area."
        }
      ],
      "actions": [
        "Investigate if LLMs can generate specific lesson plan components like syllabi and differentiated questions.",
        "Clarify how LLMs ensure inclusivity and encourage critical thinking for students of varying abilities within lesson plans."
      ]
    },
    {
      "id": "r0002",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0001",
      "claim_text": "Large language models (LLMs) can assist teachers in creating inclusive lesson plans and activities by generating course syllabi, topic descriptions, and questions that encourage critical thinking and participation from students of varying abilities. (E1).",
      "summary": "The claim implies LLMs can directly create inclusive lesson plans, but evidence highlights the risk of over-reliance and the need for human oversight.",
      "detail": "The claim suggests LLMs can assist teachers in creating inclusive lesson plans and activities. However, evidence snippets E4 and E5 strongly caution against teachers becoming too reliant on LLMs and emphasize that these models should supplement, not replace, human instruction. E4 states that LLMs cannot replace the creativity, critical thinking, and problem-solving skills developed through human instruction. E5 points out that learners may rely too heavily on LLMs, negatively impacting their critical thinking and problem-solving skills due to the effortless generation of information. This suggests that while LLMs can aid in content creation, the 'inclusive' and 'critical thinking' aspects require significant human teacher involvement to ensure effectiveness and avoid detrimental over-reliance.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 0,
          "char_end": 2297,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13 \u2022 Professional training and resources to educators on how to recognize and address potential biases and other fail- ures in the model\u2019s output \u2022 Continuous updates of the model with diverse, unbiased data, and supervision...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13\n\u2022 Professional training and resources to educators on how\nto recognize and address potential biases and other fail-\nures in the model\u2019s output\n\u2022 Continuous updates of the model with diverse, unbiased\ndata, and supervision of human experts to review the\nresults\nLearners may rely too heavily on the model.\nThe effort-\nlessly generated information could negatively impact their\ncritical thinking and problem-solving skills. This is because\nthe model simplifies the acquisition of answers or informa-\ntion, which can amplify laziness and counteract the learners\u2019\ninterest to conduct their own investigations and come to their\nown conclusions or solutions.\nTo encounter this risk, it is important to be aware of the\nlimitations of large language models and use them only as\na tool to support and enhance learning [55], rather than as\na replacement for human authorities and other authoritative\nsources. Thus a responsible mitigation strategy would focus\non the following key aspects:\n\u2022 Raising awareness of the limitations and unexpected\nbrittleness of large language models and AI systems in\ngeneral (i.e., experimenting with the model to build an\nown understanding of the workings and limitations)\n\u2022 Using language models to generate hypotheses and ex-\nplore different perspectives, rather than just to generate\nanswers\n\u2022 Strategies to use other educational resources (e.g., books,\narticles) and other authoritative sources to evaluate and\ncorroborate the factual correctness of the information\nprovided by the model (i.e., encouraging learners to\nquestion the generated content)\n\u2022 Incorporating critical thinking and problem-solving ac-\ntivities into the curriculum, to help students develop\nthese skills\n\u2022 Incorporating human expertise and teachers to review,\nvalidate and explain the information provided by the\nmodel\nIt is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand"
        }
      ],
      "actions": [
        "Examine the extent to which LLM-generated content requires human modification to ensure inclusivity and critical thinking.",
        "Explore best practices for integrating LLMs into lesson planning to avoid teacher over-reliance and maintain educational quality."
      ]
    },
    {
      "id": "r0003",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0002",
      "claim_text": "LLMs can support the development of research skills by providing students with information, resources, and suggestions for unexplored aspects of a topic. (E2).",
      "summary": "LLMs can assist in research by providing information and suggesting new avenues of inquiry.",
      "detail": "The claim states that LLMs can support research skills by offering information, resources, and suggestions for unexplored aspects of a topic. Evidence snippets E2 and E3 support this by mentioning that LLMs can locate information or resources professionals may need, assist in research, and provide students with personalized practice materials, summaries, and explanations that can improve performance and learning experiences. E3 explicitly states LLMs can assist in research.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 0,
          "char_end": 2311,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 3/13 They can also generate questions and prompts that encourage learners to think critically about their work and to analyze and interpret the information presented to them. In conclusion, large language models have the poten...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 3/13\nThey can also generate questions and prompts that encourage\nlearners to think critically about their work and to analyze and\ninterpret the information presented to them.\nIn conclusion, large language models have the potential to\nprovide a wide range of benefits and opportunities for students\nand professionals at all stages of education. They can assist\nin the development of reading, writing, math, science, and\nlanguage skills, as well as providing students with personal-\nized practice materials, summaries and explanations, which\ncan help to improve student performance and contribute to en-\nhanced learning experiences. Additionally, large language\nmodels can also assist in research, writing, and problem-\nsolving tasks, and provide domain-specific language skills\nand other skills for professional training. However, as pre-\nviously mentioned, the use of these models should be done\nwith caution, as they also have limitations such as lack of\ninterpretability and potential for bias, unexpected brittleness\nin relatively simple tasks [9] which need to be addressed.\n1.2 Opportunities for Teaching\nLarge language models, such as ChatGPT, have the potential\nto revolutionize teaching and assist in teaching processes.\nBelow we provide only a few examples of how these models\ncan benefit teachers:\nFor personalized learning, teachers can use large lan-\nguage models to create personalized learning experiences for\ntheir students. These models can analyze student\u2019s writing\nand responses, and provide tailored feedback and suggest ma-\nterials that align with the student\u2019s specific learning needs.\nSuch support can save teachers\u2019 time and effort in creating\npersonalized materials and feedback, and also allow them to\nfocus on other aspects of teaching, such as creating engaging\nand interactive lessons.\nFor lesson planning, large language models can also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at"
        }
      ],
      "actions": [
        "Confirm that LLMs can indeed provide suggestions for unexplored aspects of a topic, not just general information.",
        "Investigate the extent to which LLMs can proactively identify and suggest 'unexplored aspects' versus simply responding to user queries about a topic."
      ]
    },
    {
      "id": "r0004",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0002",
      "claim_text": "LLMs can support the development of research skills by providing students with information, resources, and suggestions for unexplored aspects of a topic. (E2).",
      "summary": "Over-reliance on LLMs for information could hinder the development of critical thinking and independent research skills.",
      "detail": "While LLMs can provide information and resources (E2, E3), there's a significant concern that students might become too reliant on them. Evidence E4 and E5 highlight that LLMs cannot replace creativity, critical thinking, and problem-solving skills developed through human instruction and that effortlessly generated information could negatively impact these skills. This is because LLMs simplify the acquisition of answers, potentially leading to laziness and reducing the learner's motivation to conduct their own investigations and reach their own conclusions.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 0,
          "char_end": 2311,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 3/13 They can also generate questions and prompts that encourage learners to think critically about their work and to analyze and interpret the information presented to them. In conclusion, large language models have the poten...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 3/13\nThey can also generate questions and prompts that encourage\nlearners to think critically about their work and to analyze and\ninterpret the information presented to them.\nIn conclusion, large language models have the potential to\nprovide a wide range of benefits and opportunities for students\nand professionals at all stages of education. They can assist\nin the development of reading, writing, math, science, and\nlanguage skills, as well as providing students with personal-\nized practice materials, summaries and explanations, which\ncan help to improve student performance and contribute to en-\nhanced learning experiences. Additionally, large language\nmodels can also assist in research, writing, and problem-\nsolving tasks, and provide domain-specific language skills\nand other skills for professional training. However, as pre-\nviously mentioned, the use of these models should be done\nwith caution, as they also have limitations such as lack of\ninterpretability and potential for bias, unexpected brittleness\nin relatively simple tasks [9] which need to be addressed.\n1.2 Opportunities for Teaching\nLarge language models, such as ChatGPT, have the potential\nto revolutionize teaching and assist in teaching processes.\nBelow we provide only a few examples of how these models\ncan benefit teachers:\nFor personalized learning, teachers can use large lan-\nguage models to create personalized learning experiences for\ntheir students. These models can analyze student\u2019s writing\nand responses, and provide tailored feedback and suggest ma-\nterials that align with the student\u2019s specific learning needs.\nSuch support can save teachers\u2019 time and effort in creating\npersonalized materials and feedback, and also allow them to\nfocus on other aspects of teaching, such as creating engaging\nand interactive lessons.\nFor lesson planning, large language models can also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 0,
          "char_end": 2297,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13 \u2022 Professional training and resources to educators on how to recognize and address potential biases and other fail- ures in the model\u2019s output \u2022 Continuous updates of the model with diverse, unbiased data, and supervision...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13\n\u2022 Professional training and resources to educators on how\nto recognize and address potential biases and other fail-\nures in the model\u2019s output\n\u2022 Continuous updates of the model with diverse, unbiased\ndata, and supervision of human experts to review the\nresults\nLearners may rely too heavily on the model.\nThe effort-\nlessly generated information could negatively impact their\ncritical thinking and problem-solving skills. This is because\nthe model simplifies the acquisition of answers or informa-\ntion, which can amplify laziness and counteract the learners\u2019\ninterest to conduct their own investigations and come to their\nown conclusions or solutions.\nTo encounter this risk, it is important to be aware of the\nlimitations of large language models and use them only as\na tool to support and enhance learning [55], rather than as\na replacement for human authorities and other authoritative\nsources. Thus a responsible mitigation strategy would focus\non the following key aspects:\n\u2022 Raising awareness of the limitations and unexpected\nbrittleness of large language models and AI systems in\ngeneral (i.e., experimenting with the model to build an\nown understanding of the workings and limitations)\n\u2022 Using language models to generate hypotheses and ex-\nplore different perspectives, rather than just to generate\nanswers\n\u2022 Strategies to use other educational resources (e.g., books,\narticles) and other authoritative sources to evaluate and\ncorroborate the factual correctness of the information\nprovided by the model (i.e., encouraging learners to\nquestion the generated content)\n\u2022 Incorporating critical thinking and problem-solving ac-\ntivities into the curriculum, to help students develop\nthese skills\n\u2022 Incorporating human expertise and teachers to review,\nvalidate and explain the information provided by the\nmodel\nIt is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand"
        }
      ],
      "actions": [
        "Explore strategies and best practices for integrating LLMs into research education to ensure they supplement rather than supplant critical thinking and independent investigation.",
        "Investigate the specific types of 'unexplored aspects' LLMs can suggest and how these suggestions can be framed to encourage, rather than shortcut, deeper research."
      ]
    },
    {
      "id": "r0005",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0003",
      "claim_text": "For group and remote learning, LLMs can facilitate discussions by offering structure, real-time feedback, and personalized guidance to students. (E2).",
      "summary": "The provided evidence does not directly support the claim that LLMs facilitate group and remote learning discussions with real-time feedback and personalized guidance.",
      "detail": "While the evidence snippets discuss LLMs' potential to enhance learning experiences, assist in skill development (reading, writing, critical thinking), and generate prompts for critical thinking (E1), they do not specifically address the facilitation of group discussions in remote learning settings. The evidence mentions peer-reviewing and assessing solutions (E2), but this is distinct from LLMs actively structuring or guiding discussions in real-time. The claim's focus on \"structure, real-time feedback, and personalized guidance to students\" within group/remote discussions is not explicitly corroborated by the provided snippets.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 1901,
          "char_end": 4241,
          "quote": "these mod- els, opportunities for enhancement of learning and teaching experiences may be possible for individuals at all levels of edu- cation, including primary, secondary, tertiary and professional development. For elementary school students, large language models can assist in the development of reading and writ...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0001",
          "chunk_text": "these mod-\nels, opportunities for enhancement of learning and teaching\nexperiences may be possible for individuals at all levels of edu-\ncation, including primary, secondary, tertiary and professional\ndevelopment.\nFor elementary school students, large language models\ncan assist in the development of reading and writing skills\n(e.g., by suggesting syntactic and grammatical corrections), as\nwell as in the development of writing style and critical think-\ning skills. These models can be used to generate questions\nand prompts that encourage students to think critically about\nwhat they are reading and writing, and to analyze and inter-\npret the information presented to them. Additionally, large\nlanguage models can also assist in the development of reading\ncomprehension skills by providing students with summaries\nand explanations of complex texts, which can make reading\nand understanding the material easier.\nFor middle and high school students, large language\nmodels can assist in the learning of a language and of writ-\ning styles for various subjects and topics, e.g., mathematics,\nphysics, language and literature, and other subjects. These\nmodels can be used to generate practice problems and quizzes,\nwhich can help students to better understand, contextual-\nize and retain the material they are learning. Additionally,\nlarge language models can also assist in the development of\nproblem-solving skills by providing students with explana-\ntions, step-by-step solutions, and interesting related questions\nto problems, which can help them to understand the reasoning\nbehind the solutions and develop analytical and out-of-the-box\nthinking.\nFor university students, large language models can assist\nin the research and writing tasks, as well as in the development\nof critical thinking and problem-solving skills. These models\ncan be used to generate summaries and outlines of texts, which\ncan help students to quickly understand the main points of a\ntext and to organize their thoughts for writing. Additionally,\nlarge language models can also assist in the development of\nresearch skills by providing students with information and re-\nsources on a particular topic and hinting at unexplored aspects\nand current research topics, which can help them to better\nunderstand and analyze the material.\nFor group & remote learning, large"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 0,
          "char_end": 2181,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 5/13 ing by a trained GPT-3 model and manual reviews by human experts. The authors reported that the generated questions were rated favorably by human experts, promoting thus the usage of large language models in data science ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 5/13\ning by a trained GPT-3 model and manual reviews by human\nexperts. The authors reported that the generated questions\nwere rated favorably by human experts, promoting thus the\nusage of large language models in data science education [20].\nStudents can learn from each other by peer-reviewing and\nassessing each other\u2019s solutions. This, of course, has the best\neffect when the given feedback is comprehensive and of high\nquality. For example, Jia et al. [21] showed how BERT can\nbe used to evaluate the peer assessments so that students can\nlearn to improve their feedback.\nIn a recent review on conversational AI in language edu-\ncation, the authors found that there are five main applications\nof conversational AI during teaching [22], the most common\none being the use of large language models as a conversa-\ntional partner in a written or oral form, e.g., in the context\nof a task-oriented dialogue that provides language practice\nopportunities such as pronunciation [23]. Another application\nis to support students when they experience foreign language\nlearning anxiety [24] or have a lower willingness to commu-\nnicate [25]. In [26], the application of providing feedback, as\na needs analyst, and evaluator when primary school students\npractice their vocabulary was explored. The authors of [27]\nfound that a chatbot that is guided by a mind map is more suc-\ncessful in supporting students by providing scaffolds during\nlanguage learning than a conventional AI chatbot.\nA recent work in the area of medical education by Kung et\nal. [28] explored the performance of ChatGPT on the United\nStates Medical Licensing Exam. According to the evaluation\nresults, the performance of ChatGPT on this test was at or\nnear the passing threshold without any domain fine-tuning.\nBased on these results, the authors argue that large language\nmodels might be a powerful tool to assist medical education\nand eventually clinical decision-making processes [28].\nTeachers\u2019 perspective.\nAs the rate of adoption of AI in\neducation is still slow compared to other fields, such as indus-\ntrial applications"
        }
      ],
      "actions": [
        "Search for evidence that directly discusses LLM applications in facilitating group or remote learning discussions.",
        "Look for evidence detailing how LLMs provide structure, real-time feedback, or personalized guidance within a group learning context."
      ]
    },
    {
      "id": "r0006",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0003",
      "claim_text": "For group and remote learning, LLMs can facilitate discussions by offering structure, real-time feedback, and personalized guidance to students. (E2).",
      "summary": "The evidence highlights potential negative impacts on critical thinking and problem-solving skills due to over-reliance on LLMs, which could counter the claim's implication of personalized guidance enhancing learning.",
      "detail": "Several snippets warn that learners may rely too heavily on LLMs, leading to a negative impact on their critical thinking and problem-solving skills because the models simplify information acquisition. This can foster laziness and discourage independent investigation (E6). The claim suggests LLMs offer \"personalized guidance\" which, if interpreted as providing answers or simplifying tasks, could inadvertently lead to the issues described in the evidence. The evidence emphasizes that LLMs should be a \"complementary supplement\" and not a replacement for human instruction, and that teachers should help mitigate risks of over-reliance (E4, E6).",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 0,
          "char_end": 2297,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13 \u2022 Professional training and resources to educators on how to recognize and address potential biases and other fail- ures in the model\u2019s output \u2022 Continuous updates of the model with diverse, unbiased data, and supervision...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13\n\u2022 Professional training and resources to educators on how\nto recognize and address potential biases and other fail-\nures in the model\u2019s output\n\u2022 Continuous updates of the model with diverse, unbiased\ndata, and supervision of human experts to review the\nresults\nLearners may rely too heavily on the model.\nThe effort-\nlessly generated information could negatively impact their\ncritical thinking and problem-solving skills. This is because\nthe model simplifies the acquisition of answers or informa-\ntion, which can amplify laziness and counteract the learners\u2019\ninterest to conduct their own investigations and come to their\nown conclusions or solutions.\nTo encounter this risk, it is important to be aware of the\nlimitations of large language models and use them only as\na tool to support and enhance learning [55], rather than as\na replacement for human authorities and other authoritative\nsources. Thus a responsible mitigation strategy would focus\non the following key aspects:\n\u2022 Raising awareness of the limitations and unexpected\nbrittleness of large language models and AI systems in\ngeneral (i.e., experimenting with the model to build an\nown understanding of the workings and limitations)\n\u2022 Using language models to generate hypotheses and ex-\nplore different perspectives, rather than just to generate\nanswers\n\u2022 Strategies to use other educational resources (e.g., books,\narticles) and other authoritative sources to evaluate and\ncorroborate the factual correctness of the information\nprovided by the model (i.e., encouraging learners to\nquestion the generated content)\n\u2022 Incorporating critical thinking and problem-solving ac-\ntivities into the curriculum, to help students develop\nthese skills\n\u2022 Incorporating human expertise and teachers to review,\nvalidate and explain the information provided by the\nmodel\nIt is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand"
        }
      ],
      "actions": [
        "Investigate how LLM-driven \"personalized guidance\" can be designed to actively promote critical thinking rather than hinder it.",
        "Look for evidence that demonstrates LLMs effectively balancing personalized support with the development of independent learning and problem-solving skills."
      ]
    },
    {
      "id": "r0007",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0004",
      "claim_text": "LLMs can significantly reduce grading effort in large courses, with reported reductions of up to 85% while maintaining high precision and improving perceived quality by students. (E4).",
      "summary": "The claim that LLMs can significantly reduce grading effort by up to 85% is not directly supported by the provided evidence.",
      "detail": "While evidence E1 mentions that teachers can use LLMs to semi-automate grading, it does not quantify the reduction in effort or provide specific percentages like the claimed 85%. The other evidence snippets discuss LLMs in education for content generation, peer assessment evaluation, and professional development, but do not offer data on grading efficiency.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        }
      ],
      "actions": [
        "Seek evidence that quantifies the reduction in grading effort by LLMs.",
        "Look for studies that report specific percentages of grading time saved.",
        "Investigate if the 'high precision' and 'improved perceived quality' aspects of the claim are supported by evidence."
      ]
    },
    {
      "id": "r0008",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0004",
      "claim_text": "LLMs can significantly reduce grading effort in large courses, with reported reductions of up to 85% while maintaining high precision and improving perceived quality by students. (E4).",
      "summary": "The evidence does not address the claim's assertion about maintaining high precision and improving perceived quality by students.",
      "detail": "The provided snippets focus on the potential of LLMs in education, including semi-automating grading (E1), teacher attitudes towards AI (E2), and LLM applications in data science education (E3). However, none of the evidence directly discusses the precision of LLM-based grading or student perceptions of the quality of work graded by LLMs. Evidence E4 mentions the difficulty in distinguishing model-generated from student-generated answers, which could be a related challenge but doesn't speak to grading quality.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 3704,
          "char_end": 5972,
          "quote": "teachers attitudes towards chatbots in education were reported in [34]: perceiving the AI chatbot as easy-to- use and useful leads to greater acceptance of the chatbot. As for the chatbots\u2019 features, formal language by a chatbot leads to a higher intention of using it. As it seems that teachers\u2019 perspectives on the ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0002",
          "chunk_text": "teachers attitudes towards chatbots in education\nwere reported in [34]: perceiving the AI chatbot as easy-to-\nuse and useful leads to greater acceptance of the chatbot. As\nfor the chatbots\u2019 features, formal language by a chatbot leads\nto a higher intention of using it.\nAs it seems that teachers\u2019 perspectives on the general use\nof AI in education have a lot in common with the mentioned at-\ntitude towards chatbots in particular, a responsible integration\nof AI into education by involving the expertise of different\ncommunities is crucial [35].\nRecent works addressing the use of large language models\nfrom the teacher\u2019s perspective have focused on the automated\nassessment of student answers, adaptive feedback, and the\ngeneration of teaching content.\nFor example, a recent work by Moore et al. [36] employed\na fine-tuned GPT-3 model to evaluate student-generated an-\nswers in a learning environment for chemistry education [36].\nThe authors argue that large language models might (espe-\ncially when fine-tuned to the specific domain) be a powerful\ntool to assist teachers in the quality and pedagogical evalua-\ntion of student answers [36]. In addition, the following studies\nexamined NLP-based models for generating automatic adap-\ntive feedback: Zhu et al. [37] examined an AI-based feedback\nsystem incorporating automated scoring technologies in the\ncontext of a high school climate activity task. The results show\nthat the feedback helped students revise their scientific argu-\nments. Sailer et al. [38] used NLP-based adaptive feedback\nin the context of diagnosing students\u2019 learning difficulties in\nteacher education. In their experimental study, they found that\npre-service teachers who received adaptive feedback were\nbetter able to justify their diagnoses than prospective teachers\nwho received static feedback. Bernius et al. [39] used NLP-\nbased models to generate feedback for textual student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 0,
          "char_end": 2181,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 5/13 ing by a trained GPT-3 model and manual reviews by human experts. The authors reported that the generated questions were rated favorably by human experts, promoting thus the usage of large language models in data science ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 5/13\ning by a trained GPT-3 model and manual reviews by human\nexperts. The authors reported that the generated questions\nwere rated favorably by human experts, promoting thus the\nusage of large language models in data science education [20].\nStudents can learn from each other by peer-reviewing and\nassessing each other\u2019s solutions. This, of course, has the best\neffect when the given feedback is comprehensive and of high\nquality. For example, Jia et al. [21] showed how BERT can\nbe used to evaluate the peer assessments so that students can\nlearn to improve their feedback.\nIn a recent review on conversational AI in language edu-\ncation, the authors found that there are five main applications\nof conversational AI during teaching [22], the most common\none being the use of large language models as a conversa-\ntional partner in a written or oral form, e.g., in the context\nof a task-oriented dialogue that provides language practice\nopportunities such as pronunciation [23]. Another application\nis to support students when they experience foreign language\nlearning anxiety [24] or have a lower willingness to commu-\nnicate [25]. In [26], the application of providing feedback, as\na needs analyst, and evaluator when primary school students\npractice their vocabulary was explored. The authors of [27]\nfound that a chatbot that is guided by a mind map is more suc-\ncessful in supporting students by providing scaffolds during\nlanguage learning than a conventional AI chatbot.\nA recent work in the area of medical education by Kung et\nal. [28] explored the performance of ChatGPT on the United\nStates Medical Licensing Exam. According to the evaluation\nresults, the performance of ChatGPT on this test was at or\nnear the passing threshold without any domain fine-tuning.\nBased on these results, the authors argue that large language\nmodels might be a powerful tool to assist medical education\nand eventually clinical decision-making processes [28].\nTeachers\u2019 perspective.\nAs the rate of adoption of AI in\neducation is still slow compared to other fields, such as indus-\ntrial applications"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 8,
          "char_start": 0,
          "char_end": 2311,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 8/13 \u2022 Open educational resources (e.g., tutorials, studies, use cases, etc.) and Guidelines for educators and institu- tions to access and learn about the use of language models in education \u2022 Incentives for collaboration and...",
          "chunk_id": "1-ChatGPT_for_Good:p0008:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 8/13\n\u2022 Open educational resources (e.g., tutorials, studies, use\ncases, etc.) and Guidelines for educators and institu-\ntions to access and learn about the use of language\nmodels in education\n\u2022 Incentives for collaboration and community building\n(e.g., professional learning communities) among edu-\ncators and institutions that are already using language\nmodels in their teaching practice, so they can share their\nknowledge and experience with others\n\u2022 Regular analysis and feedback on the use of language\nmodels to ensure their effective use and make adjust-\nments as necessary\nDifficulty to distinguish model-generated from student\u2013\ngenerated answers.\nIt is becoming increasingly difficult to\ndistinguish whether a text is machine- or human-generated,\npresenting an additional major challenge to teachers and ed-\nucators [58, 59, 60, 61]. As a result, the New York City\u2019s\nDepartment of Education recently banned ChatGPT from\nschools\u2019 devices and networks [62].\nJust recently, Cotton et al. [60] proposed several strate-\ngies to detect work that has been generated by large language\nmodels, and specifically ChatGPT. In addition, tools, such as\nthe recently released GPTZero [63], which uses perplexity,\nas a measure that hints at generalization capabilities (of the\nagent by which the text was written), to detect AI involvement\nin text writing, are expected to provide additional support.\nMore advanced techniques aim at watermarking the content\ngenerated by language models [64, 65], e.g., by biasing the\ncontent generation towards terms, which are rather unlikely\nto be jointly used by humans in a text passage. In the long\nrun, however, we believe that developing curricula and instruc-\ntions that encourage the creative and evidence-based use of\nlarge language models will be the key to solving this problem.\nHence, a reasonable mitigation strategy for this risk should\nfocus on:\n\u2022 Research on transparency, explanation and analysis\ntechniques and measures to distinguish machine- from\nhuman-generated text\n\u2022 Incentives and support to develop curricula and instruc-\ntions that require the creative and complementary use\nof large language models\nCost of training and maintenance.\nThe maintenance of\nlarge language"
        }
      ],
      "actions": [
        "Find evidence that evaluates the precision of LLM grading.",
        "Search for studies that measure student satisfaction or perception of quality when LLMs are involved in grading.",
        "Explore research on the accuracy and reliability of LLM-generated feedback in educational assessments."
      ]
    },
    {
      "id": "r0009",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0005",
      "claim_text": "The OpenAI Codex model, using few-shot learning, can generate programming tasks, correct solutions, automated tests, and code explanations, aiding in learning programming. (E4).",
      "summary": "The claim states OpenAI Codex can generate programming tasks, solutions, tests, and explanations, but evidence only directly supports code explanations.",
      "detail": "The claim asserts that OpenAI Codex, through few-shot learning, can generate programming tasks, correct solutions, automated tests, and code explanations, thereby assisting in programming education. However, the provided evidence snippets do not fully corroborate all these capabilities. E1 explicitly mentions GPT-3's potential to support learning by explaining code snippets, aligning with the 'code explanations' aspect. E2 discusses LLMs generating educational content like quizzes and flashcards, and E4 mentions LLMs for automated assessment, adaptive feedback, and content generation from a teacher's perspective. None of the snippets directly confirm Codex's ability to generate programming tasks, correct solutions, or automated tests.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 5697,
          "char_end": 6291,
          "quote": "to generate code explanations. Despite several open research and pedagogical questions that need to be further explored, this work has successfully demon- strated the potential of GPT-3 to support learning by explain- ing aspects of a given code snippet. For a data science course, Bhat et al. [20] proposed a pipelin...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0003",
          "chunk_text": "to generate code explanations.\nDespite several open research and pedagogical questions that\nneed to be further explored, this work has successfully demon-\nstrated the potential of GPT-3 to support learning by explain-\ning aspects of a given code snippet.\nFor a data science course, Bhat et al. [20] proposed a\npipeline for generating assessment questions based on a fine-\ntuned GPT3 model on text-based learning materials. The gen-\nerated questions were further evaluated with regard to their\nusefulness to the learning outcome based on automated label-\n3https://huggingface.co/bigscience/bloom"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 3807,
          "char_end": 6075,
          "quote": "13 programming languages, resulting in a data volume of 1.6TB. 2.2 Review of Research Applying Large Language Models in Education In the following, we provide an overview of research works employing large language models in education that were pub- lished since the release of the first large language model in 2018. ...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0002",
          "chunk_text": "13 programming\nlanguages, resulting in a data volume of 1.6TB.\n2.2 Review of Research Applying Large Language\nModels in Education\nIn the following, we provide an overview of research works\nemploying large language models in education that were pub-\nlished since the release of the first large language model in\n2018. These studies have been discussed in the following\naccording to their target groups, i.e., learners or teachers.\nLearners\u2019 perspective.\nFrom a student\u2019s perspective, large\nlanguage models can be used in multiple ways to assist the\nlearning process. One example is in the creation and design of\neducational content. For example, researchers have used large\nlanguage models to generate interactive educational materials\nsuch as quizzes and flashcards, which can be used to improve\nstudent learning and engagement [16, 17]. More specifically,\nin a recent work by Dijkstra et al. [17], researchers have used\nGPT-3 to generate multiple-choice questions and answers\nfor a reading comprehension task and argue that automated\ngeneration of quizzes not only reduces the burden of manual\nquiz design for teachers but, above all, provides a helpful tool\nfor students to train and test their knowledge while learning\nfrom textbooks and during exam preparation [17].\nIn another recent work, GPT-3 was employed as a ped-\nagogical agent to stimulate the curiosity of children and en-\nhance question-asking skills [18]. More specifically, the au-\nthors automated the generation of curiosity-prompting cues\nas an incentive for asking more and deeper questions. Ac-\ncording to their results, large language models not only bear\nthe potential to significantly facilitate the implementation of\ncuriosity-stimulating learning but can also serve as an efficient\ntool towards an increased curiosity expression [18].\nIn computing education, a recent work by MacNeil et\nal. [19] has employed GPT-3 to generate code explanations.\nDespite several open research and pedagogical questions that\nneed to be further explored, this work has successfully demon-\nstrated the potential of GPT-3 to support learning by explain-\ning aspects of a given code snippet.\nFor a data science course, Bhat et al. [20] proposed a\npipeline for generating assessment questions based on a fine-\ntuned"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 3704,
          "char_end": 5972,
          "quote": "teachers attitudes towards chatbots in education were reported in [34]: perceiving the AI chatbot as easy-to- use and useful leads to greater acceptance of the chatbot. As for the chatbots\u2019 features, formal language by a chatbot leads to a higher intention of using it. As it seems that teachers\u2019 perspectives on the ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0002",
          "chunk_text": "teachers attitudes towards chatbots in education\nwere reported in [34]: perceiving the AI chatbot as easy-to-\nuse and useful leads to greater acceptance of the chatbot. As\nfor the chatbots\u2019 features, formal language by a chatbot leads\nto a higher intention of using it.\nAs it seems that teachers\u2019 perspectives on the general use\nof AI in education have a lot in common with the mentioned at-\ntitude towards chatbots in particular, a responsible integration\nof AI into education by involving the expertise of different\ncommunities is crucial [35].\nRecent works addressing the use of large language models\nfrom the teacher\u2019s perspective have focused on the automated\nassessment of student answers, adaptive feedback, and the\ngeneration of teaching content.\nFor example, a recent work by Moore et al. [36] employed\na fine-tuned GPT-3 model to evaluate student-generated an-\nswers in a learning environment for chemistry education [36].\nThe authors argue that large language models might (espe-\ncially when fine-tuned to the specific domain) be a powerful\ntool to assist teachers in the quality and pedagogical evalua-\ntion of student answers [36]. In addition, the following studies\nexamined NLP-based models for generating automatic adap-\ntive feedback: Zhu et al. [37] examined an AI-based feedback\nsystem incorporating automated scoring technologies in the\ncontext of a high school climate activity task. The results show\nthat the feedback helped students revise their scientific argu-\nments. Sailer et al. [38] used NLP-based adaptive feedback\nin the context of diagnosing students\u2019 learning difficulties in\nteacher education. In their experimental study, they found that\npre-service teachers who received adaptive feedback were\nbetter able to justify their diagnoses than prospective teachers\nwho received static feedback. Bernius et al. [39] used NLP-\nbased models to generate feedback for textual student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is"
        }
      ],
      "actions": [
        "Verify if OpenAI Codex specifically can generate programming tasks, correct solutions, and automated tests.",
        "Investigate if the 'code explanations' mentioned in E1 are directly related to the capabilities of OpenAI Codex as described in the claim."
      ]
    },
    {
      "id": "r0010",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0005",
      "claim_text": "The OpenAI Codex model, using few-shot learning, can generate programming tasks, correct solutions, automated tests, and code explanations, aiding in learning programming. (E4).",
      "summary": "The claim focuses on OpenAI Codex and few-shot learning, while evidence discusses broader LLM applications and different models.",
      "detail": "The claim specifically attributes the mentioned capabilities to the 'OpenAI Codex model' and highlights its use of 'few-shot learning'. The provided evidence, however, discusses large language models (LLMs) more generally and mentions specific models like GPT-3 (E1, E3) and Bloom (E2), without always specifying the learning paradigm used. While GPT-3 is an OpenAI model, the evidence doesn't explicitly link its capabilities to Codex or the few-shot learning approach for all the tasks mentioned in the claim. This creates a potential gap in directly attributing all claimed functionalities to the specified model and method.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 5697,
          "char_end": 6291,
          "quote": "to generate code explanations. Despite several open research and pedagogical questions that need to be further explored, this work has successfully demon- strated the potential of GPT-3 to support learning by explain- ing aspects of a given code snippet. For a data science course, Bhat et al. [20] proposed a pipelin...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0003",
          "chunk_text": "to generate code explanations.\nDespite several open research and pedagogical questions that\nneed to be further explored, this work has successfully demon-\nstrated the potential of GPT-3 to support learning by explain-\ning aspects of a given code snippet.\nFor a data science course, Bhat et al. [20] proposed a\npipeline for generating assessment questions based on a fine-\ntuned GPT3 model on text-based learning materials. The gen-\nerated questions were further evaluated with regard to their\nusefulness to the learning outcome based on automated label-\n3https://huggingface.co/bigscience/bloom"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 3807,
          "char_end": 6075,
          "quote": "13 programming languages, resulting in a data volume of 1.6TB. 2.2 Review of Research Applying Large Language Models in Education In the following, we provide an overview of research works employing large language models in education that were pub- lished since the release of the first large language model in 2018. ...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0002",
          "chunk_text": "13 programming\nlanguages, resulting in a data volume of 1.6TB.\n2.2 Review of Research Applying Large Language\nModels in Education\nIn the following, we provide an overview of research works\nemploying large language models in education that were pub-\nlished since the release of the first large language model in\n2018. These studies have been discussed in the following\naccording to their target groups, i.e., learners or teachers.\nLearners\u2019 perspective.\nFrom a student\u2019s perspective, large\nlanguage models can be used in multiple ways to assist the\nlearning process. One example is in the creation and design of\neducational content. For example, researchers have used large\nlanguage models to generate interactive educational materials\nsuch as quizzes and flashcards, which can be used to improve\nstudent learning and engagement [16, 17]. More specifically,\nin a recent work by Dijkstra et al. [17], researchers have used\nGPT-3 to generate multiple-choice questions and answers\nfor a reading comprehension task and argue that automated\ngeneration of quizzes not only reduces the burden of manual\nquiz design for teachers but, above all, provides a helpful tool\nfor students to train and test their knowledge while learning\nfrom textbooks and during exam preparation [17].\nIn another recent work, GPT-3 was employed as a ped-\nagogical agent to stimulate the curiosity of children and en-\nhance question-asking skills [18]. More specifically, the au-\nthors automated the generation of curiosity-prompting cues\nas an incentive for asking more and deeper questions. Ac-\ncording to their results, large language models not only bear\nthe potential to significantly facilitate the implementation of\ncuriosity-stimulating learning but can also serve as an efficient\ntool towards an increased curiosity expression [18].\nIn computing education, a recent work by MacNeil et\nal. [19] has employed GPT-3 to generate code explanations.\nDespite several open research and pedagogical questions that\nneed to be further explored, this work has successfully demon-\nstrated the potential of GPT-3 to support learning by explain-\ning aspects of a given code snippet.\nFor a data science course, Bhat et al. [20] proposed a\npipeline for generating assessment questions based on a fine-\ntuned"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 12,
          "char_start": 2131,
          "char_end": 4678,
          "quote": "and John Stamper. Assessing the Quality of Student-Generated Short Answer Questions Using GPT- 3. In Educating for a New Future: Making Sense of Technology-Enhanced Learning Adoption: 17th Euro- pean Conference on Technology Enhanced Learning, EC- TEL 2022, Toulouse, France, September 12\u201316, 2022, Proceedings, pages...",
          "chunk_id": "1-ChatGPT_for_Good:p0012:c0001",
          "chunk_text": "and John Stamper. Assessing the Quality of\nStudent-Generated Short Answer Questions Using GPT-\n3. In Educating for a New Future: Making Sense of\nTechnology-Enhanced Learning Adoption: 17th Euro-\npean Conference on Technology Enhanced Learning, EC-\nTEL 2022, Toulouse, France, September 12\u201316, 2022,\nProceedings, pages 243\u2013257. Springer, 2022.\n[37] Hee-Sun Lee Mengxiao Zhu, Ou Lydia Liu. The effect\nof automated feedback on revision behavior and learn-\ning gains in formative assessment of scientific argument\nwriting. Computers & Education, 143:103668, 2020.\n[38] Michael Sailer, Elisabeth Bauer, Riikka Hofmann, Jan\nKiesewetter, Julia Glas, Iryna Gurevych, and Frank Fis-\ncher. Adaptive feedback from artificial neural networks\nfacilitates pre-service teachers\u2019 diagnostic reasoning in\nsimulation-based learning.\nLearning and Instruction,\n83:101620, 2023.\n[39] Jan Philip Bernius, Stephan Krusche, and Bernd Bruegge.\nMachine learning based feedback on textual student an-\nswers in large courses. Computers and Education: Artifi-\ncial Intelligence, 3, 2022.\n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen.\nAutomatic generation of programming exercises and code\nexplanations using large language models. In Proceed-\nings of the 2022 ACM Conference on International Com-\nputing Education Research-Volume 1, pages 27\u201343, 2022.\n[41] Fanyi Qu, Xin Jia, and Yunfang Wu.\nAsking Ques-\ntions Like Educational Experts: Automatically Gener-\nating Question-Answer Pairs on Real-World Examination\nData. In Proceedings of the 2021 Conference on Em-\npirical Methods in Natural Language Processing, pages\n2583\u20132593, 2021.\n[42] Ricardo Rodriguez-Torrealba, Eva Garcia-Lopez, and An-\ntonio Garcia-Cabot. End-to-end generation of multiple-\nchoice questions using text-to-text transfer transformer\nmodels. Expert Systems with Applications, 208:118258,\n2022.\n[43] Vatsal Raina and Mark Gales. Multiple-Choice Question\nGeneration: Towards an Automated Assessment Frame-\nwork. arXiv preprint arXiv:2209.11830, 2022.\n[44] Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin\nJiang, Ming Zhang, and Qun Liu. Generate & Rank: A\nMulti-task Framework for Math Word Problems. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2021, pages 2269\u20132279, 2021.\n[45] Weijiang Yu, Yingpeng Wen, Fudan Zheng, and Nong\nXiao. Improving math word problems with pre-trained\nknowledge and hierarchical reasoning. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 3384\u20133394, 2021.\n[46] Zichao Wang, Andrew Lan,"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 3704,
          "char_end": 5972,
          "quote": "teachers attitudes towards chatbots in education were reported in [34]: perceiving the AI chatbot as easy-to- use and useful leads to greater acceptance of the chatbot. As for the chatbots\u2019 features, formal language by a chatbot leads to a higher intention of using it. As it seems that teachers\u2019 perspectives on the ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0002",
          "chunk_text": "teachers attitudes towards chatbots in education\nwere reported in [34]: perceiving the AI chatbot as easy-to-\nuse and useful leads to greater acceptance of the chatbot. As\nfor the chatbots\u2019 features, formal language by a chatbot leads\nto a higher intention of using it.\nAs it seems that teachers\u2019 perspectives on the general use\nof AI in education have a lot in common with the mentioned at-\ntitude towards chatbots in particular, a responsible integration\nof AI into education by involving the expertise of different\ncommunities is crucial [35].\nRecent works addressing the use of large language models\nfrom the teacher\u2019s perspective have focused on the automated\nassessment of student answers, adaptive feedback, and the\ngeneration of teaching content.\nFor example, a recent work by Moore et al. [36] employed\na fine-tuned GPT-3 model to evaluate student-generated an-\nswers in a learning environment for chemistry education [36].\nThe authors argue that large language models might (espe-\ncially when fine-tuned to the specific domain) be a powerful\ntool to assist teachers in the quality and pedagogical evalua-\ntion of student answers [36]. In addition, the following studies\nexamined NLP-based models for generating automatic adap-\ntive feedback: Zhu et al. [37] examined an AI-based feedback\nsystem incorporating automated scoring technologies in the\ncontext of a high school climate activity task. The results show\nthat the feedback helped students revise their scientific argu-\nments. Sailer et al. [38] used NLP-based adaptive feedback\nin the context of diagnosing students\u2019 learning difficulties in\nteacher education. In their experimental study, they found that\npre-service teachers who received adaptive feedback were\nbetter able to justify their diagnoses than prospective teachers\nwho received static feedback. Bernius et al. [39] used NLP-\nbased models to generate feedback for textual student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is"
        }
      ],
      "actions": [
        "Confirm that the capabilities mentioned in the claim (generating tasks, solutions, tests, explanations) are indeed exclusive to or primarily demonstrated by OpenAI Codex using few-shot learning.",
        "Clarify if the evidence supporting code explanations (E1) is derived from a few-shot learning approach with Codex, or if it applies to other LLMs or learning methods."
      ]
    },
    {
      "id": "r0011",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0006",
      "claim_text": "LLMs can assist in professional training by developing field-specific language skills and aiding in the acquisition of skills such as programming, report writing, project management, decision making, and problem-solving. (E5).",
      "summary": "The claim that LLMs can assist in professional training by developing field-specific language skills is not directly supported by the provided evidence.",
      "detail": "While the evidence snippets discuss LLMs assisting in professional development by providing resources, summaries, and explanations of new methodologies and technologies (E6), and aiding in the acquisition of skills like programming, report writing, and project management is mentioned in the claim, the evidence does not explicitly detail the development of 'field-specific language skills' as a distinct capability for professional training. The evidence focuses more on general skill enhancement and information provision.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        }
      ],
      "actions": [
        "Search for evidence that specifically details LLMs developing 'field-specific language skills' in professional training contexts.",
        "Clarify if 'field-specific language skills' is implicitly covered by the general skill development mentioned in the evidence."
      ]
    },
    {
      "id": "r0012",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0006",
      "claim_text": "LLMs can assist in professional training by developing field-specific language skills and aiding in the acquisition of skills such as programming, report writing, project management, decision making, and problem-solving. (E5).",
      "summary": "The claim that LLMs can aid in decision making and problem-solving for professional training is partially supported, but with a caveat about LLMs not replacing human critical thinking.",
      "detail": "Evidence suggests LLMs can generate questions and prompts that elicit critical thinking and problem-solving (E3). However, other evidence strongly emphasizes that LLMs cannot replace the creativity, critical thinking, and problem-solving skills developed through human instruction and should be used as a supplement rather than a replacement (E4). This implies that while LLMs can facilitate these skills, they are not the sole or primary means of their acquisition in professional training.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 1952,
          "char_end": 4293,
          "quote": "also as- sist teachers in the creation of (inclusive) lesson plans and activities. Teachers can input to the models the corpus of document based on which they want to build a course. The output can be a course syllabus with short description of each topic. Language models can also generate questions and prompts that...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0001",
          "chunk_text": "also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at different\nknowledge and ability levels, and elicit critical thinking and\nproblem-solving. Moreover, they can be used to generate tar-\ngeted and personalized practice problems and quizzes, which\ncan help to ensure that students are mastering the material.\nFor language learning, teachers of language classes can\nuse large language models in an assistive way, e.g., to high-\nlight important phrases, generate summaries and translations,\nprovide explanations of grammar and vocabulary, suggest\ngrammatical or style improvements and assist in conversation\npractice. Language models can also provide teachers with\nadaptive and personalized means to assist students in their\nlanguage learning journey, which can make language learning\nmore engaging and effective for students.\nFor research and writing, large language models can\nassist teachers of university and high school classes to com-\nplete research and writing tasks (e.g., in seminar works, paper\nwriting, and feedback to students) more efficiently and effec-\ntively. The most basic help can happen at a syntactic level,\ni.e., identifying and correcting typos. At a semantic level,\nlarge language models can be used to highlight (potential)\ngrammatical inconsistencies and suggest adequate and person-\nalized improvement strategies. Going further, these models\ncan be used to identify possibilities for topic-specific style\nimprovement. They can also be used to generate summaries\nand outlines of challenging texts, which can help teachers and\nresearchers to highlight the main points of a text in a way\nthat is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        }
      ],
      "actions": [
        "Investigate the extent to which LLMs can independently contribute to decision-making processes in professional training, beyond generating prompts.",
        "Clarify the balance between LLM assistance and human-led development of decision-making and problem-solving skills in professional training."
      ]
    },
    {
      "id": "r0013",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0007",
      "claim_text": "LLMs can generate human-like text, answer questions, and perform tasks like translation and summarization, as demonstrated by models such as GPT-2 and GPT-3. (E6).",
      "summary": "The claim is supported by evidence that LLMs can generate human-like text, answer questions, and perform tasks like translation and summarization.",
      "detail": "Evidence E3 explicitly states that recent advancements like GPT-3 and ChatGPT have demonstrated state-of-the-art performance on a wide range of natural-language tasks, including translation, question answering, writing coherent essays, and computer programs. Evidence E2 also mentions that language models can generate summaries and translations, and assist teachers in creating lesson plans and activities. Evidence E5 highlights their ability to answer natural language questions across various domains and generate contextualized natural language texts and code. Evidence E1 mentions GPT-3's massive dataset and parameter count, implying its advanced capabilities. The claim specifically mentions GPT-2 and GPT-3, and the evidence supports their capabilities in these areas.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 0,
          "char_end": 2323,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 2/13 efficiently adapted to down-stream tasks or even other seem- ingly unrelated tasks (e.g., as in transfer learning) has been empirically observed and studied for various natural-language tasks [6], e.g., more recently in t...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 2/13\nefficiently adapted to down-stream tasks or even other seem-\ningly unrelated tasks (e.g., as in transfer learning) has been\nempirically observed and studied for various natural-language\ntasks [6], e.g., more recently in the context of generating\nsynthetic and yet realistic heterogeneous tabular data [7].\nRecent advancements also include GPT-3 [1] and Chat-\nGPT [8], which were trained on a much larger datasets, i.e.,\ntexts from a very large web corpus, and have demonstrated\nstate-of-the-art performance on a wide range of natural-language\ntasks ranging from translation to question answering, writ-\ning coherent essays, and computer programs. Additionally,\nextensive research has been conducted on fine-tuning these\nmodels on smaller datasets and applying transfer learning to\nnew problems. This allows for improved performance on\nspecific tasks with smaller amount of data.\nWhile large language models have made great strides in\nrecent years, there are still many limitations that need to be\naddressed. One major limitation is the lack of interpretabil-\nity, as it is difficult to understand the reasoning behind the\nmodel\u2019s predictions. There are ethical considerations, such\nas concerns about bias and the impact of these models, e.g.,\non employment, risks of misuse and inadequate or unethical\ndeployment, loss of integrity, and many more. Overall, large\nlanguage models will continue to push the boundaries of what\nis possible in natural language processing. However, there\nis still much work to be done in terms of addressing their\nlimitations and the related ethical considerations.\n1.1 Opportunities for Learning\nThe use of large language models in education has been iden-\ntified as a potential area of interest due to the diverse range of\napplications they offer. Through the utilization of these mod-\nels, opportunities for enhancement of learning and teaching\nexperiences may be possible for individuals at all levels of edu-\ncation, including primary, secondary, tertiary and professional\ndevelopment.\nFor elementary school students, large language models\ncan assist in the development of reading and writing skills\n(e.g., by suggesting syntactic and grammatical corrections), as\nwell as in the development of"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 1952,
          "char_end": 4293,
          "quote": "also as- sist teachers in the creation of (inclusive) lesson plans and activities. Teachers can input to the models the corpus of document based on which they want to build a course. The output can be a course syllabus with short description of each topic. Language models can also generate questions and prompts that...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0001",
          "chunk_text": "also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at different\nknowledge and ability levels, and elicit critical thinking and\nproblem-solving. Moreover, they can be used to generate tar-\ngeted and personalized practice problems and quizzes, which\ncan help to ensure that students are mastering the material.\nFor language learning, teachers of language classes can\nuse large language models in an assistive way, e.g., to high-\nlight important phrases, generate summaries and translations,\nprovide explanations of grammar and vocabulary, suggest\ngrammatical or style improvements and assist in conversation\npractice. Language models can also provide teachers with\nadaptive and personalized means to assist students in their\nlanguage learning journey, which can make language learning\nmore engaging and effective for students.\nFor research and writing, large language models can\nassist teachers of university and high school classes to com-\nplete research and writing tasks (e.g., in seminar works, paper\nwriting, and feedback to students) more efficiently and effec-\ntively. The most basic help can happen at a syntactic level,\ni.e., identifying and correcting typos. At a semantic level,\nlarge language models can be used to highlight (potential)\ngrammatical inconsistencies and suggest adequate and person-\nalized improvement strategies. Going further, these models\ncan be used to identify possibilities for topic-specific style\nimprovement. They can also be used to generate summaries\nand outlines of challenging texts, which can help teachers and\nresearchers to highlight the main points of a text in a way\nthat is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 6,
          "char_start": 1977,
          "char_end": 4238,
          "quote": "users. Fur- thermore, their ability to answer natural language questions across various domains can facilitate the integration of diverse digital applications into a unified framework or application, which is also critical for expanding the bounds of educational possibilities and experiences [52, 49]. In general, th...",
          "chunk_id": "1-ChatGPT_for_Good:p0006:c0001",
          "chunk_text": "users. Fur-\nthermore, their ability to answer natural language questions\nacross various domains can facilitate the integration of diverse\ndigital applications into a unified framework or application,\nwhich is also critical for expanding the bounds of educational\npossibilities and experiences [52, 49].\nIn general, the ability of these models to generate contextu-\nalized natural language texts, code for various implementation\ntasks [53] as well as various types of multimedia content\n(e.g., in combination with other AI systems, such as DALL-\nE [54]) can enable and scale the creation of compelling and\nimmersive digital (e.g., AR/VR) experiences. From gamifica-\ntion to detailed simulations for immersive learning in digital\nenvironments, large language models are a key enabling tech-\nnology. To fully realize this potential, however, it is important\nto consider not only technical aspects but also ethical, legal,\necological and social implications.\nIn the following section, we take a brief look at the risks re-\nlated to the application on large language models in education\nand provide corresponding mitigation strategies.\n4. Key Challenges and Risks Related to\nthe Application of Large Language\nModels in Education\nCopyright Issues.\nWhen we train large language models on\na task to produce education-related content \u2013 course syllabus,\nquizzes, scientific paper \u2013 the mode should be trained on\nexamples of such texts. During the generation for a new\nprompt, the answer may contain a full sentence or even a\nparagraph seen in the training set, leading to copyright and\nplagiarism issues.\nImportant steps to responsibly mitigate such an issue can\nbe the following:\n\u2022 Asking the authors of the original documents trans-\nparently (i.e., purpose and policy of data usage) for\npermission to use their content for training the model\n\u2022 Compliance with copyright terms for open-source con-\ntent\n\u2022 Inheritance and detailed terms of use for the content\ngenerated by the model\n\u2022 Informing and raising awareness of the users about\nthese policies\nBias and fairness.\nLarge language models can perpetuate\nand amplify existing biases and unfairness in society, which\ncan negatively impact teaching and learning processes and\noutcomes. For example, if a model is trained"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 1857,
          "char_end": 4185,
          "quote": "feature being its ability to perform many NLP tasks with a single pre-training and fine-tuning pipeline. In parallel with Open AI and Google, Facebook AI devel- oped a large language model called RoBERTa (Robustly Opti- mized BERT Pre-training) [13], which was released in 2019. RoBERTa is a variant of the BERT model...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0001",
          "chunk_text": "feature\nbeing its ability to perform many NLP tasks with a single\npre-training and fine-tuning pipeline.\nIn parallel with Open AI and Google, Facebook AI devel-\noped a large language model called RoBERTa (Robustly Opti-\nmized BERT Pre-training) [13], which was released in 2019.\nRoBERTa is a variant of the BERT model which uses dynamic\nmasking instead of static masking during pre-training. Addi-\ntionally, RoBERTa is trained on a much larger dataset, and\nhence clearly outperformed BERT and other models such as\nGPT-2 and XLNet by the time of its release.\nCurrently, the most widely used and the largest available\nlanguage model is GPT-3, which was also pre-trained on a\nmassive text dataset (including books, articles, and websites,\namong other sources) and has 175 billion parameters. As all\nother previously described language models, GPT-3 uses a\ntransformer architecture, which allows it to efficiently process\nsequential data and generate more coherent and contextually\nadjusted text. Indeed, text generated by GPT-3 is almost\nindistinguishable from human-written text [14]. With the\nability to perform zero-shot learning, GPT-3 can cope with\ntasks it has not been specifically trained on, providing hence\nenormous opportunities for applications, from automation\n(summarizing, completing texts from bullet points), to dialog\nsystems, chatbots, and creative writing.\nJust recently, the BigScience-community developed and\nreleased the large language model BLOOM (BigScience Large\nOpen-science Open-access Multilingual Language Model) [15]\nas on open-source joint project by HuggingFace, GENCI and\nIDRIS3. The aim of this project was to provide a transparently\ntrained multi-lingual language model for the academic and\nnon-profit community. BLOOM is based on the same trans-\nformer architecture as the models from the GPT-family with\nonly minor structural changes, but the training data was explic-\nitly chosen to cover 46 natural languages and 13 programming\nlanguages, resulting in a data volume of 1.6TB.\n2.2 Review of Research Applying Large Language\nModels in Education\nIn the following, we provide an overview of research works\nemploying large language models in education that were pub-\nlished since the release of the first large language model in\n2018. These studies have been discussed in the following\naccording"
        }
      ],
      "actions": [
        "Confirm that GPT-2 and GPT-3 are indeed capable of the tasks mentioned in the claim based on the provided evidence.",
        "Identify if there are any limitations or nuances to these capabilities mentioned in the evidence."
      ]
    },
    {
      "id": "r0014",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0007",
      "claim_text": "LLMs can generate human-like text, answer questions, and perform tasks like translation and summarization, as demonstrated by models such as GPT-2 and GPT-3. (E6).",
      "summary": "While the claim focuses on the capabilities of LLMs, the evidence also points to challenges and limitations, particularly regarding fairness and access.",
      "detail": "Evidence E4 discusses the issue of unfair access to LLM-based educational technologies for non-English speaking users and the potential for financial means to access and maintain these models to widen the education gap. It calls for governmental organizations to ensure equitable access. Evidence E6, while a citation list, indirectly suggests that there are ongoing discussions and research into LLMs, which might include their limitations. The claim itself does not address these fairness and access issues, presenting a more optimistic view of LLM capabilities.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 1938,
          "char_end": 4252,
          "quote": "users, causing unfair access to such education technologies for non-English speaking users. Despite the efforts of various research communities to address multilingualism fairness for AI technologies, there is still much room for improvement. Lastly, the unfairness related to financial means for access- ing, trainin...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0001",
          "chunk_text": "users, causing unfair access to such education technologies\nfor non-English speaking users. Despite the efforts of various\nresearch communities to address multilingualism fairness for\nAI technologies, there is still much room for improvement.\nLastly, the unfairness related to financial means for access-\ning, training and maintaining large language models may need\nto be regulated by governmental organisations with the aim\nto provide equity-oriented means to all educational entities\ninterested in using these modern technologies. Without fair\naccess, this AI technology may seriously widen the education\ngap like no other technology before it.\nWe therefore conclude with UNESCO\u2019s call to ensure that\nAI does not widen the technological and educational divides\nwithin and between countries, and recommended important\nstrategies for the use of AI in a responsible and fair way to\nreduce this existing gap instead. According to the UNESCO\neducation 2030 Agenda [67]: \u201cUNESCO\u2019s mandate calls in-\nherently for a human-centred approach to AI. It aims to shift\nthe conversation to include AI\u2019s role in addressing current\ninequalities regarding access to knowledge, research and the\ndiversity of cultural expressions and to ensure AI does not\nwiden the technological divides within and between countries.\nThe promise of \u201cAI for all\u201d must be that everyone can take ad-\nvantage of the technological revolution under way and access\nits fruits, notably in terms of innovation and knowledge.\u201d\n6. Concluding Remarks\nThe use of large language models in education is a promising\narea of research that offers many opportunities to enhance the\nlearning experience for students and support the work of teach-\ners. However, to unleash their full potential for education, it is\ncrucial to approach the use of these models with caution and\nto critically evaluate their limitations and potential biases. In-\ntegrating large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 11,
          "char_start": 0,
          "char_end": 2629,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 11/13 in neural information processing systems, 33:1877\u20131901, 2020. [7] Vadim Borisov, Kathrin Se\u00dfler, Tobias Leemann, Mar- tin Pawelczyk, and Gjergji Kasneci. Language mod- els are realistic tabular data generators. arXiv pre...",
          "chunk_id": "1-ChatGPT_for_Good:p0011:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 11/13\nin neural information processing systems, 33:1877\u20131901,\n2020.\n[7] Vadim Borisov, Kathrin Se\u00dfler, Tobias Leemann, Mar-\ntin Pawelczyk, and Gjergji Kasneci.\nLanguage mod-\nels are realistic tabular data generators. arXiv preprint\narXiv:2210.06280, 2022.\n[8] OpenAI Team. ChatGPT: Optimizing language mod-\nels for dialogue.\nhttps://openai.com/blog/\nchatgpt/, November 2022. Accessed: 2023-01-19.\n[9] Tasmia\nAnsari\n(Analytics\nIndia\nMagazine).\nFreaky\nChatGPT\nfails\nthat\ncaught\nour\neyes!\nhttps://analyticsindiamag.com/freaky-\nchatgpt-fails-that-caught-our-eyes/,\nDec 2022. Accessed: 2023-01-22.\n[10] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya\nSutskever, et al. Improving language understanding by\ngenerative pre-training. 2018.\n[11] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell,\nRusslan Salakhutdinov, and Quoc V. Le. XLNet: Gen-\neralized Autoregressive Pretraining for Language Under-\nstanding. Advances in neural information processing\nsystems, 32, 2019.\n[12] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei\nLi, Peter J. Liu, et al. Exploring the limits of transfer\nlearning with a unified text-to-text transformer. Journal\nof Machine Learning Research, 21(140):1\u201367, 2020.\n[13] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke\nZettlemoyer, and Veselin Stoyanov. Roberta: A robustly\noptimized bert pretraining approach.\narXiv preprint\narXiv:1907.11692, 2019.\n[14] Elizabeth Clark, Tal August, Sofia Serrano, Nikita\nHaduong, Suchin Gururangan, and Noah A. Smith. All\nthat\u2019s \u2018human\u2019 is not gold: Evaluating human evaluation\nof generated text. In Proceedings of the 59th Annual\nMeeting of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natural\nLanguage Processing (Volume 1: Long Papers), pages\n7282\u20137296, Online, August 2021. Association for Com-\nputational Linguistics.\n[15] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie\nPavlick, Suzana Ili\u00b4c, Daniel Hesslow, Roman Castagn\u00b4e,\nAlexandra Sasha Luccioni, Franc\u00b8ois Yvon, Matthias\nGall\u00b4e, et al.\nBLOOM: A 176B-Parameter Open-\nAccess Multilingual Language Model. arXiv preprint\narXiv:2211.05100, 2022.\n[16] Ebrahim Gabajiwala, Priyav Mehta, Ritik Singh, and\nReeta Koshy. Quiz Maker: Automatic Quiz Generation\nfrom Text Using NLP. In Futuristic Trends in Networks\nand Computing Technologies, pages 523\u2013533, Singapore,\n2022. Springer.\n[17] Ramon Dijkstra, Z\u00a8ulk\u00a8uf Genc\u00b8, Subhradeep Kayal,\nand Jaap Kamps.\nReading"
        }
      ],
      "actions": [
        "Investigate further the specific 'freaky ChatGPT fails' mentioned in E6 to understand potential limitations or errors in LLM performance.",
        "Explore the extent to which the 'multilingualism fairness' and 'financial means' issues raised in E4 impact the general usability and accessibility of LLMs for the tasks listed in the claim."
      ]
    },
    {
      "id": "r0015",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0008",
      "claim_text": "LLMs are capable of automatically generating math word problems, requiring an understanding of equations and their contextualization. (E7).",
      "summary": "The claim that LLMs can automatically generate math word problems requiring contextual understanding is supported by evidence citing research in this area.",
      "detail": "The claim is directly supported by evidence snippets that reference research papers specifically focused on the generation of math word problems. These papers, cited as [45] and [46] in E2, address the improvement of math word problems with pre-trained knowledge and hierarchical reasoning, and the generation of math word problems with mathematical consistency and problem context constraints, respectively. This indicates that LLMs are indeed being developed and used for this purpose, implying the capability to understand equations and their contextualization.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 12,
          "char_start": 4257,
          "char_end": 5451,
          "quote": "Framework for Math Word Problems. In Find- ings of the Association for Computational Linguistics: EMNLP 2021, pages 2269\u20132279, 2021. [45] Weijiang Yu, Yingpeng Wen, Fudan Zheng, and Nong Xiao. Improving math word problems with pre-trained knowledge and hierarchical reasoning. In Proceedings of the 2021 Conference on...",
          "chunk_id": "1-ChatGPT_for_Good:p0012:c0002",
          "chunk_text": "Framework for Math Word Problems. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2021, pages 2269\u20132279, 2021.\n[45] Weijiang Yu, Yingpeng Wen, Fudan Zheng, and Nong\nXiao. Improving math word problems with pre-trained\nknowledge and hierarchical reasoning. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 3384\u20133394, 2021.\n[46] Zichao Wang, Andrew Lan, and Richard Baraniuk. Math\nword problem generation with mathematical consistency\nand problem context constraints. In Proceedings of the\n2021 Conference on Empirical Methods in Natural Lan-\nguage Processing, pages 5986\u20135999, 2021.\n[47] Ana\u00a8\u0131s Tack and Chris Piech. The AI Teacher Test: Mea-\nsuring the Pedagogical Ability of Blender and GPT-3 in\nEducational Dialogues. In Proceedings of the 15th Inter-\nnational Conference on Educational Data Mining, pages\n522\u2013529, Durham, United Kingdom, 2022. International\nEducational Data Mining Society.\n[48] Mario A Rojas-S\u00b4anchez, Pedro R Palos-S\u00b4anchez, and\nJos\u00b4e A Folgado-Fern\u00b4andez. Systematic literature review\nand bibliometric analysis on virtual reality and education.\nEducation and Information Technologies, pages 1\u201338,\n2022."
        }
      ],
      "actions": [
        "Confirm that the cited research papers ([45], [46]) demonstrate LLMs' ability to generate math word problems that require contextual understanding.",
        "Investigate the specific methodologies and results of these papers to understand the extent of LLMs' capabilities in this domain."
      ]
    },
    {
      "id": "r0016",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0008",
      "claim_text": "LLMs are capable of automatically generating math word problems, requiring an understanding of equations and their contextualization. (E7).",
      "summary": "While LLMs can generate exercises, their role in education should be complementary, not a replacement for human instruction.",
      "detail": "Evidence E1 mentions that LLMs can assist in the automatic generation of exercises, similar to how they can generate programming tasks and question-answer pairs. However, E4 strongly emphasizes that LLMs should be integrated into the curriculum as a complement to human instruction, not a replacement. It highlights that LLMs cannot replace the development of creativity, critical thinking, and problem-solving skills fostered by human teachers. Therefore, while LLMs can generate math word problems, their practical application in educational settings needs careful consideration to avoid over-reliance and to ensure they enhance, rather than diminish, the learning experience.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 5605,
          "char_end": 6603,
          "quote": "student answers in large courses, where grading effort could be reduced by up to 85% with a high precision and an improved quality perceived by the students. Large language models can not only support the assess- ment of student\u2019s solutions but also assist in the automatic generation of exercises. Using few-shot lea...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0003",
          "chunk_text": "student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is able to provide a variety of\nprogramming tasks together with the correct solution, auto-\nmated tests to verify the student\u2019s solutions, and additional\ncode explanations. With regard to testing factual knowledge\nin general, [41] proposed a framework to automatically gen-\nerate question-answer pairs. This can be used in the creation\nof teaching materials, e.g., for reading comprehension tasks.\nBeyond the generation of the correct answer, transformer\nmodels are also able to create distractor answers, as needed\nfor the generation of multiple choice questionnaires [42, 43].\nBringing language models to mathematics education, sev-"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        }
      ],
      "actions": [
        "Explore the limitations of LLM-generated math word problems in terms of fostering higher-order thinking skills.",
        "Examine best practices for integrating LLM-generated educational content into curricula to supplement, not supplant, human teaching."
      ]
    },
    {
      "id": "r0017",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0009",
      "claim_text": "Conversational agents, including models like Blender and GPT-3, can adequately respond to students in educational dialogues, generating conversational exchanges. (E7).",
      "summary": "The claim states LLMs can adequately respond to students in educational dialogues, but evidence suggests this is an area of ongoing research with open questions.",
      "detail": "The claim asserts that conversational agents like Blender and GPT-3 can adequately respond to students in educational dialogues. However, evidence suggests that while GPT-3 has demonstrated potential in supporting learning, for example, by explaining code snippets (E3), there are still 'several open research and pedagogical questions that need to be further explored' regarding its use in education (E3). Furthermore, the integration of LLMs into education requires careful consideration of privacy, security, ethical requirements, and ongoing human monitoring and guidance (E4). The adaptability of these models to individual student needs is also an area where improvements are expected with more advanced models (E5).",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 5697,
          "char_end": 6291,
          "quote": "to generate code explanations. Despite several open research and pedagogical questions that need to be further explored, this work has successfully demon- strated the potential of GPT-3 to support learning by explain- ing aspects of a given code snippet. For a data science course, Bhat et al. [20] proposed a pipelin...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0003",
          "chunk_text": "to generate code explanations.\nDespite several open research and pedagogical questions that\nneed to be further explored, this work has successfully demon-\nstrated the potential of GPT-3 to support learning by explain-\ning aspects of a given code snippet.\nFor a data science course, Bhat et al. [20] proposed a\npipeline for generating assessment questions based on a fine-\ntuned GPT3 model on text-based learning materials. The gen-\nerated questions were further evaluated with regard to their\nusefulness to the learning outcome based on automated label-\n3https://huggingface.co/bigscience/bloom"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 3836,
          "char_end": 5925,
          "quote": "large language models into education must therefore meet stringent privacy, security, and - for sustainable scal- ing - environmental, regulatory and ethical requirements, and must be done in conjunction with ongoing human monitoring, guidance, and critical thinking. While this position paper reflects the optimism o...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0002",
          "chunk_text": "large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in education, it also underscores\nthe need for further research to explore best practices for inte-\ngrating large language models into education and to mitigate\nthe risks identified.\nWe believe that despite many difficulties and challenges,\nthe discussed risks are manageable and should be addressed to\nprovide trustworthy and fair access to large language models\nfor education. Towards this goal, the mitigation strategies\nproposed in this position paper could serve as a starting point.\nReferences\n[1] Luciano Floridi and Massimo Chiriatti. GPT-3: Its nature,\nscope, limits, and consequences. Minds and Machines,\n30(4):681\u2013694, 2020.\n[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. BERT: Pre-training of Deep Bidirec-\ntional Transformers for Language Understanding. arXiv\npreprint arXiv:1810.04805, 2018.\n[3] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Met-\nzler. Efficient transformers: A survey. ACM Computing\nSurveys, 55(6):1\u201328, 2022.\n[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. Advances\nin neural information processing systems, 30, 2017.\n[5] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben\nVeyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre,\nIlana Heinz, and Dan Roth. Recent advances in natural\nlanguage processing via large pre-trained language mod-\nels: A survey. arXiv preprint arXiv:2111.01243, 2021.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-\nbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\net al. Language models are few-shot learners. Advances"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 9,
          "char_start": 3895,
          "char_end": 5102,
          "quote": "ogy, but it is conceivable that with more advanced models, the adaptability will increase. More specifically, a sensible mitigation strategy would be comprised of: \u2022 Use of adaptive learning technologies to personalize the output of the model to the needs of individual students by using student data (e.g., about lea...",
          "chunk_id": "1-ChatGPT_for_Good:p0009:c0002",
          "chunk_text": "ogy, but it is conceivable that with more advanced models, the\nadaptability will increase.\nMore specifically, a sensible mitigation strategy would be\ncomprised of:\n\u2022 Use of adaptive learning technologies to personalize the\noutput of the model to the needs of individual students\nby using student data (e.g., about learning style, prior\nknowledge, and performance, etc.)\n\u2022 Customization of the language model\u2019s output to align\nwith the teaching style and curriculum (by using data\nprovided by the teacher)\n\u2022 Use of multi-modal learning and teaching approaches,\nwhich combine text, audio, video, and experimentation\nto provide a more engaging and personalized experience\nfor students and teachers\n\u2022 Use of hybrid approaches, which combine the strengths\nof both human teachers and language models to gener-\nate targeted and personalized learning materials (based\non feedback, guidance, and support provided by the\nteachers)\n\u2022 Regular review of the model and continual improve-\nment for curriculum-related uses cases to ensure ade-\nquate and accurate functioning for education purposes\n\u2022 Research and development to create more advanced\nmodels that can better adapt to the diverse needs of\nstudents and teachers"
        }
      ],
      "actions": [
        "Investigate specific examples of educational dialogues where LLMs have been used and evaluated for adequacy.",
        "Research the 'open research and pedagogical questions' mentioned in E3 to understand the limitations of current LLM capabilities in educational dialogues.",
        "Explore the 'best practices for integrating large language models into education' and how they address the 'difficulties and challenges' mentioned in E4."
      ]
    },
    {
      "id": "r0018",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0009",
      "claim_text": "Conversational agents, including models like Blender and GPT-3, can adequately respond to students in educational dialogues, generating conversational exchanges. (E7).",
      "summary": "While LLMs can generate content for education, their role in direct student interaction for dialogue is not definitively established as 'adequate' across all contexts.",
      "detail": "The evidence highlights LLMs' capabilities in generating content relevant to education, such as assessment questions (E3) and potentially teaching content (E2). It also mentions GPT-3 being used for 'training children\u2019s curious question-asking skills' (E1), which implies some form of interaction. However, the claim's assertion of 'adequately respond to students in educational dialogues' is not directly supported by a definitive statement of adequacy in the provided snippets. Instead, the focus is on potential, ongoing research, and the need for careful integration and human oversight (E4, E5). The evidence also points to teachers' attitudes towards chatbots, where ease of use and usefulness contribute to acceptance (E2), suggesting that the perception of adequacy might be linked to these factors.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 11,
          "char_start": 2184,
          "char_end": 4766,
          "quote": "Yvon, Matthias Gall\u00b4e, et al. BLOOM: A 176B-Parameter Open- Access Multilingual Language Model. arXiv preprint arXiv:2211.05100, 2022. [16] Ebrahim Gabajiwala, Priyav Mehta, Ritik Singh, and Reeta Koshy. Quiz Maker: Automatic Quiz Generation from Text Using NLP. In Futuristic Trends in Networks and Computing Technol...",
          "chunk_id": "1-ChatGPT_for_Good:p0011:c0001",
          "chunk_text": "Yvon, Matthias\nGall\u00b4e, et al.\nBLOOM: A 176B-Parameter Open-\nAccess Multilingual Language Model. arXiv preprint\narXiv:2211.05100, 2022.\n[16] Ebrahim Gabajiwala, Priyav Mehta, Ritik Singh, and\nReeta Koshy. Quiz Maker: Automatic Quiz Generation\nfrom Text Using NLP. In Futuristic Trends in Networks\nand Computing Technologies, pages 523\u2013533, Singapore,\n2022. Springer.\n[17] Ramon Dijkstra, Z\u00a8ulk\u00a8uf Genc\u00b8, Subhradeep Kayal,\nand Jaap Kamps.\nReading Comprehension Quiz\nGeneration\nusing\nGenerative\nPre-trained\nTrans-\nformers.\nhttps://e.humanities.uva.nl/\npublications/2022/dijk_read22.pdf,\n2022.\n[18] Rania Abdelghani, Yen-Hsiang Wang, Xingdi Yuan, Tong\nWang, H\u00b4el`ene Sauz\u00b4eon, and Pierre-Yves Oudeyer. GPT-3-\ndriven pedagogical agents for training children\u2019s curious\nquestion-asking skills. arXiv preprint arXiv:2211.14228,\n2022.\n[19] Stephen MacNeil, Andrew Tran, Dan Mogil, Seth Bern-\nstein, Erin Ross, and Ziheng Huang. Generating Diverse\nCode Explanations Using the GPT-3 Large Language\nModel. In Proceedings of the 2022 ACM Conference on\nInternational Computing Education Research - Volume\n2, ICER \u201922, page 37\u201339, New York, NY, USA, 2022.\nAssociation for Computing Machinery.\n[20] Shravya Bhat, Huy A. Nguyen, Steven Moore, John Stam-\nper, Majd Sakr, and Eric Nyberg. Towards Automated\nGeneration and Evaluation of Questions in Educational\nDomains. In Proceedings of the 15th International Con-\nference on Educational Data Mining, pages 701\u2013704,\nDurham, United Kingdom, 2022. International Educa-\ntional Data Mining Society.\n[21] Qinjin Jia, Jialin Cui, Yunkai Xiao, Chengyuan Liu,\nParvez Rashid, and Edward F. Gehringer. ALL-IN-ONE:\nMulti-Task Learning BERT models for Evaluating Peer\nAssessments. International Educational Data Mining\nSociety, 2021.\n[22] Hyangeun Ji, Insook Han, and Yujung Ko. A systematic\nreview of conversational ai in language education: focus-\ning on the collaboration with human teachers. Journal of\nResearch on Technology in Education, pages 1\u201316, 2022.\n[23] Reham El Shazly. Effects of artificial intelligence on\nenglish speaking anxiety and speaking performance: A\ncase study. Expert Systems, 38(3):e12667, 2021.\n[24] Minhui Bao.\nCan home use of speech-enabled ar-\ntificial intelligence mitigate foreign language anxiety\u2013\ninvestigation of a concept. Arab World English Journal\n(AWEJ) Special Issue on CALL, (5), 2019.\n[25] Tzu-Yu Tai and Howard Hao-Jan Chen. The impact of\ngoogle assistant on adolescent efl learners\u2019 willingness to\ncommunicate. Interactive Learning Environments, pages\n1\u201318, 2020.\n[26] Jaeho Jeon. Chatbot-assisted dynamic assessment"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 3704,
          "char_end": 5972,
          "quote": "teachers attitudes towards chatbots in education were reported in [34]: perceiving the AI chatbot as easy-to- use and useful leads to greater acceptance of the chatbot. As for the chatbots\u2019 features, formal language by a chatbot leads to a higher intention of using it. As it seems that teachers\u2019 perspectives on the ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0002",
          "chunk_text": "teachers attitudes towards chatbots in education\nwere reported in [34]: perceiving the AI chatbot as easy-to-\nuse and useful leads to greater acceptance of the chatbot. As\nfor the chatbots\u2019 features, formal language by a chatbot leads\nto a higher intention of using it.\nAs it seems that teachers\u2019 perspectives on the general use\nof AI in education have a lot in common with the mentioned at-\ntitude towards chatbots in particular, a responsible integration\nof AI into education by involving the expertise of different\ncommunities is crucial [35].\nRecent works addressing the use of large language models\nfrom the teacher\u2019s perspective have focused on the automated\nassessment of student answers, adaptive feedback, and the\ngeneration of teaching content.\nFor example, a recent work by Moore et al. [36] employed\na fine-tuned GPT-3 model to evaluate student-generated an-\nswers in a learning environment for chemistry education [36].\nThe authors argue that large language models might (espe-\ncially when fine-tuned to the specific domain) be a powerful\ntool to assist teachers in the quality and pedagogical evalua-\ntion of student answers [36]. In addition, the following studies\nexamined NLP-based models for generating automatic adap-\ntive feedback: Zhu et al. [37] examined an AI-based feedback\nsystem incorporating automated scoring technologies in the\ncontext of a high school climate activity task. The results show\nthat the feedback helped students revise their scientific argu-\nments. Sailer et al. [38] used NLP-based adaptive feedback\nin the context of diagnosing students\u2019 learning difficulties in\nteacher education. In their experimental study, they found that\npre-service teachers who received adaptive feedback were\nbetter able to justify their diagnoses than prospective teachers\nwho received static feedback. Bernius et al. [39] used NLP-\nbased models to generate feedback for textual student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 5697,
          "char_end": 6291,
          "quote": "to generate code explanations. Despite several open research and pedagogical questions that need to be further explored, this work has successfully demon- strated the potential of GPT-3 to support learning by explain- ing aspects of a given code snippet. For a data science course, Bhat et al. [20] proposed a pipelin...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0003",
          "chunk_text": "to generate code explanations.\nDespite several open research and pedagogical questions that\nneed to be further explored, this work has successfully demon-\nstrated the potential of GPT-3 to support learning by explain-\ning aspects of a given code snippet.\nFor a data science course, Bhat et al. [20] proposed a\npipeline for generating assessment questions based on a fine-\ntuned GPT3 model on text-based learning materials. The gen-\nerated questions were further evaluated with regard to their\nusefulness to the learning outcome based on automated label-\n3https://huggingface.co/bigscience/bloom"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 3836,
          "char_end": 5925,
          "quote": "large language models into education must therefore meet stringent privacy, security, and - for sustainable scal- ing - environmental, regulatory and ethical requirements, and must be done in conjunction with ongoing human monitoring, guidance, and critical thinking. While this position paper reflects the optimism o...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0002",
          "chunk_text": "large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in education, it also underscores\nthe need for further research to explore best practices for inte-\ngrating large language models into education and to mitigate\nthe risks identified.\nWe believe that despite many difficulties and challenges,\nthe discussed risks are manageable and should be addressed to\nprovide trustworthy and fair access to large language models\nfor education. Towards this goal, the mitigation strategies\nproposed in this position paper could serve as a starting point.\nReferences\n[1] Luciano Floridi and Massimo Chiriatti. GPT-3: Its nature,\nscope, limits, and consequences. Minds and Machines,\n30(4):681\u2013694, 2020.\n[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. BERT: Pre-training of Deep Bidirec-\ntional Transformers for Language Understanding. arXiv\npreprint arXiv:1810.04805, 2018.\n[3] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Met-\nzler. Efficient transformers: A survey. ACM Computing\nSurveys, 55(6):1\u201328, 2022.\n[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. Advances\nin neural information processing systems, 30, 2017.\n[5] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben\nVeyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre,\nIlana Heinz, and Dan Roth. Recent advances in natural\nlanguage processing via large pre-trained language mod-\nels: A survey. arXiv preprint arXiv:2111.01243, 2021.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-\nbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\net al. Language models are few-shot learners. Advances"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 9,
          "char_start": 3895,
          "char_end": 5102,
          "quote": "ogy, but it is conceivable that with more advanced models, the adaptability will increase. More specifically, a sensible mitigation strategy would be comprised of: \u2022 Use of adaptive learning technologies to personalize the output of the model to the needs of individual students by using student data (e.g., about lea...",
          "chunk_id": "1-ChatGPT_for_Good:p0009:c0002",
          "chunk_text": "ogy, but it is conceivable that with more advanced models, the\nadaptability will increase.\nMore specifically, a sensible mitigation strategy would be\ncomprised of:\n\u2022 Use of adaptive learning technologies to personalize the\noutput of the model to the needs of individual students\nby using student data (e.g., about learning style, prior\nknowledge, and performance, etc.)\n\u2022 Customization of the language model\u2019s output to align\nwith the teaching style and curriculum (by using data\nprovided by the teacher)\n\u2022 Use of multi-modal learning and teaching approaches,\nwhich combine text, audio, video, and experimentation\nto provide a more engaging and personalized experience\nfor students and teachers\n\u2022 Use of hybrid approaches, which combine the strengths\nof both human teachers and language models to gener-\nate targeted and personalized learning materials (based\non feedback, guidance, and support provided by the\nteachers)\n\u2022 Regular review of the model and continual improve-\nment for curriculum-related uses cases to ensure ade-\nquate and accurate functioning for education purposes\n\u2022 Research and development to create more advanced\nmodels that can better adapt to the diverse needs of\nstudents and teachers"
        }
      ],
      "actions": [
        "Seek evidence that directly evaluates the adequacy of LLM-generated responses in educational dialogues based on student learning outcomes or engagement.",
        "Examine the specific types of educational dialogues LLMs are being used for and compare them to the broad claim of 'adequately respond'.",
        "Investigate the criteria used to define 'adequately respond' in the context of educational dialogues."
      ]
    },
    {
      "id": "r0019",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0010",
      "claim_text": "LLMs can help elementary school students develop reading and writing skills through syntactic and grammatical corrections, and foster writing style and critical thinking. (E8).",
      "summary": "LLMs can support elementary students in developing reading and writing skills, and foster critical thinking, but their use needs careful integration to avoid over-reliance.",
      "detail": "The claim states that LLMs can help elementary school students develop reading and writing skills through syntactic and grammatical corrections, and foster writing style and critical thinking. Evidence E1 and E3 support the idea that LLMs can assist in writing by organizing thoughts and providing editing assistance. E2 and E3 mention that LLMs can generate questions and prompts that elicit critical thinking. However, E4 and E5 highlight a significant limitation: LLMs should complement, not replace, human instruction, as over-reliance can negatively impact students' creativity, critical thinking, and problem-solving skills by simplifying information acquisition and potentially fostering laziness.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 3858,
          "char_end": 6173,
          "quote": "a text and to organize their thoughts for writing. Additionally, large language models can also assist in the development of research skills by providing students with information and re- sources on a particular topic and hinting at unexplored aspects and current research topics, which can help them to better unders...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0002",
          "chunk_text": "a\ntext and to organize their thoughts for writing. Additionally,\nlarge language models can also assist in the development of\nresearch skills by providing students with information and re-\nsources on a particular topic and hinting at unexplored aspects\nand current research topics, which can help them to better\nunderstand and analyze the material.\nFor group & remote learning, large language models\ncan be used to facilitate group discussions and debates by\nproviding a discussion structure, real-time feedback and per-\nsonalized guidance to students during the discussion. This\ncan help to improve student engagement and participation. In\ncollaborative writing activities, where multiple students work\ntogether to write a document or a project, language models\ncan assist by providing style and editing suggestions as well\nas other integrative co-writing features. For research purposes,\nsuch models can be used to span the range of open research\nquestions in relation to already researched topics and to au-\ntomatically assign the questions and topics to the involved\nteam members. For remote tutoring purposes, they can be\nused to automatically generate questions and provide practice\nproblems, explanations, and assessments that are tailored to\nthe students\u2019 level of knowledge so that they can learn at their\nown pace.\nTo empower learners with disabilities, large language\nmodels can be used in combination with speech-to-text or text-\nto-speech solutions to help people with visual impairment. In\ncombination with the previously mentioned group and remote\ntutoring opportunities, language models can be used to de-\nvelop inclusive learning strategies with adequate support in\ntasks such as adaptive writing, translating, and highlighting\nof important content in various formats. However, it is im-\nportant to note that the use of large language models should\nbe accompanied by the help of professionals such as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 1952,
          "char_end": 4293,
          "quote": "also as- sist teachers in the creation of (inclusive) lesson plans and activities. Teachers can input to the models the corpus of document based on which they want to build a course. The output can be a course syllabus with short description of each topic. Language models can also generate questions and prompts that...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0001",
          "chunk_text": "also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at different\nknowledge and ability levels, and elicit critical thinking and\nproblem-solving. Moreover, they can be used to generate tar-\ngeted and personalized practice problems and quizzes, which\ncan help to ensure that students are mastering the material.\nFor language learning, teachers of language classes can\nuse large language models in an assistive way, e.g., to high-\nlight important phrases, generate summaries and translations,\nprovide explanations of grammar and vocabulary, suggest\ngrammatical or style improvements and assist in conversation\npractice. Language models can also provide teachers with\nadaptive and personalized means to assist students in their\nlanguage learning journey, which can make language learning\nmore engaging and effective for students.\nFor research and writing, large language models can\nassist teachers of university and high school classes to com-\nplete research and writing tasks (e.g., in seminar works, paper\nwriting, and feedback to students) more efficiently and effec-\ntively. The most basic help can happen at a syntactic level,\ni.e., identifying and correcting typos. At a semantic level,\nlarge language models can be used to highlight (potential)\ngrammatical inconsistencies and suggest adequate and person-\nalized improvement strategies. Going further, these models\ncan be used to identify possibilities for topic-specific style\nimprovement. They can also be used to generate summaries\nand outlines of challenging texts, which can help teachers and\nresearchers to highlight the main points of a text in a way\nthat is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 0,
          "char_end": 2311,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 3/13 They can also generate questions and prompts that encourage learners to think critically about their work and to analyze and interpret the information presented to them. In conclusion, large language models have the poten...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 3/13\nThey can also generate questions and prompts that encourage\nlearners to think critically about their work and to analyze and\ninterpret the information presented to them.\nIn conclusion, large language models have the potential to\nprovide a wide range of benefits and opportunities for students\nand professionals at all stages of education. They can assist\nin the development of reading, writing, math, science, and\nlanguage skills, as well as providing students with personal-\nized practice materials, summaries and explanations, which\ncan help to improve student performance and contribute to en-\nhanced learning experiences. Additionally, large language\nmodels can also assist in research, writing, and problem-\nsolving tasks, and provide domain-specific language skills\nand other skills for professional training. However, as pre-\nviously mentioned, the use of these models should be done\nwith caution, as they also have limitations such as lack of\ninterpretability and potential for bias, unexpected brittleness\nin relatively simple tasks [9] which need to be addressed.\n1.2 Opportunities for Teaching\nLarge language models, such as ChatGPT, have the potential\nto revolutionize teaching and assist in teaching processes.\nBelow we provide only a few examples of how these models\ncan benefit teachers:\nFor personalized learning, teachers can use large lan-\nguage models to create personalized learning experiences for\ntheir students. These models can analyze student\u2019s writing\nand responses, and provide tailored feedback and suggest ma-\nterials that align with the student\u2019s specific learning needs.\nSuch support can save teachers\u2019 time and effort in creating\npersonalized materials and feedback, and also allow them to\nfocus on other aspects of teaching, such as creating engaging\nand interactive lessons.\nFor lesson planning, large language models can also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 0,
          "char_end": 2297,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13 \u2022 Professional training and resources to educators on how to recognize and address potential biases and other fail- ures in the model\u2019s output \u2022 Continuous updates of the model with diverse, unbiased data, and supervision...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13\n\u2022 Professional training and resources to educators on how\nto recognize and address potential biases and other fail-\nures in the model\u2019s output\n\u2022 Continuous updates of the model with diverse, unbiased\ndata, and supervision of human experts to review the\nresults\nLearners may rely too heavily on the model.\nThe effort-\nlessly generated information could negatively impact their\ncritical thinking and problem-solving skills. This is because\nthe model simplifies the acquisition of answers or informa-\ntion, which can amplify laziness and counteract the learners\u2019\ninterest to conduct their own investigations and come to their\nown conclusions or solutions.\nTo encounter this risk, it is important to be aware of the\nlimitations of large language models and use them only as\na tool to support and enhance learning [55], rather than as\na replacement for human authorities and other authoritative\nsources. Thus a responsible mitigation strategy would focus\non the following key aspects:\n\u2022 Raising awareness of the limitations and unexpected\nbrittleness of large language models and AI systems in\ngeneral (i.e., experimenting with the model to build an\nown understanding of the workings and limitations)\n\u2022 Using language models to generate hypotheses and ex-\nplore different perspectives, rather than just to generate\nanswers\n\u2022 Strategies to use other educational resources (e.g., books,\narticles) and other authoritative sources to evaluate and\ncorroborate the factual correctness of the information\nprovided by the model (i.e., encouraging learners to\nquestion the generated content)\n\u2022 Incorporating critical thinking and problem-solving ac-\ntivities into the curriculum, to help students develop\nthese skills\n\u2022 Incorporating human expertise and teachers to review,\nvalidate and explain the information provided by the\nmodel\nIt is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand"
        }
      ],
      "actions": [
        "Investigate specific examples of how LLMs provide syntactic and grammatical corrections for elementary students.",
        "Explore how LLMs foster writing style and critical thinking in elementary students, beyond just generating prompts.",
        "Examine the balance between LLM assistance and the development of independent critical thinking and problem-solving skills in young learners."
      ]
    },
    {
      "id": "r0020",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0011",
      "claim_text": "LLMs can provide teachers with resources, summaries, and explanations of new teaching methodologies and technologies, helping them stay current in their field. (E9).",
      "summary": "The claim is partially supported, as LLMs can assist teachers with lesson planning and content creation, but direct evidence for providing resources on new teaching methodologies is limited.",
      "detail": "The provided evidence snippets extensively detail how LLMs can assist teachers in creating lesson plans, generating activities, and personalizing content for students (E1, E2). They can also help with assessment and professional development (E2). However, none of the snippets explicitly state that LLMs provide teachers with summaries and explanations of *new teaching methodologies and technologies* to help them stay current in their field, which is the specific assertion in the claim. The evidence focuses more on the *application* of LLMs in teaching rather than LLMs acting as a resource for teachers to learn about new pedagogical approaches.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 1952,
          "char_end": 4293,
          "quote": "also as- sist teachers in the creation of (inclusive) lesson plans and activities. Teachers can input to the models the corpus of document based on which they want to build a course. The output can be a course syllabus with short description of each topic. Language models can also generate questions and prompts that...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0001",
          "chunk_text": "also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at different\nknowledge and ability levels, and elicit critical thinking and\nproblem-solving. Moreover, they can be used to generate tar-\ngeted and personalized practice problems and quizzes, which\ncan help to ensure that students are mastering the material.\nFor language learning, teachers of language classes can\nuse large language models in an assistive way, e.g., to high-\nlight important phrases, generate summaries and translations,\nprovide explanations of grammar and vocabulary, suggest\ngrammatical or style improvements and assist in conversation\npractice. Language models can also provide teachers with\nadaptive and personalized means to assist students in their\nlanguage learning journey, which can make language learning\nmore engaging and effective for students.\nFor research and writing, large language models can\nassist teachers of university and high school classes to com-\nplete research and writing tasks (e.g., in seminar works, paper\nwriting, and feedback to students) more efficiently and effec-\ntively. The most basic help can happen at a syntactic level,\ni.e., identifying and correcting typos. At a semantic level,\nlarge language models can be used to highlight (potential)\ngrammatical inconsistencies and suggest adequate and person-\nalized improvement strategies. Going further, these models\ncan be used to identify possibilities for topic-specific style\nimprovement. They can also be used to generate summaries\nand outlines of challenging texts, which can help teachers and\nresearchers to highlight the main points of a text in a way\nthat is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 5792,
          "char_end": 6400,
          "quote": "acquaint students early on with potential societal biases, and risks of AI application. In conclusion, large language models have the potential to revolutionize teaching from a teacher\u2019s perspective by pro- viding teachers with a wide range of tools and resources that can assist with lesson planning, personalized co...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0003",
          "chunk_text": "acquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language models\nhave the potential to be a powerful tool in education, and\nthere are a number of ongoing research efforts exploring its\npotential applications in this area."
        }
      ],
      "actions": [
        "Seek evidence that directly addresses LLMs as a source of information for teachers on emerging teaching methodologies and technologies.",
        "Clarify if 'professional development' (E2) implicitly includes learning about new methodologies, or if it refers to other aspects of teacher growth."
      ]
    },
    {
      "id": "r0021",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0011",
      "claim_text": "LLMs can provide teachers with resources, summaries, and explanations of new teaching methodologies and technologies, helping them stay current in their field. (E9).",
      "summary": "Over-reliance on LLMs by teachers is a significant risk that needs mitigation.",
      "detail": "Evidence highlights that teachers may become too reliant on LLMs, potentially diminishing the development of their own creativity, critical thinking, and problem-solving skills (E4). The integration of LLMs should complement and enhance learning experiences rather than replace human instruction (E4). This suggests a limitation in the uncritical adoption of LLMs for all teaching tasks, including staying current, as it could lead to a passive approach rather than active engagement with new ideas.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 3847,
          "char_end": 5202,
          "quote": "in their teaching [56]. This particularly applies to the use and integration of large language models into teaching practice. Educational theory has long since suggested ways of integrating novel tools into educational practice (e.g., [57]). As with any other technological innovation, integrating large language mode...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0002",
          "chunk_text": "in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to effectively use\nthem to supplement or enhance specific learning processes.\nThere are several ways to address these challenges and\nencounter this risk:\n\u2022 Research on the challenges of large language models in\neducation by investigating existing educational models\nof technology integration, students\u2019 learning processes\nand transfer them to the context of large language mod-\nels, as well as developing a new educational theory\nspecifically for the context of large language models\n\u2022 Assessing the needs of the educators and students and\nprovide case-based guidance (e.g., for the secure ethical\nuse of large language models in education scenarios)\n\u2022 Demand-oriented Training and professional develop-\nment opportunities for educators and institutions to\nlearn about the capabilities and potential uses of large\nlanguage models in education, as well as providing\nbest practices for integrating them into their teaching\nmethods"
        }
      ],
      "actions": [
        "Investigate strategies and research mentioned in the evidence for mitigating teacher over-reliance on LLMs.",
        "Explore how the 'limitations' of LLMs (E5) might specifically impact their utility in helping teachers stay current with rapidly evolving fields."
      ]
    },
    {
      "id": "r0022",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0012",
      "claim_text": "LLMs can be used to generate assessment questions for courses, with generated questions being rated favorably by human experts for their usefulness in learning. (E10, E24).",
      "summary": "LLMs can generate assessment questions, and human experts have found them useful for learning.",
      "detail": "The claim states that LLMs can be used to generate assessment questions for courses, and that these generated questions have been rated favorably by human experts for their usefulness in learning. Evidence snippets E1 and E2 directly support this claim by mentioning the generation of exercises and question-answer pairs, and E1 specifically references a study assessing the quality of student-generated short answer questions using GPT-3, implying a focus on question generation and evaluation.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 12,
          "char_start": 2131,
          "char_end": 4678,
          "quote": "and John Stamper. Assessing the Quality of Student-Generated Short Answer Questions Using GPT- 3. In Educating for a New Future: Making Sense of Technology-Enhanced Learning Adoption: 17th Euro- pean Conference on Technology Enhanced Learning, EC- TEL 2022, Toulouse, France, September 12\u201316, 2022, Proceedings, pages...",
          "chunk_id": "1-ChatGPT_for_Good:p0012:c0001",
          "chunk_text": "and John Stamper. Assessing the Quality of\nStudent-Generated Short Answer Questions Using GPT-\n3. In Educating for a New Future: Making Sense of\nTechnology-Enhanced Learning Adoption: 17th Euro-\npean Conference on Technology Enhanced Learning, EC-\nTEL 2022, Toulouse, France, September 12\u201316, 2022,\nProceedings, pages 243\u2013257. Springer, 2022.\n[37] Hee-Sun Lee Mengxiao Zhu, Ou Lydia Liu. The effect\nof automated feedback on revision behavior and learn-\ning gains in formative assessment of scientific argument\nwriting. Computers & Education, 143:103668, 2020.\n[38] Michael Sailer, Elisabeth Bauer, Riikka Hofmann, Jan\nKiesewetter, Julia Glas, Iryna Gurevych, and Frank Fis-\ncher. Adaptive feedback from artificial neural networks\nfacilitates pre-service teachers\u2019 diagnostic reasoning in\nsimulation-based learning.\nLearning and Instruction,\n83:101620, 2023.\n[39] Jan Philip Bernius, Stephan Krusche, and Bernd Bruegge.\nMachine learning based feedback on textual student an-\nswers in large courses. Computers and Education: Artifi-\ncial Intelligence, 3, 2022.\n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen.\nAutomatic generation of programming exercises and code\nexplanations using large language models. In Proceed-\nings of the 2022 ACM Conference on International Com-\nputing Education Research-Volume 1, pages 27\u201343, 2022.\n[41] Fanyi Qu, Xin Jia, and Yunfang Wu.\nAsking Ques-\ntions Like Educational Experts: Automatically Gener-\nating Question-Answer Pairs on Real-World Examination\nData. In Proceedings of the 2021 Conference on Em-\npirical Methods in Natural Language Processing, pages\n2583\u20132593, 2021.\n[42] Ricardo Rodriguez-Torrealba, Eva Garcia-Lopez, and An-\ntonio Garcia-Cabot. End-to-end generation of multiple-\nchoice questions using text-to-text transfer transformer\nmodels. Expert Systems with Applications, 208:118258,\n2022.\n[43] Vatsal Raina and Mark Gales. Multiple-Choice Question\nGeneration: Towards an Automated Assessment Frame-\nwork. arXiv preprint arXiv:2209.11830, 2022.\n[44] Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin\nJiang, Ming Zhang, and Qun Liu. Generate & Rank: A\nMulti-task Framework for Math Word Problems. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2021, pages 2269\u20132279, 2021.\n[45] Weijiang Yu, Yingpeng Wen, Fudan Zheng, and Nong\nXiao. Improving math word problems with pre-trained\nknowledge and hierarchical reasoning. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 3384\u20133394, 2021.\n[46] Zichao Wang, Andrew Lan,"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 5605,
          "char_end": 6603,
          "quote": "student answers in large courses, where grading effort could be reduced by up to 85% with a high precision and an improved quality perceived by the students. Large language models can not only support the assess- ment of student\u2019s solutions but also assist in the automatic generation of exercises. Using few-shot lea...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0003",
          "chunk_text": "student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is able to provide a variety of\nprogramming tasks together with the correct solution, auto-\nmated tests to verify the student\u2019s solutions, and additional\ncode explanations. With regard to testing factual knowledge\nin general, [41] proposed a framework to automatically gen-\nerate question-answer pairs. This can be used in the creation\nof teaching materials, e.g., for reading comprehension tasks.\nBeyond the generation of the correct answer, transformer\nmodels are also able to create distractor answers, as needed\nfor the generation of multiple choice questionnaires [42, 43].\nBringing language models to mathematics education, sev-"
        }
      ],
      "actions": [
        "Confirm the specific findings of the study mentioned in E1 regarding expert ratings of generated questions.",
        "Investigate if E2 provides details on the types of assessment questions generated and the criteria used for evaluation."
      ]
    },
    {
      "id": "r0023",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0012",
      "claim_text": "LLMs can be used to generate assessment questions for courses, with generated questions being rated favorably by human experts for their usefulness in learning. (E10, E24).",
      "summary": "While LLMs can generate assessment questions, their integration should supplement, not replace, human instruction.",
      "detail": "The claim focuses on the positive aspect of LLMs generating assessment questions. However, evidence snippet E4 introduces a crucial limitation: LLMs should be used as a complementary supplement to the generation of instructions and should not replace human instruction. This is because LLMs cannot replicate the creativity, critical thinking, and problem-solving skills developed through human interaction. Therefore, while LLMs can assist in question generation, over-reliance on them could be detrimental to student development.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        }
      ],
      "actions": [
        "Explore the specific risks of teachers becoming too reliant on LLMs for assessment question generation.",
        "Identify strategies for integrating LLM-generated questions in a way that enhances, rather than replaces, human pedagogical input."
      ]
    },
    {
      "id": "r0024",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0013",
      "claim_text": "LLMs can generate contextualized natural language texts and code for various implementation tasks, and in conjunction with other AI systems, can create multimedia content. (E11).",
      "summary": "LLMs can assist in educational tasks by generating lesson plans, practice problems, and providing feedback, but their ability to truly understand and help students is limited compared to human instructors.",
      "detail": "The evidence suggests that LLMs can be valuable tools in education, aiding teachers in creating lesson plans, generating personalized practice problems, and even facilitating group discussions. They can also assist in language learning by highlighting phrases, summarizing, and translating. However, E2 explicitly states that while models like Blender and GPT-3 can respond adequately to students and create dialogues that give the impression of understanding, they are 'well behind human performance when it comes to helping the student.' This highlights a significant limitation in their ability to provide genuine pedagogical support.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 1952,
          "char_end": 4293,
          "quote": "also as- sist teachers in the creation of (inclusive) lesson plans and activities. Teachers can input to the models the corpus of document based on which they want to build a course. The output can be a course syllabus with short description of each topic. Language models can also generate questions and prompts that...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0001",
          "chunk_text": "also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at different\nknowledge and ability levels, and elicit critical thinking and\nproblem-solving. Moreover, they can be used to generate tar-\ngeted and personalized practice problems and quizzes, which\ncan help to ensure that students are mastering the material.\nFor language learning, teachers of language classes can\nuse large language models in an assistive way, e.g., to high-\nlight important phrases, generate summaries and translations,\nprovide explanations of grammar and vocabulary, suggest\ngrammatical or style improvements and assist in conversation\npractice. Language models can also provide teachers with\nadaptive and personalized means to assist students in their\nlanguage learning journey, which can make language learning\nmore engaging and effective for students.\nFor research and writing, large language models can\nassist teachers of university and high school classes to com-\nplete research and writing tasks (e.g., in seminar works, paper\nwriting, and feedback to students) more efficiently and effec-\ntively. The most basic help can happen at a syntactic level,\ni.e., identifying and correcting typos. At a semantic level,\nlarge language models can be used to highlight (potential)\ngrammatical inconsistencies and suggest adequate and person-\nalized improvement strategies. Going further, these models\ncan be used to identify possibilities for topic-specific style\nimprovement. They can also be used to generate summaries\nand outlines of challenging texts, which can help teachers and\nresearchers to highlight the main points of a text in a way\nthat is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 6,
          "char_start": 0,
          "char_end": 2405,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 6/13 eral works discuss the automatic generation of math word problems [44, 45, 46], which combines the challenge of un- derstanding equations and putting them into the appropriate context. Finally, another recent work [47] in...",
          "chunk_id": "1-ChatGPT_for_Good:p0006:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 6/13\neral works discuss the automatic generation of math word\nproblems [44, 45, 46], which combines the challenge of un-\nderstanding equations and putting them into the appropriate\ncontext.\nFinally, another recent work [47] investigated the capabil-\nity of state-of-the-art conversational agents to adequately reply\nto a student in an educational dialogue. Both models used in\nthis work (Blender and GPT-3) were capable of replying to\na student adequately and generated conversational dialogues\nthat conveyed the impression that these models understand the\nlearner (in particular Blender). They are however well behind\nhuman performance when it comes to helping the student [47],\nthus emphasizing the need for further research.\n3. Opportunities for Innovative\nEducational Technologies\nLooking forward, large language models bear the potential to\nconsiderably improve digital ecosystems for education, such\nas environments based on Augmented Reality (AR), Virtual\nReality (VR) [48, 49], and other related digital experiences.\nSpecifically, they can be used to amplify several key fac-\ntors, which are crucial for the immersive interaction of users\nwith digital content. For example, large language models\ncan considerably improve the natural language processing\nand understanding capabilities of an AR/VR system to enable\nan effective natural communication and interaction between\nusers and the system (e.g., virtual teacher or virtual peers).\nThe latter has been identified early on as a key usability aspect\nfor immersive educational technologies [50] and is in general\nseen as a key factor for improving the interaction between\nhumans and AI systems [51].\nLarge language models can also be used to develop more\nnatural and sophisticated user interfaces by exploiting their\nability to generate contextualized, personalized, and diverse\nresponses to natural language questions asked by users. Fur-\nthermore, their ability to answer natural language questions\nacross various domains can facilitate the integration of diverse\ndigital applications into a unified framework or application,\nwhich is also critical for expanding the bounds of educational\npossibilities and experiences [52, 49].\nIn general, the ability of these models to generate contextu-\nalized natural language texts, code for various implementation"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 3858,
          "char_end": 6173,
          "quote": "a text and to organize their thoughts for writing. Additionally, large language models can also assist in the development of research skills by providing students with information and re- sources on a particular topic and hinting at unexplored aspects and current research topics, which can help them to better unders...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0002",
          "chunk_text": "a\ntext and to organize their thoughts for writing. Additionally,\nlarge language models can also assist in the development of\nresearch skills by providing students with information and re-\nsources on a particular topic and hinting at unexplored aspects\nand current research topics, which can help them to better\nunderstand and analyze the material.\nFor group & remote learning, large language models\ncan be used to facilitate group discussions and debates by\nproviding a discussion structure, real-time feedback and per-\nsonalized guidance to students during the discussion. This\ncan help to improve student engagement and participation. In\ncollaborative writing activities, where multiple students work\ntogether to write a document or a project, language models\ncan assist by providing style and editing suggestions as well\nas other integrative co-writing features. For research purposes,\nsuch models can be used to span the range of open research\nquestions in relation to already researched topics and to au-\ntomatically assign the questions and topics to the involved\nteam members. For remote tutoring purposes, they can be\nused to automatically generate questions and provide practice\nproblems, explanations, and assessments that are tailored to\nthe students\u2019 level of knowledge so that they can learn at their\nown pace.\nTo empower learners with disabilities, large language\nmodels can be used in combination with speech-to-text or text-\nto-speech solutions to help people with visual impairment. In\ncombination with the previously mentioned group and remote\ntutoring opportunities, language models can be used to de-\nvelop inclusive learning strategies with adequate support in\ntasks such as adaptive writing, translating, and highlighting\nof important content in various formats. However, it is im-\nportant to note that the use of large language models should\nbe accompanied by the help of professionals such as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision"
        }
      ],
      "actions": [
        "Investigate the specific ways LLMs fall short of human performance in educational dialogues.",
        "Explore the implications of LLMs creating an 'impression' of understanding versus actual comprehension in an educational context."
      ]
    },
    {
      "id": "r0025",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0013",
      "claim_text": "LLMs can generate contextualized natural language texts and code for various implementation tasks, and in conjunction with other AI systems, can create multimedia content. (E11).",
      "summary": "While LLMs can generate various forms of content, including code and domain-specific language, their outputs may perpetuate societal biases present in their training data.",
      "detail": "The claim states that LLMs can generate contextualized natural language texts and code. E6 supports this by mentioning their ability to assist in programming and generate domain-specific language for fields like legal, medical, and IT. However, E5 introduces a critical limitation: LLMs can 'perpetuate and amplify existing biases and unfairness in society.' This means that the generated content, whether it's text or code, might reflect and even exacerbate biases present in the data they were trained on, potentially leading to unfair or discriminatory outcomes, especially for minority groups.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 5772,
          "char_end": 6441,
          "quote": "as speech therapists, educators, and other specialists that can adapt the technology to the specific needs of the learner\u2019s disabilities. For professional training, large language models can assist in the development of language skills that are specific to a particular field of work. They can also assist in the deve...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0003",
          "chunk_text": "as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision making and problem-solving.\nFor example, large language models can be fine-tuned on\na domain-specific corpus (e.g. legal, medical, IT) in order\nto generate domain-specific language and assist learners in\nwriting technical reports, legal documents, medical records etc."
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 6,
          "char_start": 3861,
          "char_end": 5568,
          "quote": "con- tent \u2022 Inheritance and detailed terms of use for the content generated by the model \u2022 Informing and raising awareness of the users about these policies Bias and fairness. Large language models can perpetuate and amplify existing biases and unfairness in society, which can negatively impact teaching and learning...",
          "chunk_id": "1-ChatGPT_for_Good:p0006:c0002",
          "chunk_text": "con-\ntent\n\u2022 Inheritance and detailed terms of use for the content\ngenerated by the model\n\u2022 Informing and raising awareness of the users about\nthese policies\nBias and fairness.\nLarge language models can perpetuate\nand amplify existing biases and unfairness in society, which\ncan negatively impact teaching and learning processes and\noutcomes. For example, if a model is trained on data that\nis biased towards certain groups of people, it may produce\nresults that are unfair or discriminatory towards those groups\n(e.g., local knowledge about minorities such as small ethnic\ngroups or cultures can fade into the background). Thus, it is\nimportant to ensure that the training data or the data used for\nfine-tuning on down-stream tasks for the model is diverse and\nrepresentative of different groups of people. Regular monitor-\ning and testing of the model\u2019s performance on different groups\nof people can help identify and address any biases early on.\nHence, human oversight in the process is indispensable and\ncritical for the mitigation of bias and beneficial application of\nlarge language models in education.\nMore specifically, a responsible mitigation strategy would\nfocus on the following key aspects:\n\u2022 A diverse set of data to train or fine-tune the model, to\nensure that it is not biased towards any particular group\n\u2022 Regular monitoring and evaluation of the model\u2019s per-\nformance (on diverse groups of people) to identify and\naddress any biases that may arise\n\u2022 Fairness measures and bias-correction techniques, such\nas pre-processing or post-processing methods\n\u2022 Transparency mechanisms that enable users to compre-\nhend the model\u2019s output, and the data and assumptions\nthat were used to generate it"
        }
      ],
      "actions": [
        "Examine the types of biases that LLMs are known to perpetuate in generated text and code.",
        "Research methods for mitigating bias in LLM outputs, particularly in domain-specific applications."
      ]
    },
    {
      "id": "r0026",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0014",
      "claim_text": "LLMs have demonstrated the potential to assist in medical education and clinical decision-making processes by performing at or near passing thresholds without domain-specific fine-tuning. (E14).",
      "summary": "The evidence does not directly support the claim that LLMs can perform at or near passing thresholds in medical education or clinical decision-making without fine-tuning.",
      "detail": "The provided evidence snippets discuss the use of LLMs in education for tasks like generating educational content (quizzes, flashcards), evaluating peer assessments, and their general capabilities in natural language tasks. However, none of the snippets specifically mention LLMs being used or tested in medical education or clinical decision-making, nor do they address their performance relative to passing thresholds in these domains without domain-specific fine-tuning. The evidence focuses more broadly on LLMs in education and their general language processing abilities.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 4,
          "char_start": 3807,
          "char_end": 6075,
          "quote": "13 programming languages, resulting in a data volume of 1.6TB. 2.2 Review of Research Applying Large Language Models in Education In the following, we provide an overview of research works employing large language models in education that were pub- lished since the release of the first large language model in 2018. ...",
          "chunk_id": "1-ChatGPT_for_Good:p0004:c0002",
          "chunk_text": "13 programming\nlanguages, resulting in a data volume of 1.6TB.\n2.2 Review of Research Applying Large Language\nModels in Education\nIn the following, we provide an overview of research works\nemploying large language models in education that were pub-\nlished since the release of the first large language model in\n2018. These studies have been discussed in the following\naccording to their target groups, i.e., learners or teachers.\nLearners\u2019 perspective.\nFrom a student\u2019s perspective, large\nlanguage models can be used in multiple ways to assist the\nlearning process. One example is in the creation and design of\neducational content. For example, researchers have used large\nlanguage models to generate interactive educational materials\nsuch as quizzes and flashcards, which can be used to improve\nstudent learning and engagement [16, 17]. More specifically,\nin a recent work by Dijkstra et al. [17], researchers have used\nGPT-3 to generate multiple-choice questions and answers\nfor a reading comprehension task and argue that automated\ngeneration of quizzes not only reduces the burden of manual\nquiz design for teachers but, above all, provides a helpful tool\nfor students to train and test their knowledge while learning\nfrom textbooks and during exam preparation [17].\nIn another recent work, GPT-3 was employed as a ped-\nagogical agent to stimulate the curiosity of children and en-\nhance question-asking skills [18]. More specifically, the au-\nthors automated the generation of curiosity-prompting cues\nas an incentive for asking more and deeper questions. Ac-\ncording to their results, large language models not only bear\nthe potential to significantly facilitate the implementation of\ncuriosity-stimulating learning but can also serve as an efficient\ntool towards an increased curiosity expression [18].\nIn computing education, a recent work by MacNeil et\nal. [19] has employed GPT-3 to generate code explanations.\nDespite several open research and pedagogical questions that\nneed to be further explored, this work has successfully demon-\nstrated the potential of GPT-3 to support learning by explain-\ning aspects of a given code snippet.\nFor a data science course, Bhat et al. [20] proposed a\npipeline for generating assessment questions based on a fine-\ntuned"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 0,
          "char_end": 2181,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 5/13 ing by a trained GPT-3 model and manual reviews by human experts. The authors reported that the generated questions were rated favorably by human experts, promoting thus the usage of large language models in data science ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 5/13\ning by a trained GPT-3 model and manual reviews by human\nexperts. The authors reported that the generated questions\nwere rated favorably by human experts, promoting thus the\nusage of large language models in data science education [20].\nStudents can learn from each other by peer-reviewing and\nassessing each other\u2019s solutions. This, of course, has the best\neffect when the given feedback is comprehensive and of high\nquality. For example, Jia et al. [21] showed how BERT can\nbe used to evaluate the peer assessments so that students can\nlearn to improve their feedback.\nIn a recent review on conversational AI in language edu-\ncation, the authors found that there are five main applications\nof conversational AI during teaching [22], the most common\none being the use of large language models as a conversa-\ntional partner in a written or oral form, e.g., in the context\nof a task-oriented dialogue that provides language practice\nopportunities such as pronunciation [23]. Another application\nis to support students when they experience foreign language\nlearning anxiety [24] or have a lower willingness to commu-\nnicate [25]. In [26], the application of providing feedback, as\na needs analyst, and evaluator when primary school students\npractice their vocabulary was explored. The authors of [27]\nfound that a chatbot that is guided by a mind map is more suc-\ncessful in supporting students by providing scaffolds during\nlanguage learning than a conventional AI chatbot.\nA recent work in the area of medical education by Kung et\nal. [28] explored the performance of ChatGPT on the United\nStates Medical Licensing Exam. According to the evaluation\nresults, the performance of ChatGPT on this test was at or\nnear the passing threshold without any domain fine-tuning.\nBased on these results, the authors argue that large language\nmodels might be a powerful tool to assist medical education\nand eventually clinical decision-making processes [28].\nTeachers\u2019 perspective.\nAs the rate of adoption of AI in\neducation is still slow compared to other fields, such as indus-\ntrial applications"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 0,
          "char_end": 2323,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 2/13 efficiently adapted to down-stream tasks or even other seem- ingly unrelated tasks (e.g., as in transfer learning) has been empirically observed and studied for various natural-language tasks [6], e.g., more recently in t...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 2/13\nefficiently adapted to down-stream tasks or even other seem-\ningly unrelated tasks (e.g., as in transfer learning) has been\nempirically observed and studied for various natural-language\ntasks [6], e.g., more recently in the context of generating\nsynthetic and yet realistic heterogeneous tabular data [7].\nRecent advancements also include GPT-3 [1] and Chat-\nGPT [8], which were trained on a much larger datasets, i.e.,\ntexts from a very large web corpus, and have demonstrated\nstate-of-the-art performance on a wide range of natural-language\ntasks ranging from translation to question answering, writ-\ning coherent essays, and computer programs. Additionally,\nextensive research has been conducted on fine-tuning these\nmodels on smaller datasets and applying transfer learning to\nnew problems. This allows for improved performance on\nspecific tasks with smaller amount of data.\nWhile large language models have made great strides in\nrecent years, there are still many limitations that need to be\naddressed. One major limitation is the lack of interpretabil-\nity, as it is difficult to understand the reasoning behind the\nmodel\u2019s predictions. There are ethical considerations, such\nas concerns about bias and the impact of these models, e.g.,\non employment, risks of misuse and inadequate or unethical\ndeployment, loss of integrity, and many more. Overall, large\nlanguage models will continue to push the boundaries of what\nis possible in natural language processing. However, there\nis still much work to be done in terms of addressing their\nlimitations and the related ethical considerations.\n1.1 Opportunities for Learning\nThe use of large language models in education has been iden-\ntified as a potential area of interest due to the diverse range of\napplications they offer. Through the utilization of these mod-\nels, opportunities for enhancement of learning and teaching\nexperiences may be possible for individuals at all levels of edu-\ncation, including primary, secondary, tertiary and professional\ndevelopment.\nFor elementary school students, large language models\ncan assist in the development of reading and writing skills\n(e.g., by suggesting syntactic and grammatical corrections), as\nwell as in the development of"
        }
      ],
      "actions": [
        "Search for evidence specifically on LLM performance in medical education.",
        "Look for studies evaluating LLMs against passing thresholds in clinical decision-making.",
        "Investigate if any of the cited research in the provided snippets has follow-up studies in the medical domain."
      ]
    },
    {
      "id": "r0027",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0014",
      "claim_text": "LLMs have demonstrated the potential to assist in medical education and clinical decision-making processes by performing at or near passing thresholds without domain-specific fine-tuning. (E14).",
      "summary": "The evidence highlights the need for human monitoring and critical thinking when integrating LLMs into education, which implies a limitation on their autonomous use in critical areas like clinical decision-making.",
      "detail": "Evidence snippet E5 explicitly states that the integration of LLMs into education 'must be done in conjunction with ongoing human monitoring, guidance, and critical thinking.' This suggests that LLMs are not intended to operate autonomously in educational or potentially clinical settings, especially when dealing with sensitive or high-stakes applications. The claim that LLMs can assist in clinical decision-making without fine-tuning might be overstated if human oversight and critical evaluation are always required, implying a dependency on human expertise rather than full LLM autonomy.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 3836,
          "char_end": 5925,
          "quote": "large language models into education must therefore meet stringent privacy, security, and - for sustainable scal- ing - environmental, regulatory and ethical requirements, and must be done in conjunction with ongoing human monitoring, guidance, and critical thinking. While this position paper reflects the optimism o...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0002",
          "chunk_text": "large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in education, it also underscores\nthe need for further research to explore best practices for inte-\ngrating large language models into education and to mitigate\nthe risks identified.\nWe believe that despite many difficulties and challenges,\nthe discussed risks are manageable and should be addressed to\nprovide trustworthy and fair access to large language models\nfor education. Towards this goal, the mitigation strategies\nproposed in this position paper could serve as a starting point.\nReferences\n[1] Luciano Floridi and Massimo Chiriatti. GPT-3: Its nature,\nscope, limits, and consequences. Minds and Machines,\n30(4):681\u2013694, 2020.\n[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. BERT: Pre-training of Deep Bidirec-\ntional Transformers for Language Understanding. arXiv\npreprint arXiv:1810.04805, 2018.\n[3] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Met-\nzler. Efficient transformers: A survey. ACM Computing\nSurveys, 55(6):1\u201328, 2022.\n[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. Advances\nin neural information processing systems, 30, 2017.\n[5] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben\nVeyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre,\nIlana Heinz, and Dan Roth. Recent advances in natural\nlanguage processing via large pre-trained language mod-\nels: A survey. arXiv preprint arXiv:2111.01243, 2021.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-\nbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\net al. Language models are few-shot learners. Advances"
        }
      ],
      "actions": [
        "Clarify the extent of 'assistance' in clinical decision-making and whether it implies full autonomy.",
        "Investigate the implications of 'ongoing human monitoring' for LLM performance claims in critical fields.",
        "Search for research that quantifies the level of human intervention required for LLM-assisted clinical decision-making."
      ]
    },
    {
      "id": "r0028",
      "topic": "What are some tasks that LLMs today are used for?",
      "claim_id": "c0015",
      "claim_text": "LLMs can be used to generate personalized practice materials, summaries, and explanations to aid in the development of various skills, including reading, writing, math, science, and language. (E16).",
      "summary": "LLMs can generate personalized practice materials and summaries for various skills, but their use should supplement, not replace, human instruction.",
      "detail": "The claim states that LLMs can generate personalized practice materials, summaries, and explanations for skills like reading, writing, math, science, and language. Evidence E1, E2, and E3 support this by detailing how LLMs can assist in developing reading and writing skills, research skills, and generating practice problems and quizzes. However, E4 introduces a crucial limitation: LLMs should be used as a complement to human instruction and not as a replacement, as they cannot substitute for creativity, critical thinking, and problem-solving skills developed through human teaching. This highlights an open question about the optimal balance and integration of LLMs in skill development to avoid over-reliance.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 1901,
          "char_end": 4241,
          "quote": "these mod- els, opportunities for enhancement of learning and teaching experiences may be possible for individuals at all levels of edu- cation, including primary, secondary, tertiary and professional development. For elementary school students, large language models can assist in the development of reading and writ...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0001",
          "chunk_text": "these mod-\nels, opportunities for enhancement of learning and teaching\nexperiences may be possible for individuals at all levels of edu-\ncation, including primary, secondary, tertiary and professional\ndevelopment.\nFor elementary school students, large language models\ncan assist in the development of reading and writing skills\n(e.g., by suggesting syntactic and grammatical corrections), as\nwell as in the development of writing style and critical think-\ning skills. These models can be used to generate questions\nand prompts that encourage students to think critically about\nwhat they are reading and writing, and to analyze and inter-\npret the information presented to them. Additionally, large\nlanguage models can also assist in the development of reading\ncomprehension skills by providing students with summaries\nand explanations of complex texts, which can make reading\nand understanding the material easier.\nFor middle and high school students, large language\nmodels can assist in the learning of a language and of writ-\ning styles for various subjects and topics, e.g., mathematics,\nphysics, language and literature, and other subjects. These\nmodels can be used to generate practice problems and quizzes,\nwhich can help students to better understand, contextual-\nize and retain the material they are learning. Additionally,\nlarge language models can also assist in the development of\nproblem-solving skills by providing students with explana-\ntions, step-by-step solutions, and interesting related questions\nto problems, which can help them to understand the reasoning\nbehind the solutions and develop analytical and out-of-the-box\nthinking.\nFor university students, large language models can assist\nin the research and writing tasks, as well as in the development\nof critical thinking and problem-solving skills. These models\ncan be used to generate summaries and outlines of texts, which\ncan help students to quickly understand the main points of a\ntext and to organize their thoughts for writing. Additionally,\nlarge language models can also assist in the development of\nresearch skills by providing students with information and re-\nsources on a particular topic and hinting at unexplored aspects\nand current research topics, which can help them to better\nunderstand and analyze the material.\nFor group & remote learning, large"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 3858,
          "char_end": 6173,
          "quote": "a text and to organize their thoughts for writing. Additionally, large language models can also assist in the development of research skills by providing students with information and re- sources on a particular topic and hinting at unexplored aspects and current research topics, which can help them to better unders...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0002",
          "chunk_text": "a\ntext and to organize their thoughts for writing. Additionally,\nlarge language models can also assist in the development of\nresearch skills by providing students with information and re-\nsources on a particular topic and hinting at unexplored aspects\nand current research topics, which can help them to better\nunderstand and analyze the material.\nFor group & remote learning, large language models\ncan be used to facilitate group discussions and debates by\nproviding a discussion structure, real-time feedback and per-\nsonalized guidance to students during the discussion. This\ncan help to improve student engagement and participation. In\ncollaborative writing activities, where multiple students work\ntogether to write a document or a project, language models\ncan assist by providing style and editing suggestions as well\nas other integrative co-writing features. For research purposes,\nsuch models can be used to span the range of open research\nquestions in relation to already researched topics and to au-\ntomatically assign the questions and topics to the involved\nteam members. For remote tutoring purposes, they can be\nused to automatically generate questions and provide practice\nproblems, explanations, and assessments that are tailored to\nthe students\u2019 level of knowledge so that they can learn at their\nown pace.\nTo empower learners with disabilities, large language\nmodels can be used in combination with speech-to-text or text-\nto-speech solutions to help people with visual impairment. In\ncombination with the previously mentioned group and remote\ntutoring opportunities, language models can be used to de-\nvelop inclusive learning strategies with adequate support in\ntasks such as adaptive writing, translating, and highlighting\nof important content in various formats. However, it is im-\nportant to note that the use of large language models should\nbe accompanied by the help of professionals such as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 1952,
          "char_end": 4293,
          "quote": "also as- sist teachers in the creation of (inclusive) lesson plans and activities. Teachers can input to the models the corpus of document based on which they want to build a course. The output can be a course syllabus with short description of each topic. Language models can also generate questions and prompts that...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0001",
          "chunk_text": "also as-\nsist teachers in the creation of (inclusive) lesson plans and\nactivities. Teachers can input to the models the corpus of\ndocument based on which they want to build a course. The\noutput can be a course syllabus with short description of each\ntopic. Language models can also generate questions and\nprompts that encourage the participation of people at different\nknowledge and ability levels, and elicit critical thinking and\nproblem-solving. Moreover, they can be used to generate tar-\ngeted and personalized practice problems and quizzes, which\ncan help to ensure that students are mastering the material.\nFor language learning, teachers of language classes can\nuse large language models in an assistive way, e.g., to high-\nlight important phrases, generate summaries and translations,\nprovide explanations of grammar and vocabulary, suggest\ngrammatical or style improvements and assist in conversation\npractice. Language models can also provide teachers with\nadaptive and personalized means to assist students in their\nlanguage learning journey, which can make language learning\nmore engaging and effective for students.\nFor research and writing, large language models can\nassist teachers of university and high school classes to com-\nplete research and writing tasks (e.g., in seminar works, paper\nwriting, and feedback to students) more efficiently and effec-\ntively. The most basic help can happen at a syntactic level,\ni.e., identifying and correcting typos. At a semantic level,\nlarge language models can be used to highlight (potential)\ngrammatical inconsistencies and suggest adequate and person-\nalized improvement strategies. Going further, these models\ncan be used to identify possibilities for topic-specific style\nimprovement. They can also be used to generate summaries\nand outlines of challenging texts, which can help teachers and\nresearchers to highlight the main points of a text in a way\nthat is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        }
      ],
      "actions": [
        "Clarify the specific types of 'personalized practice materials' LLMs can generate beyond grammar correction and question generation.",
        "Investigate the extent to which LLMs can effectively aid in the development of math and science skills, as evidence primarily focuses on language-based skills.",
        "Explore strategies for integrating LLMs as supplements to human instruction to maximize skill development without fostering over-reliance."
      ]
    }
  ]
}