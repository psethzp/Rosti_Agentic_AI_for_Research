{
  "insights": [
    {
      "id": "i0001",
      "topic": "What are some areas in which LLms today fail?",
      "claim_ids": [
        "c0001"
      ],
      "summary": "LLMs struggle with sustained focus and cognitive load, particularly when faced with complex tasks or distractions, impacting their ability to maintain relevance.",
      "text": "LLMs can exhibit a decrease in focus as task complexity, or cognitive load, increases, akin to mental fatigue (c0001). This can be exacerbated by distractions, with a 'threshold' parameter influencing how easily an LLM deviates from the topic (c0001). Metrics like 'Time-on-Task' and the frequency of off-topic utterances are used to quantify this failure in sustained attention (c0001). While the evidence simulates cognitive states, the direct measurement of LLM focus degradation remains a challenge (c0001).",
      "confidence": 0.9,
      "provenance": [
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 4,
          "char_start": 2056,
          "char_end": 3798,
          "quote": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an off-topic comment, a complex thought) shifting the agent\u2019s focus. \u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum, the probability of an attention lapse increases...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0001",
          "chunk_text": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the agent\u2019s output is semantically relevant to the\nongoing topic.\n\u2022 Frequency of Off-Topic Utterances: A count of instances where the agent\u2019s output deviates from the\nestablished topic.\n\u2022 Human Expert Ratings: Blind evaluators will rate the believability of an agent\u2019s attentional patterns.\nTestable Hypotheses:\n\u2022 H3 : Agents with a lower \u2018Attention Span\u2019 parameter will exhibit a statistically significant higher frequency\nof off-topic utterances compared to agents with higher attention spans.\n\u2022 H4 : Agents with a lower \u2018Distractibility Threshold\u2019 will show greater performance degradation in simulated\nenvironments with high levels of external distractions.\n3) The Memory and Decoding Module (Memory Filter):\nTheoretical Grounding: The module is based on the Dual-Route Cascade Model of Reading [11][35], which\nexplains how individuals decode familiar and unfamiliar words. Deficiencies in phonological (sound-based) and\northographic (visual-based) processing, which are often implicated in dyslexia, will be modeled [40]. Furthermore,\nit incorporates principles from Verbal Efficiency Theory [49], which posits that effortful decoding consumes finite\nworking memory resources needed for comprehension.\nOperational Definition: This module acts as a filter that pre-processes text input to the LLM. It is defined by:"
        }
      ]
    },
    {
      "id": "i0002",
      "topic": "What are some areas in which LLms today fail?",
      "claim_ids": [
        "c0002"
      ],
      "summary": "The internal text processing and memory capacity of LLMs are vulnerable to errors and limitations, hindering comprehension.",
      "text": "LLMs can experience difficulties in phonological and orthographic processing, where character-level errors, simulated by a 'Phonological Noise Parameter,' can consume limited working memory (c0002). This reduction in working memory capacity impairs higher-level comprehension (c0002). While reading comprehension accuracy is a key metric, the specific evaluation metrics for comprehension are not detailed in the evidence (c0002). The claim's emphasis on a specific 'Phonological Noise Parameter' and its direct impact on working memory is not fully supported by the provided evidence (c0002).",
      "confidence": 0.85,
      "provenance": [
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 5,
          "char_start": 0,
          "char_end": 2714,
          "quote": "5 \u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into the agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties. \u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to ...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0005:c0000",
          "chunk_text": "5\n\u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into\nthe agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties.\n\u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to hold information. Effortful\ndecoding, as dictated by the noise parameter, will consume space in this buffer, reducing the resources available\nfor higher-level comprehension.\nEvaluation Metrics:\n\u2022 Reading Comprehension Accuracy: Agent performance on simulated comprehension tasks.\n\u2022 Error Analysis: Classification of agent errors into phonological, orthographic, or semantic categories.\n\u2022 Information Recall Fidelity: The accuracy with which an agent can recall facts presented in a passage, testing\nthe integrity of its working memory.\nTestable Hypotheses:\n\u2022 H5 : Agents with a high \u2018Phonological Noise\u2019 parameter will make significantly more phonologically-based\nerrors than agents with a low parameter.\n\u2022 H6 : A reduction in the \u2018Working Memory Buffer\u2019 size will be negatively correlated with an agent\u2019s ability\nto answer questions about long passages of text.\nIV. EXPECTED MILESTONES\nThe project is envisioned as a four-month intensive research program with clearly defined deliverables and\nevaluation checkpoints:\n\u2022 Month 1: Foundation and Architecture\nComplete a systematic review of educational psychology to formalize student archetypes, followed by the\ndesign of the complete Cognitive Twin architecture and development of initial meta-prompts.\nDeliverables: Comprehensive literature analysis, formal archetype specifications, and a complete architectural\ndesign with an initial meta-prompt library.\n\u2022 Month 2: Implementation and Preliminary Validation\nDevelop and implement the three core cognitive processing modules (Affect, Attention, Memory and Decod-\ning). Integrate all system components and conduct preliminary validation studies, including agent behavior\nconsistency testing.\nDeliverables: A functional, integrated system with documented performance characteristics and preliminary\nvalidation results.\n\u2022 Month 3: Comprehensive Evaluation and Alternative Architecture Exploration\nConduct full validation study including human expert evaluation, behavioral differentiation analysis, and\nCommittee of Agents implementation as a comparative study.\nDeliverables: Complete validation results and architectural comparison analysis.\n\u2022 Month 4: Analysis, Documentation, and Dissemination\nAnalyze all collected data, optimize system parameters based on evaluation results, and prepare comprehensive\ndocumentation, including academic paper preparation for submission to relevant conferences"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 2,
          "char_start": 2133,
          "char_end": 4362,
          "quote": "phonological and orthographic processing, such as character-level decoding fidelity and working memory for text [33][43][19]. 3) Demonstrate Superior Simulation Fidelity: Validate the architecture\u2019s effectiveness through comprehensive evaluation including human expert assessment of agent believability, quantitative ...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0002:c0001",
          "chunk_text": "phonological and orthographic\nprocessing, such as character-level decoding fidelity and working memory for text [33][43][19].\n3) Demonstrate Superior Simulation Fidelity: Validate the architecture\u2019s effectiveness through comprehensive\nevaluation including human expert assessment of agent believability, quantitative analysis of behavioral pattern\ndifferentiation between agent archetypes, and comparative analysis with existing student modeling approaches\nin terms of predictive accuracy and educational insight generation.\nIII. PROPOSED IMPLEMENTATION\nOur implementation strategy consists of four integrated phases designed to create a comprehensive psychologically-\ngrounded educational simulation framework:\na) Phase 1: Literature Review and Archetype Formalization: We begin with a systematic review of educational\npsychology literature to identify and formalize 3-5 empirically-validated student archetypes, building upon estab-\nlished frameworks such as the Deep/Surface/Strategic learning approaches [4][18][41][53]. Each archetype will be\ncharacterized through comprehensive behavioral profiles including learning motivations, communication patterns,\ncognitive processing preferences, and response tendencies to different pedagogical interventions. This phase will\nalso incorporate findings from student modeling research using Bayesian Knowledge Tracing [32][64][66] and\ncognitive agent computing models [61] to ensure compatibility with existing educational technologies.\nb) Phase 2: Disposition Layer Implementation: For each identified archetype, we will engineer sophisticated\n\u201cmeta-prompts\u201d that serve as the agent\u2019s psychological constitution. These prompts will define core motivations,\ncommunication styles, and worldviews that establish the baseline parameters for the cognitive modules in the next\nphase. (e.g., \u201cYou are a \u2018Surface Learner.\u2019 Your primary goal is to pass assessments with minimal effort. You prefer\nclear, factual information and avoid deep, open-ended discussions that require extensive cognitive processing...\u201d).\nThe meta-prompting approach will draw from recent advances in persona-based LLM control [31][37][1][67] and\npsychological authenticity research in conversational agents [30][57]."
        }
      ]
    },
    {
      "id": "i0003",
      "topic": "What are some areas in which LLms today fail?",
      "claim_ids": [
        "c0003",
        "c0004",
        "c0001"
      ],
      "summary": "Current LLM architectures lack dynamic integration of core cognitive functions like affect, attention, and memory, limiting their ability to model comprehensive learning and authentic emotional states.",
      "text": "While LLMs excel at individual cognitive aspects, there is a significant gap in models that dynamically integrate affect, attention, and memory for holistic learning (c0003). These three components are crucial for motivation, information processing, and knowledge construction, with their interplay influencing focus and memory encoding (c0003). Although 'Affect Modules' can track simulated emotional states and behavioral indicators, the evidence primarily validates the believability of agent personas rather than the internal emotional tracking mechanisms (c0004). The claim regarding 'mental fatigue' is also not directly supported, as the evidence describes simulated cognitive states rather than actual fatigue (c0001).",
      "confidence": 0.8,
      "provenance": [
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 1,
          "char_start": 2198,
          "char_end": 4370,
          "quote": "[26], [20], [12], [7], where affect drives motivation, attention governs information processing, and memory anchors knowledge construction [29], [8], [3], [63]. Beyond these individual explorations, studies have also examined their crucial interplay as research on the link between affect and attention has shown how ...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0001:c0001",
          "chunk_text": "[26], [20], [12], [7], where affect drives motivation, attention governs information processing, and\nmemory anchors knowledge construction [29], [8], [3], [63]. Beyond these individual explorations, studies have also\nexamined their crucial interplay as research on the link between affect and attention has shown how emotional\nstates can direct or impair focus [63], [17], [39], while studies on attention and memory have confirmed that\nfocused attention is essential for effective memory encoding [46], [54], [36], [14]. Works also demonstrate how\nthese interactions create compounding effects, particularly for diverse learners, where heightened anxiety (affect)\ncan disrupt attentional control, which in turn compromises working memory, making it exceedingly difficult for\na student to follow multi-step instructions or comprehend complex texts [39]. Furthermore, studies focusing on\nlearning disabilities demonstrate that issues regarding attention or memory are often exacerbated by emotional\ndysregulation, making a unified framework essential to accurately simulate the significant barriers diverse learners\nface. [26], [36], [59], [62], [42], [55], [38]. This evidence of compounding effects due to interplay reinforces a\ncritical conclusion from cognitive and clinical research: Any model aiming to be psychologically authentic must\nintegrate all three components and simulate their dynamic interplay to reflect how they function interdependently\nwithin a natural cognitive system.\nA primary issue in the current implementations is the reliance on uniform, static student representations that\nfail to model the above core cognitive dimensions driving student behavior. [65]. Frameworks like PEERS [2] use\nlimited behavioral parameters that model only on-task actions, ignoring off-task behaviors driven by boredom or\nfrustration while even advanced systems like EduAgent [67] and SimClass [68] struggle to capture the full spectrum\nof individual differences related to these cognitive aspects, as they are yet unable to simulate how a student with\nanxiety might freeze up when called upon (affect), how another with attentional deficits might frequently disengage"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 2,
          "char_start": 0,
          "char_end": 2658,
          "quote": "2 (attention), or how different learning styles impact knowledge retention (memory) [4], [18], [41]. While cognitive architectures like NEOLAF and the Unified Mind Model [21][22], ACT-R [51], CLARION [60], Sigma [13], and MalAlgoPy [58] have hinted at unified systems, there remains a clear gap in models that holisti...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0002:c0000",
          "chunk_text": "2\n(attention), or how different learning styles impact knowledge retention (memory) [4], [18], [41]. While cognitive\narchitectures like NEOLAF and the Unified Mind Model [21][22], ACT-R [51], CLARION [60], Sigma [13],\nand MalAlgoPy [58] have hinted at unified systems, there remains a clear gap in models that holistically integrate\nall three components on a dynamic basis for modeling learning [39], [13], [28], [45]. To address this, we propose a\nnovel, layered agent architecture that grounds agent behavior in validated educational psychology by formalizing\nstudent archetypes [4], [18], [41], [53], made feasible by advances in persona-based prompting [31], [37], [1] and\ncognitive digital twins [23], [24]. By implementing specialized cognitive layers for affect, attention and memory,\nthis approach will aim to bridge the fidelity gap where the primary goal will be the development of authentic\npsychological diversity, transforming simulations into powerful training tools to better prepare educators for the\nunpredictable dynamics of a live classroom, ensuring they are equipped to manage diverse student needs effectively.\nII. OBJECTIVES\nThe primary goal of this research is to develop and validate a psychologically-grounded architecture for creating\nrealistic student agents in educational simulations, focusing on three main objectives:\n1) Develop a Novel Cognitive Agent Architecture: Create a layered agent system that integrates empirically-\nderived student archetypes from educational psychology literature with programmatic cognitive processing\nlayers to simulate authentic student behaviors and learning patterns.\n2) Implement Psychologically-Authentic Simulation Components: Design and validate specialized cognitive\nprocessing modules including an Affective module to dynamically modulate emotional states based on estab-\nlished psychological theories of student motivation and anxiety, an Attention module modeling variations in\nexecutive function and attention, such as distractibility and sustained focus [6][56][56], and a Memory and\nDecoding module with memory filtering mechanisms simulating variations in phonological and orthographic\nprocessing, such as character-level decoding fidelity and working memory for text [33][43][19].\n3) Demonstrate Superior Simulation Fidelity: Validate the architecture\u2019s effectiveness through comprehensive\nevaluation including human expert assessment of agent believability, quantitative analysis of behavioral pattern\ndifferentiation between agent archetypes, and comparative analysis with existing student modeling approaches\nin terms of predictive accuracy and educational insight generation."
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 3,
          "char_start": 0,
          "char_end": 2687,
          "quote": "3 c) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules that dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM that is trained to read this Control Panel and generate behavior that matches the specified cognit...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0003:c0000",
          "chunk_text": "3\nc) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules\nthat dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM\nthat is trained to read this Control Panel and generate behavior that matches the specified cognitive state to simulate\ncore cognitive functions and individual differences. The modules function as follows:\n\u2022 Affect Module (Emotional State Modulator): A state-machine implementation tracking dynamic emotional\nstates (confident, confused, anxious, engaged) based on interaction history and performance outcomes. This\nmodule will modify LLM prompt components in real-time to reflect emotional influences on communication\nstyle, response length, and cognitive processing approach. Here we update the emotion field of the Control\nPanel (e.g., \u201cemotion\u201d: \u201cprimary\u201d: \u201canxious\u201d, \u201cconfidence\u201d: 0.3), which the LLM interprets to modulate its\ncommunication style, response length, and cognitive processing approach.\n\u2022 Attention Module (Focus Manager): A dynamic attention modeling system that simulates varying atten-\ntion spans and distractibility patterns. Drawing from cognitive models of attention and executive function\n[6][56][56], this module will implement time-decay functions for attention, threshold-based coherence degra-\ndation, and attention reset mechanisms triggered by direct engagement or environmental changes. Here we\nupdate the focus field of the Control Panel in real-time (e.g., \u201cfocus\u201d: \u201clevel\u201d: 0.4), which instructs the LLM\nto adjust its response coherence and relevance.\n\u2022 Memory and Decoding Module (Memory Filter): A cognitive processing filter that models information\nprocessing variations, particularly those reflecting a spectrum of information processing speeds and accuracies\n[33][43][19]. This system will introduce controlled character-level noise (e.g., b/d reversals, transposition errors)\nwith probability distributions calibrated to diverse reading patterns, affecting information encoding and retrieval\naccuracy. Here we update the memory field of the Control Panel (e.g., \u201cmemory\u201d: \u201cdecoding fidelity\u201d: 0.85),\naffecting information encoding and retrieval accuracy.\nd) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation\nthrough multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis-\ntency, quantitative analysis of behavioral differentiation between agent types, and integration testing within educa-\ntional simulation environments. We will also explore the proposed \u201cCommittee of Agents\u201d alternative architecture as\nan ablation study,"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 4,
          "char_start": 0,
          "char_end": 2483,
          "quote": "4 Evaluation Metrics: \u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts. \u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and proactive questioning. \u2022 Human Expert Ratings: Educators will evaluate the authenti...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0000",
          "chunk_text": "4\nEvaluation Metrics:\n\u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts.\n\u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and\nproactive questioning.\n\u2022 Human Expert Ratings: Educators will evaluate the authenticity of the agent\u2019s emotional and motivational\ntrajectory.\nTestable Hypotheses:\n\u2022 H1 : An agent whose \u2018Control Appraisal\u2019 is systematically lowered through negative feedback will transition\nto negative emotional states (e.g., frustration, anxiety) and exhibit a corresponding increase in negative-valence\nlanguage.\n\u2022 H2 : Agents equipped with the Affective Module will be perceived by human raters as demonstrating more\nbelievable and differentiated student personalities than agents defined only by a static dispositional prompt.\n2) The Attention Module (Focus Manager):\nTheoretical Grounding: This module is grounded in hierarchical models of attention that differentiate between\nsustained attention (maintaining focus over time) and selective attention (filtering distractions) [10][50]. It also\ndraws from cognitive models of executive function, such as Baddeley\u2019s model of working memory [5], which\nincludes a central executive responsible for attentional control, and Load Theory of Attention [34] which posits that\nthe ability to ignore distractions depends on the perceptual load of the current task. These concepts are quite central\nto understanding various underlying conditions that affect Attention, such as ADHD [9]. Our model operationalizes\nthese concepts to simulate how an agent\u2019s focus can decay, be captured by competing stimuli, or be reset by direct\nengagement.\nOperational Definition: The module will be a state-based system governed by the following parameters:\n\u2022 Attention Span: A numerical value representing the number of conversational turns an agent can maintain\nfocus on a single topic before a potential \u201cattention lapse.\u201d This will be implemented as a timer that resets\nupon re-engagement.\n\u2022 Distractibility Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 4,
          "char_start": 2056,
          "char_end": 3798,
          "quote": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an off-topic comment, a complex thought) shifting the agent\u2019s focus. \u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum, the probability of an attention lapse increases...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0001",
          "chunk_text": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the agent\u2019s output is semantically relevant to the\nongoing topic.\n\u2022 Frequency of Off-Topic Utterances: A count of instances where the agent\u2019s output deviates from the\nestablished topic.\n\u2022 Human Expert Ratings: Blind evaluators will rate the believability of an agent\u2019s attentional patterns.\nTestable Hypotheses:\n\u2022 H3 : Agents with a lower \u2018Attention Span\u2019 parameter will exhibit a statistically significant higher frequency\nof off-topic utterances compared to agents with higher attention spans.\n\u2022 H4 : Agents with a lower \u2018Distractibility Threshold\u2019 will show greater performance degradation in simulated\nenvironments with high levels of external distractions.\n3) The Memory and Decoding Module (Memory Filter):\nTheoretical Grounding: The module is based on the Dual-Route Cascade Model of Reading [11][35], which\nexplains how individuals decode familiar and unfamiliar words. Deficiencies in phonological (sound-based) and\northographic (visual-based) processing, which are often implicated in dyslexia, will be modeled [40]. Furthermore,\nit incorporates principles from Verbal Efficiency Theory [49], which posits that effortful decoding consumes finite\nworking memory resources needed for comprehension.\nOperational Definition: This module acts as a filter that pre-processes text input to the LLM. It is defined by:"
        }
      ]
    }
  ],
  "actions": [
    {
      "id": "a0001",
      "topic": "What are some areas in which LLms today fail?",
      "title": "Investigate the direct impact of cognitive load on LLM focus degradation.",
      "detail": "While claim c0001 suggests a correlation between cognitive load and LLM focus loss, the evidence focuses on simulation parameters rather than direct measurement of focus degradation under varying cognitive loads. Future research should aim to directly measure 'Time-on-Task' and frequency of off-topic utterances under controlled, increasing cognitive load scenarios to validate the 'threshold' parameter's real-world applicability.",
      "tag": "Clarification",
      "related_claims": [
        "c0001"
      ]
    },
    {
      "id": "a0002",
      "topic": "What are some areas in which LLms today fail?",
      "title": "Develop and validate metrics for LLM reading comprehension accuracy under simulated decoding challenges.",
      "detail": "Claim c0002 posits that phonological noise impacts working memory and comprehension, but the evidence lacks specific metrics to evaluate reading comprehension accuracy in the context of these simulated decoding difficulties. A next step is to define and implement robust evaluation metrics that can quantify the impact of 'Phonological Noise Parameter' on an LLM's ability to accurately comprehend text.",
      "tag": "NextStep",
      "related_claims": [
        "c0002"
      ]
    },
    {
      "id": "a0003",
      "topic": "What are some areas in which LLms today fail?",
      "title": "Hypothesize a unified cognitive architecture for LLMs integrating affect, attention, and memory.",
      "detail": "Insight i0003 highlights the gap in LLMs that dynamically integrate affect, attention, and memory. This action proposes a hypothesis for a novel LLM architecture that holistically combines these elements, moving beyond current implementations that focus on individual aspects. This would address the limitations in modeling comprehensive learning and authentic emotional states.",
      "tag": "Hypothesis",
      "related_claims": [
        "c0003",
        "c0004",
        "c0001"
      ]
    },
    {
      "id": "a0004",
      "topic": "What are some areas in which LLms today fail?",
      "title": "Clarify the relationship between simulated emotional states and actual LLM behavior.",
      "detail": "Claim c0004 describes an 'Affect Module' and its tracking of simulated emotional states. However, the evidence focuses on persona believability rather than directly linking these simulated states to observable behavioral changes in the LLM. Further clarification is needed on how the 'emotional valence' and 'behavioral indicators' directly reflect the LLM's internal simulated emotional trajectory and its impact on its responses.",
      "tag": "Clarification",
      "related_claims": [
        "c0004"
      ]
    },
    {
      "id": "a0005",
      "topic": "What are some areas in which LLms today fail?",
      "title": "Explore the direct measurement of LLM 'mental fatigue' beyond simulated cognitive states.",
      "detail": "Challenge c0001 points out that the concept of LLM 'mental fatigue' is not directly supported by evidence, which focuses on simulated cognitive states. A forward-looking action is to investigate methods for directly measuring or inferring 'mental fatigue' in LLMs, perhaps through prolonged task performance analysis or resource utilization metrics, to move beyond simulation and towards a more direct understanding of focus degradation.",
      "tag": "NextStep",
      "related_claims": [
        "c0001"
      ]
    }
  ],
  "challenges": [
    {
      "id": "r0001",
      "topic": "What are some areas in which LLms today fail?",
      "claim_id": "c0001",
      "claim_text": "The probability of an LLM agent losing focus increases as cognitive load, a measure of task complexity, rises, simulating mental fatigue. A 'threshold' parameter can determine how easily an LLM agent is distracted by off-topic comments or complex thoughts, impacting its ability to stay on task. Evaluation metrics like 'Time-on-Task' measure the percentage of conversational turns where an LLM's output remains semantically relevant to the ongoing topic, highlighting potential failures in maintaining focus. The frequency of off-topic utterances serves as a direct count of instances where an LLM deviates from the established conversation, indicating a failure in sustained attention.",
      "summary": "The claim discusses LLM focus and cognitive load, but the evidence focuses on simulating cognitive functions and emotional states rather than directly measuring LLM focus degradation.",
      "detail": "The claim posits that LLM focus degrades with increased cognitive load and introduces a 'threshold' parameter for distraction. It also mentions evaluation metrics like 'Time-on-Task' and frequency of off-topic utterances. However, the provided evidence snippets (E1, E2, E3) describe the implementation of modules to simulate cognitive functions, emotional states, and introduce noise/memory limitations within an LLM agent. While these modules might indirectly influence focus, they do not directly measure or validate the claim's assertion about LLM focus degradation due to cognitive load or the effectiveness of the proposed 'threshold' parameter. The evidence does not provide metrics for 'Time-on-Task' or 'off-topic utterances' as described in the claim.",
      "evidence": [
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 4,
          "char_start": 0,
          "char_end": 2483,
          "quote": "4 Evaluation Metrics: \u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts. \u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and proactive questioning. \u2022 Human Expert Ratings: Educators will evaluate the authenti...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0000",
          "chunk_text": "4\nEvaluation Metrics:\n\u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts.\n\u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and\nproactive questioning.\n\u2022 Human Expert Ratings: Educators will evaluate the authenticity of the agent\u2019s emotional and motivational\ntrajectory.\nTestable Hypotheses:\n\u2022 H1 : An agent whose \u2018Control Appraisal\u2019 is systematically lowered through negative feedback will transition\nto negative emotional states (e.g., frustration, anxiety) and exhibit a corresponding increase in negative-valence\nlanguage.\n\u2022 H2 : Agents equipped with the Affective Module will be perceived by human raters as demonstrating more\nbelievable and differentiated student personalities than agents defined only by a static dispositional prompt.\n2) The Attention Module (Focus Manager):\nTheoretical Grounding: This module is grounded in hierarchical models of attention that differentiate between\nsustained attention (maintaining focus over time) and selective attention (filtering distractions) [10][50]. It also\ndraws from cognitive models of executive function, such as Baddeley\u2019s model of working memory [5], which\nincludes a central executive responsible for attentional control, and Load Theory of Attention [34] which posits that\nthe ability to ignore distractions depends on the perceptual load of the current task. These concepts are quite central\nto understanding various underlying conditions that affect Attention, such as ADHD [9]. Our model operationalizes\nthese concepts to simulate how an agent\u2019s focus can decay, be captured by competing stimuli, or be reset by direct\nengagement.\nOperational Definition: The module will be a state-based system governed by the following parameters:\n\u2022 Attention Span: A numerical value representing the number of conversational turns an agent can maintain\nfocus on a single topic before a potential \u201cattention lapse.\u201d This will be implemented as a timer that resets\nupon re-engagement.\n\u2022 Distractibility Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 3,
          "char_start": 0,
          "char_end": 2687,
          "quote": "3 c) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules that dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM that is trained to read this Control Panel and generate behavior that matches the specified cognit...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0003:c0000",
          "chunk_text": "3\nc) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules\nthat dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM\nthat is trained to read this Control Panel and generate behavior that matches the specified cognitive state to simulate\ncore cognitive functions and individual differences. The modules function as follows:\n\u2022 Affect Module (Emotional State Modulator): A state-machine implementation tracking dynamic emotional\nstates (confident, confused, anxious, engaged) based on interaction history and performance outcomes. This\nmodule will modify LLM prompt components in real-time to reflect emotional influences on communication\nstyle, response length, and cognitive processing approach. Here we update the emotion field of the Control\nPanel (e.g., \u201cemotion\u201d: \u201cprimary\u201d: \u201canxious\u201d, \u201cconfidence\u201d: 0.3), which the LLM interprets to modulate its\ncommunication style, response length, and cognitive processing approach.\n\u2022 Attention Module (Focus Manager): A dynamic attention modeling system that simulates varying atten-\ntion spans and distractibility patterns. Drawing from cognitive models of attention and executive function\n[6][56][56], this module will implement time-decay functions for attention, threshold-based coherence degra-\ndation, and attention reset mechanisms triggered by direct engagement or environmental changes. Here we\nupdate the focus field of the Control Panel in real-time (e.g., \u201cfocus\u201d: \u201clevel\u201d: 0.4), which instructs the LLM\nto adjust its response coherence and relevance.\n\u2022 Memory and Decoding Module (Memory Filter): A cognitive processing filter that models information\nprocessing variations, particularly those reflecting a spectrum of information processing speeds and accuracies\n[33][43][19]. This system will introduce controlled character-level noise (e.g., b/d reversals, transposition errors)\nwith probability distributions calibrated to diverse reading patterns, affecting information encoding and retrieval\naccuracy. Here we update the memory field of the Control Panel (e.g., \u201cmemory\u201d: \u201cdecoding fidelity\u201d: 0.85),\naffecting information encoding and retrieval accuracy.\nd) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation\nthrough multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis-\ntency, quantitative analysis of behavioral differentiation between agent types, and integration testing within educa-\ntional simulation environments. We will also explore the proposed \u201cCommittee of Agents\u201d alternative architecture as\nan ablation study,"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 5,
          "char_start": 0,
          "char_end": 2714,
          "quote": "5 \u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into the agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties. \u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to ...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0005:c0000",
          "chunk_text": "5\n\u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into\nthe agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties.\n\u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to hold information. Effortful\ndecoding, as dictated by the noise parameter, will consume space in this buffer, reducing the resources available\nfor higher-level comprehension.\nEvaluation Metrics:\n\u2022 Reading Comprehension Accuracy: Agent performance on simulated comprehension tasks.\n\u2022 Error Analysis: Classification of agent errors into phonological, orthographic, or semantic categories.\n\u2022 Information Recall Fidelity: The accuracy with which an agent can recall facts presented in a passage, testing\nthe integrity of its working memory.\nTestable Hypotheses:\n\u2022 H5 : Agents with a high \u2018Phonological Noise\u2019 parameter will make significantly more phonologically-based\nerrors than agents with a low parameter.\n\u2022 H6 : A reduction in the \u2018Working Memory Buffer\u2019 size will be negatively correlated with an agent\u2019s ability\nto answer questions about long passages of text.\nIV. EXPECTED MILESTONES\nThe project is envisioned as a four-month intensive research program with clearly defined deliverables and\nevaluation checkpoints:\n\u2022 Month 1: Foundation and Architecture\nComplete a systematic review of educational psychology to formalize student archetypes, followed by the\ndesign of the complete Cognitive Twin architecture and development of initial meta-prompts.\nDeliverables: Comprehensive literature analysis, formal archetype specifications, and a complete architectural\ndesign with an initial meta-prompt library.\n\u2022 Month 2: Implementation and Preliminary Validation\nDevelop and implement the three core cognitive processing modules (Affect, Attention, Memory and Decod-\ning). Integrate all system components and conduct preliminary validation studies, including agent behavior\nconsistency testing.\nDeliverables: A functional, integrated system with documented performance characteristics and preliminary\nvalidation results.\n\u2022 Month 3: Comprehensive Evaluation and Alternative Architecture Exploration\nConduct full validation study including human expert evaluation, behavioral differentiation analysis, and\nCommittee of Agents implementation as a comparative study.\nDeliverables: Complete validation results and architectural comparison analysis.\n\u2022 Month 4: Analysis, Documentation, and Dissemination\nAnalyze all collected data, optimize system parameters based on evaluation results, and prepare comprehensive\ndocumentation, including academic paper preparation for submission to relevant conferences"
        }
      ],
      "severity": "High",
      "actions": [
        "Seek evidence that directly measures LLM focus degradation under varying cognitive loads.",
        "Look for studies that validate the 'threshold' parameter's impact on LLM distraction.",
        "Find evidence that uses 'Time-on-Task' or 'frequency of off-topic utterances' as evaluation metrics for LLM focus."
      ]
    },
    {
      "id": "r0003",
      "topic": "What are some areas in which LLms today fail?",
      "claim_id": "c0002",
      "claim_text": "A 'Phonological Noise Parameter' can introduce character-level errors into an LLM's internal text processing, mimicking decoding challenges. These simulated decoding difficulties consume space in a fixed-size 'Working Memory Buffer,' reducing the LLM's capacity for higher-level comprehension. Reading comprehension accuracy is a key metric used to evaluate an LLM's performance on simulated comprehension tasks, revealing potential weaknesses in text processing. The LLM's ability to handle phonological and orthographic processing, including character-level decoding fidelity and working memory for text, is crucial for its overall accuracy.",
      "summary": "The claim introduces a 'Phonological Noise Parameter' and its impact on LLM working memory, but the evidence does not directly support or refute this specific mechanism.",
      "detail": "The claim posits that a 'Phonological Noise Parameter' can introduce character-level errors, consume working memory, and reduce comprehension. However, none of the provided evidence snippets discuss this specific parameter or its effects. Evidence E1 discusses 'Cognitive Load' and 'Attention Span' in a general sense related to task complexity and focus, and E3 describes implementing core cognitive modules like an 'Affect Module' to simulate emotional states and their influence on LLM prompts. While these touch upon cognitive concepts, they do not validate or invalidate the mechanism of a 'Phonological Noise Parameter' as described in the claim.",
      "evidence": [
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 4,
          "char_start": 2056,
          "char_end": 3798,
          "quote": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an off-topic comment, a complex thought) shifting the agent\u2019s focus. \u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum, the probability of an attention lapse increases...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0001",
          "chunk_text": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the agent\u2019s output is semantically relevant to the\nongoing topic.\n\u2022 Frequency of Off-Topic Utterances: A count of instances where the agent\u2019s output deviates from the\nestablished topic.\n\u2022 Human Expert Ratings: Blind evaluators will rate the believability of an agent\u2019s attentional patterns.\nTestable Hypotheses:\n\u2022 H3 : Agents with a lower \u2018Attention Span\u2019 parameter will exhibit a statistically significant higher frequency\nof off-topic utterances compared to agents with higher attention spans.\n\u2022 H4 : Agents with a lower \u2018Distractibility Threshold\u2019 will show greater performance degradation in simulated\nenvironments with high levels of external distractions.\n3) The Memory and Decoding Module (Memory Filter):\nTheoretical Grounding: The module is based on the Dual-Route Cascade Model of Reading [11][35], which\nexplains how individuals decode familiar and unfamiliar words. Deficiencies in phonological (sound-based) and\northographic (visual-based) processing, which are often implicated in dyslexia, will be modeled [40]. Furthermore,\nit incorporates principles from Verbal Efficiency Theory [49], which posits that effortful decoding consumes finite\nworking memory resources needed for comprehension.\nOperational Definition: This module acts as a filter that pre-processes text input to the LLM. It is defined by:"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 3,
          "char_start": 0,
          "char_end": 2687,
          "quote": "3 c) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules that dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM that is trained to read this Control Panel and generate behavior that matches the specified cognit...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0003:c0000",
          "chunk_text": "3\nc) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules\nthat dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM\nthat is trained to read this Control Panel and generate behavior that matches the specified cognitive state to simulate\ncore cognitive functions and individual differences. The modules function as follows:\n\u2022 Affect Module (Emotional State Modulator): A state-machine implementation tracking dynamic emotional\nstates (confident, confused, anxious, engaged) based on interaction history and performance outcomes. This\nmodule will modify LLM prompt components in real-time to reflect emotional influences on communication\nstyle, response length, and cognitive processing approach. Here we update the emotion field of the Control\nPanel (e.g., \u201cemotion\u201d: \u201cprimary\u201d: \u201canxious\u201d, \u201cconfidence\u201d: 0.3), which the LLM interprets to modulate its\ncommunication style, response length, and cognitive processing approach.\n\u2022 Attention Module (Focus Manager): A dynamic attention modeling system that simulates varying atten-\ntion spans and distractibility patterns. Drawing from cognitive models of attention and executive function\n[6][56][56], this module will implement time-decay functions for attention, threshold-based coherence degra-\ndation, and attention reset mechanisms triggered by direct engagement or environmental changes. Here we\nupdate the focus field of the Control Panel in real-time (e.g., \u201cfocus\u201d: \u201clevel\u201d: 0.4), which instructs the LLM\nto adjust its response coherence and relevance.\n\u2022 Memory and Decoding Module (Memory Filter): A cognitive processing filter that models information\nprocessing variations, particularly those reflecting a spectrum of information processing speeds and accuracies\n[33][43][19]. This system will introduce controlled character-level noise (e.g., b/d reversals, transposition errors)\nwith probability distributions calibrated to diverse reading patterns, affecting information encoding and retrieval\naccuracy. Here we update the memory field of the Control Panel (e.g., \u201cmemory\u201d: \u201cdecoding fidelity\u201d: 0.85),\naffecting information encoding and retrieval accuracy.\nd) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation\nthrough multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis-\ntency, quantitative analysis of behavioral differentiation between agent types, and integration testing within educa-\ntional simulation environments. We will also explore the proposed \u201cCommittee of Agents\u201d alternative architecture as\nan ablation study,"
        }
      ],
      "severity": "High",
      "actions": [
        "Seek evidence that directly addresses the 'Phonological Noise Parameter' and its impact on LLM internal processing and working memory.",
        "Investigate if the concepts of 'Cognitive Load' or 'Attention Span' from E1 can be mapped to the 'Phonological Noise Parameter' or its effects.",
        "Explore if the 'Affect Module' in E3 has any implications for character-level processing or working memory limitations."
      ]
    },
    {
      "id": "r0007",
      "topic": "What are some areas in which LLms today fail?",
      "claim_id": "c0004",
      "claim_text": "An 'Affect Module' can be implemented to track dynamic emotional states like confidence, confusion, anxiety, and engagement based on interaction history. The emotional valence in an LLM's generated language, assessed through sentiment analysis, can track shifts in its simulated emotional state. Behavioral indicators such as help-seeking frequency, response length, and proactive questioning are used to measure the LLM's simulated behaviors. Human experts, such as educators, evaluate the authenticity of an LLM agent's emotional and motivational trajectory, providing a measure of its simulation fidelity.",
      "summary": "The claim describes an 'Affect Module' for LLMs, but the evidence focuses on validating the believability and consistency of agent personas, not the internal emotional tracking.",
      "detail": "The claim (c0004) posits the implementation of an 'Affect Module' to track dynamic emotional states within an LLM, using sentiment analysis of generated language and behavioral indicators. However, the provided evidence (E1) details a validation phase that includes human expert rating of agent believability and archetype consistency, and quantitative analysis of behavioral differentiation. While this validation aims to assess the *output* of the agent's persona, it does not directly confirm the existence or functionality of an internal 'Affect Module' that dynamically tracks and simulates specific emotional states like confidence, confusion, anxiety, and engagement as described in the claim. The evidence focuses on the *perception* of the agent's persona rather than the internal mechanisms for generating it.",
      "evidence": [
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 3,
          "char_start": 2206,
          "char_end": 4464,
          "quote": "accuracy. d) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation through multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis- tency, quantitative analysis of behavioral differentiation between agent types, and integ...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0003:c0001",
          "chunk_text": "accuracy.\nd) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation\nthrough multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis-\ntency, quantitative analysis of behavioral differentiation between agent types, and integration testing within educa-\ntional simulation environments. We will also explore the proposed \u201cCommittee of Agents\u201d alternative architecture as\nan ablation study, implementing student agents as coordinating processes managing multiple trait-specific sub-agents\nto compare monolithic versus composable persona approaches.\nA. Core Cognitive Module Architecture\nThis section details the design of the three core cognitive modules that form the foundation of our psychologically-\ngrounded student agents. Each module is designed to be a programmable \u201dwrapper\u201d that shapes the LLM\u2019s generative\nprocess, with parameters derived from formalized student archetypes.\n1) The Affective Module (Emotional State Modulator):\nTheoretical Grounding: This module is grounded in Pekrun\u2019s Control-Value Theory of Achievement Emotions\n[47] [48], which links emotions to an individual\u2019s perceived control over and valuation of a task. It also incorporates\nAppraisal Theory [52][44], suggesting that emotions arise from our interpretation of events. This framework allows\nus to model how a \u201cDeep Learner\u201d might react to a challenge with curiosity, while a \u201cSurface Learner\u201d might react\nwith anxiety, based on their underlying motivations [15][25].\nOperational Definition: The module will be a state-machine where states are key achievement emotions (e.g.,\nConfident, Anxious, Engaged, Bored). State transitions are governed by:\n\u2022 Control Appraisal: An internal variable representing perceived self-efficacy, which changes based on perfor-\nmance outcomes and feedback.\n\u2022 Value Appraisal: A parameter derived from the agent\u2019s archetype that defines the intrinsic or extrinsic value\nof a task.\n\u2022 Affective Influence: The current emotional state will dynamically modify the LLM\u2019s meta-prompt in real-time.\nAn \u2018Anxious\u2019 state may add instructions for shorter, more hesitant responses, while an \u2018Engaged\u2019 state may\nprompt for more proactive and detailed contributions."
        }
      ],
      "severity": "High",
      "actions": [
        "Clarify if the 'Affect Module' is a proposed component or an implemented feature.",
        "Provide evidence that directly describes the internal mechanisms for tracking and simulating dynamic emotional states within the LLM.",
        "Explain how sentiment analysis of generated language and behavioral indicators are used to *track* simulated emotional states, not just to *assess* the agent's overall believability."
      ]
    },
    {
      "id": "r0002",
      "topic": "What are some areas in which LLms today fail?",
      "claim_id": "c0001",
      "claim_text": "The probability of an LLM agent losing focus increases as cognitive load, a measure of task complexity, rises, simulating mental fatigue. A 'threshold' parameter can determine how easily an LLM agent is distracted by off-topic comments or complex thoughts, impacting its ability to stay on task. Evaluation metrics like 'Time-on-Task' measure the percentage of conversational turns where an LLM's output remains semantically relevant to the ongoing topic, highlighting potential failures in maintaining focus. The frequency of off-topic utterances serves as a direct count of instances where an LLM deviates from the established conversation, indicating a failure in sustained attention.",
      "summary": "The claim's focus on LLM 'mental fatigue' is not directly supported by the provided evidence, which describes simulated cognitive states rather than actual fatigue.",
      "detail": "The claim uses the term 'mental fatigue' to describe the LLM's loss of focus as cognitive load increases. The evidence, however, details the implementation of an 'Affect Module' that tracks dynamic emotional states like 'confident, confused, anxious, engaged' (E2) and simulates 'decoding difficulties' through a 'Phonological Noise Parameter' (E3). These are simulations of cognitive states and processing challenges, not direct evidence of LLM 'fatigue' in the human sense. The claim's analogy to human mental fatigue is not substantiated by the provided snippets.",
      "evidence": [
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 4,
          "char_start": 0,
          "char_end": 2483,
          "quote": "4 Evaluation Metrics: \u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts. \u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and proactive questioning. \u2022 Human Expert Ratings: Educators will evaluate the authenti...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0000",
          "chunk_text": "4\nEvaluation Metrics:\n\u2022 Emotional Valence in Language: Sentiment analysis of the agent\u2019s generated text to track emotional shifts.\n\u2022 Behavioral Indicators: Measurement of behaviors such as help-seeking frequency, response length, and\nproactive questioning.\n\u2022 Human Expert Ratings: Educators will evaluate the authenticity of the agent\u2019s emotional and motivational\ntrajectory.\nTestable Hypotheses:\n\u2022 H1 : An agent whose \u2018Control Appraisal\u2019 is systematically lowered through negative feedback will transition\nto negative emotional states (e.g., frustration, anxiety) and exhibit a corresponding increase in negative-valence\nlanguage.\n\u2022 H2 : Agents equipped with the Affective Module will be perceived by human raters as demonstrating more\nbelievable and differentiated student personalities than agents defined only by a static dispositional prompt.\n2) The Attention Module (Focus Manager):\nTheoretical Grounding: This module is grounded in hierarchical models of attention that differentiate between\nsustained attention (maintaining focus over time) and selective attention (filtering distractions) [10][50]. It also\ndraws from cognitive models of executive function, such as Baddeley\u2019s model of working memory [5], which\nincludes a central executive responsible for attentional control, and Load Theory of Attention [34] which posits that\nthe ability to ignore distractions depends on the perceptual load of the current task. These concepts are quite central\nto understanding various underlying conditions that affect Attention, such as ADHD [9]. Our model operationalizes\nthese concepts to simulate how an agent\u2019s focus can decay, be captured by competing stimuli, or be reset by direct\nengagement.\nOperational Definition: The module will be a state-based system governed by the following parameters:\n\u2022 Attention Span: A numerical value representing the number of conversational turns an agent can maintain\nfocus on a single topic before a potential \u201cattention lapse.\u201d This will be implemented as a timer that resets\nupon re-engagement.\n\u2022 Distractibility Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 3,
          "char_start": 0,
          "char_end": 2687,
          "quote": "3 c) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules that dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM that is trained to read this Control Panel and generate behavior that matches the specified cognit...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0003:c0000",
          "chunk_text": "3\nc) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules\nthat dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM\nthat is trained to read this Control Panel and generate behavior that matches the specified cognitive state to simulate\ncore cognitive functions and individual differences. The modules function as follows:\n\u2022 Affect Module (Emotional State Modulator): A state-machine implementation tracking dynamic emotional\nstates (confident, confused, anxious, engaged) based on interaction history and performance outcomes. This\nmodule will modify LLM prompt components in real-time to reflect emotional influences on communication\nstyle, response length, and cognitive processing approach. Here we update the emotion field of the Control\nPanel (e.g., \u201cemotion\u201d: \u201cprimary\u201d: \u201canxious\u201d, \u201cconfidence\u201d: 0.3), which the LLM interprets to modulate its\ncommunication style, response length, and cognitive processing approach.\n\u2022 Attention Module (Focus Manager): A dynamic attention modeling system that simulates varying atten-\ntion spans and distractibility patterns. Drawing from cognitive models of attention and executive function\n[6][56][56], this module will implement time-decay functions for attention, threshold-based coherence degra-\ndation, and attention reset mechanisms triggered by direct engagement or environmental changes. Here we\nupdate the focus field of the Control Panel in real-time (e.g., \u201cfocus\u201d: \u201clevel\u201d: 0.4), which instructs the LLM\nto adjust its response coherence and relevance.\n\u2022 Memory and Decoding Module (Memory Filter): A cognitive processing filter that models information\nprocessing variations, particularly those reflecting a spectrum of information processing speeds and accuracies\n[33][43][19]. This system will introduce controlled character-level noise (e.g., b/d reversals, transposition errors)\nwith probability distributions calibrated to diverse reading patterns, affecting information encoding and retrieval\naccuracy. Here we update the memory field of the Control Panel (e.g., \u201cmemory\u201d: \u201cdecoding fidelity\u201d: 0.85),\naffecting information encoding and retrieval accuracy.\nd) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation\nthrough multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis-\ntency, quantitative analysis of behavioral differentiation between agent types, and integration testing within educa-\ntional simulation environments. We will also explore the proposed \u201cCommittee of Agents\u201d alternative architecture as\nan ablation study,"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 5,
          "char_start": 0,
          "char_end": 2714,
          "quote": "5 \u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into the agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties. \u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to ...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0005:c0000",
          "chunk_text": "5\n\u2022 Phonological Noise Parameter: A probability distribution that introduces controlled, character-level errors into\nthe agent\u2019s \u201cinternal reading\u201d of text (e.g., b/d reversals, transposition errors) to simulate decoding difficulties.\n\u2022 Working Memory Buffer: A fixed-size buffer representing the agent\u2019s capacity to hold information. Effortful\ndecoding, as dictated by the noise parameter, will consume space in this buffer, reducing the resources available\nfor higher-level comprehension.\nEvaluation Metrics:\n\u2022 Reading Comprehension Accuracy: Agent performance on simulated comprehension tasks.\n\u2022 Error Analysis: Classification of agent errors into phonological, orthographic, or semantic categories.\n\u2022 Information Recall Fidelity: The accuracy with which an agent can recall facts presented in a passage, testing\nthe integrity of its working memory.\nTestable Hypotheses:\n\u2022 H5 : Agents with a high \u2018Phonological Noise\u2019 parameter will make significantly more phonologically-based\nerrors than agents with a low parameter.\n\u2022 H6 : A reduction in the \u2018Working Memory Buffer\u2019 size will be negatively correlated with an agent\u2019s ability\nto answer questions about long passages of text.\nIV. EXPECTED MILESTONES\nThe project is envisioned as a four-month intensive research program with clearly defined deliverables and\nevaluation checkpoints:\n\u2022 Month 1: Foundation and Architecture\nComplete a systematic review of educational psychology to formalize student archetypes, followed by the\ndesign of the complete Cognitive Twin architecture and development of initial meta-prompts.\nDeliverables: Comprehensive literature analysis, formal archetype specifications, and a complete architectural\ndesign with an initial meta-prompt library.\n\u2022 Month 2: Implementation and Preliminary Validation\nDevelop and implement the three core cognitive processing modules (Affect, Attention, Memory and Decod-\ning). Integrate all system components and conduct preliminary validation studies, including agent behavior\nconsistency testing.\nDeliverables: A functional, integrated system with documented performance characteristics and preliminary\nvalidation results.\n\u2022 Month 3: Comprehensive Evaluation and Alternative Architecture Exploration\nConduct full validation study including human expert evaluation, behavioral differentiation analysis, and\nCommittee of Agents implementation as a comparative study.\nDeliverables: Complete validation results and architectural comparison analysis.\n\u2022 Month 4: Analysis, Documentation, and Dissemination\nAnalyze all collected data, optimize system parameters based on evaluation results, and prepare comprehensive\ndocumentation, including academic paper preparation for submission to relevant conferences"
        }
      ],
      "severity": "Medium",
      "actions": [
        "Clarify if 'mental fatigue' in the claim refers to a simulated state or an emergent property of LLMs.",
        "Find evidence that investigates LLM performance degradation that is analogous to human mental fatigue.",
        "Explore research on the long-term performance and stability of LLMs under sustained operation."
      ]
    },
    {
      "id": "r0004",
      "topic": "What are some areas in which LLms today fail?",
      "claim_id": "c0002",
      "claim_text": "A 'Phonological Noise Parameter' can introduce character-level errors into an LLM's internal text processing, mimicking decoding challenges. These simulated decoding difficulties consume space in a fixed-size 'Working Memory Buffer,' reducing the LLM's capacity for higher-level comprehension. Reading comprehension accuracy is a key metric used to evaluate an LLM's performance on simulated comprehension tasks, revealing potential weaknesses in text processing. The LLM's ability to handle phonological and orthographic processing, including character-level decoding fidelity and working memory for text, is crucial for its overall accuracy.",
      "summary": "The claim emphasizes reading comprehension accuracy as a key metric for evaluating LLM weaknesses, but the evidence does not detail specific evaluation metrics for comprehension.",
      "detail": "The claim highlights 'reading comprehension accuracy' as a crucial metric for revealing LLM weaknesses in text processing. While E1 mentions 'Evaluation Metrics' such as 'Time-on-Task' and 'Frequency of Off-Topic Utterances,' these are related to conversational relevance and attention, not specifically reading comprehension. E2 is a list of citations and does not provide evaluation details. E3 describes implementing cognitive modules to simulate cognitive functions but does not specify how the resulting LLM behavior will be evaluated in terms of reading comprehension.",
      "evidence": [
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 4,
          "char_start": 2056,
          "char_end": 3798,
          "quote": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an off-topic comment, a complex thought) shifting the agent\u2019s focus. \u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum, the probability of an attention lapse increases...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0004:c0001",
          "chunk_text": "Threshold: A value that determines the likelihood of an external or internal stimulus (e.g., an\noff-topic comment, a complex thought) shifting the agent\u2019s focus.\n\u2022 Cognitive Load: A variable that increases with task complexity. As cognitive load approaches its maximum,\nthe probability of an attention lapse increases, simulating mental fatigue.\nEvaluation Metrics:\n\u2022 Time-on-Task: Percentage of conversational turns where the agent\u2019s output is semantically relevant to the\nongoing topic.\n\u2022 Frequency of Off-Topic Utterances: A count of instances where the agent\u2019s output deviates from the\nestablished topic.\n\u2022 Human Expert Ratings: Blind evaluators will rate the believability of an agent\u2019s attentional patterns.\nTestable Hypotheses:\n\u2022 H3 : Agents with a lower \u2018Attention Span\u2019 parameter will exhibit a statistically significant higher frequency\nof off-topic utterances compared to agents with higher attention spans.\n\u2022 H4 : Agents with a lower \u2018Distractibility Threshold\u2019 will show greater performance degradation in simulated\nenvironments with high levels of external distractions.\n3) The Memory and Decoding Module (Memory Filter):\nTheoretical Grounding: The module is based on the Dual-Route Cascade Model of Reading [11][35], which\nexplains how individuals decode familiar and unfamiliar words. Deficiencies in phonological (sound-based) and\northographic (visual-based) processing, which are often implicated in dyslexia, will be modeled [40]. Furthermore,\nit incorporates principles from Verbal Efficiency Theory [49], which posits that effortful decoding consumes finite\nworking memory resources needed for comprehension.\nOperational Definition: This module acts as a filter that pre-processes text input to the LLM. It is defined by:"
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 6,
          "char_start": 4062,
          "char_end": 6037,
          "quote": "Trends in Cognitive Sciences, 9(2):75\u201382, 2005. [35] Jonathan Levy, Tenniel Wydell, Mathew Thomas, John Duncan, Julie Wilson, Michael Richardson, and Catherine J. Mummery. Testing for the dual-route cascade reading model in the brain: An fmri effective connectivity account of an efficient reading style. PLoS ONE, 4(...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0006:c0002",
          "chunk_text": "Trends in Cognitive Sciences, 9(2):75\u201382, 2005.\n[35] Jonathan Levy, Tenniel Wydell, Mathew Thomas, John Duncan, Julie Wilson, Michael Richardson, and Catherine J. Mummery. Testing\nfor the dual-route cascade reading model in the brain: An fmri effective connectivity account of an efficient reading style. PLoS ONE,\n4(8):e6675, 2009.\n[36] GW Lindsay. Attention in psychology, neuroscience, and machine learning. Frontiers in Computational Neuroscience, 14:29, 2020.\n[37] Y. Liu et al. No for some, yes for others: Persona prompts and other sources of false refusal in language models. Semantic Scholar,\n2025.\n[38] M. Llorens-G\u00b4amez and L. Vicent. The impact of the design of learning spaces on attention and memory. Building and Environment,\n207:108483, 2022.\n[39] JM Lodge and G Kennedy. The role of attention in learning in the digital age. NPJ Science of Learning, 4:9, 2019.\n[40] Steven G. Luke, Hazel I. Blythe, James Kirkby, and Gordon Kambe. Dyslexics exhibit an orthographic, not a phonological, deficit:\nEvidence from lexical decision. Frontiers in Psychology, 14:1200329, 2023.\n[41] F. Marton and R. S\u00a8alj\u00a8o. On qualitative differences in learning: Outcome and process. British Journal of Educational Psychology,\n46(1):4\u201311, 1976.\n[42] S. Mart\u00b4\u0131nez-Briones and L. D. Shriberg. Working memory in children with learning disorders. European Child Adolescent Psychiatry,\n2020.\n[43] M. S. Mihaylova et al. Visual noise effect on reading in three developmental disorders: autism spectrum disorder, attention deficit\nhyperactivity disorder, and dyslexia. Scientific Reports, 12(1):18306, 2022.\n[44] Agnes Moors. Appraisal theories of emotion: State of the art and future development. Emotion Review, 5(2):119\u2013124, 2013.\n[45] JP et al. Morais. A general framework for reinforcement learning in cognitive architectures. Journal of Cognitive Neuroscience, 2025.\n[46] M. et al. Muhmenthaler. How attention and knowledge modulate memory. Frontiers in Cognition, 3:1125700, 2023."
        },
        {
          "source_id": "Cognitive_Twins_Practical_Work_Proposal (1)",
          "page": 3,
          "char_start": 0,
          "char_end": 2687,
          "quote": "3 c) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules that dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM that is trained to read this Control Panel and generate behavior that matches the specified cognit...",
          "chunk_id": "Cognitive_Twins_Practical_Work_Proposal (1):p0003:c0000",
          "chunk_text": "3\nc) Phase 3: Core Cognitive Module Implementation: We will implement three primary programmatic modules\nthat dynamically update a structured \u201cControl Panel\u201d input. This strategy leverages an Instruction fine-tuned LLM\nthat is trained to read this Control Panel and generate behavior that matches the specified cognitive state to simulate\ncore cognitive functions and individual differences. The modules function as follows:\n\u2022 Affect Module (Emotional State Modulator): A state-machine implementation tracking dynamic emotional\nstates (confident, confused, anxious, engaged) based on interaction history and performance outcomes. This\nmodule will modify LLM prompt components in real-time to reflect emotional influences on communication\nstyle, response length, and cognitive processing approach. Here we update the emotion field of the Control\nPanel (e.g., \u201cemotion\u201d: \u201cprimary\u201d: \u201canxious\u201d, \u201cconfidence\u201d: 0.3), which the LLM interprets to modulate its\ncommunication style, response length, and cognitive processing approach.\n\u2022 Attention Module (Focus Manager): A dynamic attention modeling system that simulates varying atten-\ntion spans and distractibility patterns. Drawing from cognitive models of attention and executive function\n[6][56][56], this module will implement time-decay functions for attention, threshold-based coherence degra-\ndation, and attention reset mechanisms triggered by direct engagement or environmental changes. Here we\nupdate the focus field of the Control Panel in real-time (e.g., \u201cfocus\u201d: \u201clevel\u201d: 0.4), which instructs the LLM\nto adjust its response coherence and relevance.\n\u2022 Memory and Decoding Module (Memory Filter): A cognitive processing filter that models information\nprocessing variations, particularly those reflecting a spectrum of information processing speeds and accuracies\n[33][43][19]. This system will introduce controlled character-level noise (e.g., b/d reversals, transposition errors)\nwith probability distributions calibrated to diverse reading patterns, affecting information encoding and retrieval\naccuracy. Here we update the memory field of the Control Panel (e.g., \u201cmemory\u201d: \u201cdecoding fidelity\u201d: 0.85),\naffecting information encoding and retrieval accuracy.\nd) Phase 4: Validation and Integration: The complete architecture will undergo comprehensive validation\nthrough multiple evaluation methodologies: human expert blind rating of agent believability and archetype consis-\ntency, quantitative analysis of behavioral differentiation between agent types, and integration testing within educa-\ntional simulation environments. We will also explore the proposed \u201cCommittee of Agents\u201d alternative architecture as\nan ablation study,"
        }
      ],
      "severity": "Medium",
      "actions": [
        "Search for evidence that explicitly discusses the evaluation of LLM reading comprehension accuracy.",
        "Determine if the 'Time-on-Task' or 'Frequency of Off-Topic Utterances' metrics in E1 could indirectly reflect comprehension issues.",
        "Investigate if the 'Human Expert Ratings' mentioned in E1 could be used to assess reading comprehension."
      ]
    }
  ]
}