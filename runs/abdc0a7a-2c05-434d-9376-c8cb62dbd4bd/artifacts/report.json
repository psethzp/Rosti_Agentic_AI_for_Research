{
  "insights": [
    {
      "id": "i0001",
      "topic": "What is wrong with the world?",
      "claim_ids": [
        "c0001",
        "c0002"
      ],
      "summary": "LLMs introduce significant ethical and equity concerns in education due to inherent biases and accessibility barriers.",
      "text": "LLMs can perpetuate and amplify existing societal biases present in their training data, leading to unfair or discriminatory outputs that negatively affect teaching and learning processes (c0001). This bias can exacerbate educational inequalities, particularly for non-English speakers and those with limited financial resources (c0001). Furthermore, the substantial financial burdens associated with training and maintaining LLMs can create disparities in access for educational institutions with limited budgets, necessitating potential governmental intervention for equitable distribution (c0002). The integration of LLMs requires careful consideration of these limitations and the development of strategies to mitigate risks like bias and unfairness, alongside proactive education for students on ethical considerations (c0001).",
      "confidence": 0.9,
      "provenance": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 1,
          "char_start": 2039,
          "char_end": 4249,
          "quote": "students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education. Keywords Large language models \u2014 Artificial Intelligence \u2014 Educati...",
          "chunk_id": "1-ChatGPT_for_Good:p0001:c0001",
          "chunk_text": "students early on with potential\nsocietal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address\nthese challenges and ensure that such models are used in a responsible and ethical manner in education.\nKeywords\nLarge language models \u2014 Artificial Intelligence \u2014 Education \u2014 Educational Technologies\n1Technical University of Munich, Germany\n2Ludwig-Maximilians-Universit\u00a8at M\u00a8unchen, Germany\n3University of T\u00a8ubingen, Germany\n*Corresponding author: Enkelejda.Kasneci@tum.de\n1. Introduction\nLarge language models, such as GPT-3 [1], have made signifi-\ncant advancements in natural language processing (NLP) in\nrecent years. These models are trained on massive amounts\nof text data and are able to generate human-like text, answer\nquestions, and complete other language-related tasks with\nhigh accuracy.\nOne key development in the area is the use of trans-\nformer architectures [2, 3] and the underlying attention mech-\nanism [4], which have greatly improved the ability of auto-\nregressive1 self-supervised2 language models to handle long-\n1Auto-regressive because the model uses its previous predictions as input\nfor new predictions.\n2Self-supervised because they learn from the data itself, rather than being\nexplicitly provided with correct answers as in supervised learning.\nrange dependencies in natural-language texts. The transformer\narchitecture, introduced in [4], uses the self-attention mecha-\nnism to determine the relevance of different parts of the input\nwhen generating predictions. This allows the model to better\nunderstand the relationships between words in a sentence, re-\ngardless of their position.\nAnother important development is the use of pre-training,\nwhere a model is first trained on a large dataset before being\nfine-tuned on a specific task. This has proven to be an effec-\ntive technique for improving performance on a wide range of\nlanguage tasks [5]. For example, BERT [2] is a pre-trained\ntransformer-based encoder model that can be fine-tuned on\nvarious NLP tasks, such as sentence classification, question\nanswering and named entity recognition. In fact, the so-called\nfew-shot learning capability of large language models to be"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 13,
          "char_start": 2063,
          "char_end": 3495,
          "quote": "Luo, and Alexander T. Pearson. Comparing scientific abstracts generated by ChatGPT to original abstracts using an ar- tificial intelligence output detector, plagiarism detector, and blinded human reviewers. bioRxiv, 2022. [60] Debby R.E. Cotton, Peter A. Cotton, and J.Reuben Ship- way. Chatting and Cheating. Ensurin...",
          "chunk_id": "1-ChatGPT_for_Good:p0013:c0001",
          "chunk_text": "Luo, and\nAlexander T. Pearson. Comparing scientific abstracts\ngenerated by ChatGPT to original abstracts using an ar-\ntificial intelligence output detector, plagiarism detector,\nand blinded human reviewers. bioRxiv, 2022.\n[60] Debby R.E. Cotton, Peter A. Cotton, and J.Reuben Ship-\nway. Chatting and Cheating. Ensuring academic integrity\nin the era of ChatGPT. EdArXiv, 2023.\n[61] Dehouche Nassim. Plagiarism in the age of massive\nGenerative Pre-trained Transformers (GPT-3). Ethics in\nScience and Environmental Politics, 21:17\u201323, 2021.\n[62] Kalhan Rosenblatt (NBC News).\nChatGPT banned\nfrom New York City public schools\u2019 devices and net-\nworks. https://nbcnews.to/3iTE0t6, January\n2023. Accessed: 22.01.2023.\n[63] Edward Tian. GPTZero. https://gptzero.me/,\n2023. Accessed: 22.01.2023.\n[64] Chenxi Gu, Chengsong Huang, Xiaoqing Zheng, Kai-Wei\nChang, and Cho-Jui Hsieh. Watermarking Pre-trained\nLanguage Models with Backdooring.\narXiv preprint\narXiv:2210.07543, 2022.\n[65] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan\nKatz, Ian Miers, and Tom Goldstein.\nA Water-\nmark for Large Language Models.\narXiv preprint\narXiv:2301.10226v1, 2023.\n[66] Carol C Kuhlthau, Leslie K Maniotes, and Ann K Caspari.\nGuided inquiry: Learning in the 21st century: Learning\nin the 21st century. Abc-Clio, 2015.\n[67] UNESCO.\nEducation 2030 Agenda.\nhttps://\nwww.unesco.org/en/digital-education/\nartificial-intelligence, 2023.\nAccessed:\n22.01.2023."
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 6,
          "char_start": 3861,
          "char_end": 5568,
          "quote": "con- tent \u2022 Inheritance and detailed terms of use for the content generated by the model \u2022 Informing and raising awareness of the users about these policies Bias and fairness. Large language models can perpetuate and amplify existing biases and unfairness in society, which can negatively impact teaching and learning...",
          "chunk_id": "1-ChatGPT_for_Good:p0006:c0002",
          "chunk_text": "con-\ntent\n\u2022 Inheritance and detailed terms of use for the content\ngenerated by the model\n\u2022 Informing and raising awareness of the users about\nthese policies\nBias and fairness.\nLarge language models can perpetuate\nand amplify existing biases and unfairness in society, which\ncan negatively impact teaching and learning processes and\noutcomes. For example, if a model is trained on data that\nis biased towards certain groups of people, it may produce\nresults that are unfair or discriminatory towards those groups\n(e.g., local knowledge about minorities such as small ethnic\ngroups or cultures can fade into the background). Thus, it is\nimportant to ensure that the training data or the data used for\nfine-tuning on down-stream tasks for the model is diverse and\nrepresentative of different groups of people. Regular monitor-\ning and testing of the model\u2019s performance on different groups\nof people can help identify and address any biases early on.\nHence, human oversight in the process is indispensable and\ncritical for the mitigation of bias and beneficial application of\nlarge language models in education.\nMore specifically, a responsible mitigation strategy would\nfocus on the following key aspects:\n\u2022 A diverse set of data to train or fine-tune the model, to\nensure that it is not biased towards any particular group\n\u2022 Regular monitoring and evaluation of the model\u2019s per-\nformance (on diverse groups of people) to identify and\naddress any biases that may arise\n\u2022 Fairness measures and bias-correction techniques, such\nas pre-processing or post-processing methods\n\u2022 Transparency mechanisms that enable users to compre-\nhend the model\u2019s output, and the data and assumptions\nthat were used to generate it"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 3836,
          "char_end": 5925,
          "quote": "large language models into education must therefore meet stringent privacy, security, and - for sustainable scal- ing - environmental, regulatory and ethical requirements, and must be done in conjunction with ongoing human monitoring, guidance, and critical thinking. While this position paper reflects the optimism o...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0002",
          "chunk_text": "large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in education, it also underscores\nthe need for further research to explore best practices for inte-\ngrating large language models into education and to mitigate\nthe risks identified.\nWe believe that despite many difficulties and challenges,\nthe discussed risks are manageable and should be addressed to\nprovide trustworthy and fair access to large language models\nfor education. Towards this goal, the mitigation strategies\nproposed in this position paper could serve as a starting point.\nReferences\n[1] Luciano Floridi and Massimo Chiriatti. GPT-3: Its nature,\nscope, limits, and consequences. Minds and Machines,\n30(4):681\u2013694, 2020.\n[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. BERT: Pre-training of Deep Bidirec-\ntional Transformers for Language Understanding. arXiv\npreprint arXiv:1810.04805, 2018.\n[3] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Met-\nzler. Efficient transformers: A survey. ACM Computing\nSurveys, 55(6):1\u201328, 2022.\n[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. Advances\nin neural information processing systems, 30, 2017.\n[5] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben\nVeyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre,\nIlana Heinz, and Dan Roth. Recent advances in natural\nlanguage processing via large pre-trained language mod-\nels: A survey. arXiv preprint arXiv:2111.01243, 2021.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-\nbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\net al. Language models are few-shot learners. Advances"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 8,
          "char_start": 1893,
          "char_end": 4239,
          "quote": "this problem. Hence, a reasonable mitigation strategy for this risk should focus on: \u2022 Research on transparency, explanation and analysis techniques and measures to distinguish machine- from human-generated text \u2022 Incentives and support to develop curricula and instruc- tions that require the creative and complement...",
          "chunk_id": "1-ChatGPT_for_Good:p0008:c0001",
          "chunk_text": "this problem.\nHence, a reasonable mitigation strategy for this risk should\nfocus on:\n\u2022 Research on transparency, explanation and analysis\ntechniques and measures to distinguish machine- from\nhuman-generated text\n\u2022 Incentives and support to develop curricula and instruc-\ntions that require the creative and complementary use\nof large language models\nCost of training and maintenance.\nThe maintenance of\nlarge language models could be a financial burden for schools\nand educational institutions, especially those with limited\nbudgets. To address this challenge, the use of pre-trained mod-\nels and cloud technology in combination with cooperative\nschemes for usage in partnership with institutions and com-\npanies can serve as a starting point. Specifically, a mitigation\nstrategy for this risk should focus on the following aspects:\n\u2022 Use of pre-trained open-source models, which can be\nfine-tuned for specific tasks\n\u2022 Development and exploration of partnerships with pri-\nvate companies, research institutions as well as govern-\nmental and non-profit organizations that can provide\nfinancial support, resources and expertise to support the\nuse of large language models in education\n\u2022 Shared costs and cooperative use of scalable (e.g., cloud)\ncomputing services that provide access to powerful\ncomputational resources at a low cost\n\u2022 Use of the model primarily for high-value educational\ntasks, such as providing personalized and targeted learn-\ning experiences for students (i.e., assignment of lower\npriority to low-value tasks)\n\u2022 Research and development of compression, distillation,\nand pruning techniques to reduce the size of the model,\nthe data, and the computational resources required\nData privacy and security.\nThe use of large language mod-\nels in education raises concerns about data privacy and secu-\nrity, as student data is often sensitive and personal. This can\ninclude concerns about data breaches, unauthorized access to\nstudent data, and the use of student data for purposes other\nthan education.\nSome specific focus areas to mitigate privacy and security\nconcerns when using large language models in education are:\n\u2022 Development and implementation of robust data privacy\nand security policies that clearly outline the collection,\nstorage, and use of student data in compliance with\nregulation (e.g., GDPR, HIPAA, FERPA) and"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 8,
          "char_start": 0,
          "char_end": 2311,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 8/13 \u2022 Open educational resources (e.g., tutorials, studies, use cases, etc.) and Guidelines for educators and institu- tions to access and learn about the use of language models in education \u2022 Incentives for collaboration and...",
          "chunk_id": "1-ChatGPT_for_Good:p0008:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 8/13\n\u2022 Open educational resources (e.g., tutorials, studies, use\ncases, etc.) and Guidelines for educators and institu-\ntions to access and learn about the use of language\nmodels in education\n\u2022 Incentives for collaboration and community building\n(e.g., professional learning communities) among edu-\ncators and institutions that are already using language\nmodels in their teaching practice, so they can share their\nknowledge and experience with others\n\u2022 Regular analysis and feedback on the use of language\nmodels to ensure their effective use and make adjust-\nments as necessary\nDifficulty to distinguish model-generated from student\u2013\ngenerated answers.\nIt is becoming increasingly difficult to\ndistinguish whether a text is machine- or human-generated,\npresenting an additional major challenge to teachers and ed-\nucators [58, 59, 60, 61]. As a result, the New York City\u2019s\nDepartment of Education recently banned ChatGPT from\nschools\u2019 devices and networks [62].\nJust recently, Cotton et al. [60] proposed several strate-\ngies to detect work that has been generated by large language\nmodels, and specifically ChatGPT. In addition, tools, such as\nthe recently released GPTZero [63], which uses perplexity,\nas a measure that hints at generalization capabilities (of the\nagent by which the text was written), to detect AI involvement\nin text writing, are expected to provide additional support.\nMore advanced techniques aim at watermarking the content\ngenerated by language models [64, 65], e.g., by biasing the\ncontent generation towards terms, which are rather unlikely\nto be jointly used by humans in a text passage. In the long\nrun, however, we believe that developing curricula and instruc-\ntions that encourage the creative and evidence-based use of\nlarge language models will be the key to solving this problem.\nHence, a reasonable mitigation strategy for this risk should\nfocus on:\n\u2022 Research on transparency, explanation and analysis\ntechniques and measures to distinguish machine- from\nhuman-generated text\n\u2022 Incentives and support to develop curricula and instruc-\ntions that require the creative and complementary use\nof large language models\nCost of training and maintenance.\nThe maintenance of\nlarge language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 1938,
          "char_end": 4252,
          "quote": "users, causing unfair access to such education technologies for non-English speaking users. Despite the efforts of various research communities to address multilingualism fairness for AI technologies, there is still much room for improvement. Lastly, the unfairness related to financial means for access- ing, trainin...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0001",
          "chunk_text": "users, causing unfair access to such education technologies\nfor non-English speaking users. Despite the efforts of various\nresearch communities to address multilingualism fairness for\nAI technologies, there is still much room for improvement.\nLastly, the unfairness related to financial means for access-\ning, training and maintaining large language models may need\nto be regulated by governmental organisations with the aim\nto provide equity-oriented means to all educational entities\ninterested in using these modern technologies. Without fair\naccess, this AI technology may seriously widen the education\ngap like no other technology before it.\nWe therefore conclude with UNESCO\u2019s call to ensure that\nAI does not widen the technological and educational divides\nwithin and between countries, and recommended important\nstrategies for the use of AI in a responsible and fair way to\nreduce this existing gap instead. According to the UNESCO\neducation 2030 Agenda [67]: \u201cUNESCO\u2019s mandate calls in-\nherently for a human-centred approach to AI. It aims to shift\nthe conversation to include AI\u2019s role in addressing current\ninequalities regarding access to knowledge, research and the\ndiversity of cultural expressions and to ensure AI does not\nwiden the technological divides within and between countries.\nThe promise of \u201cAI for all\u201d must be that everyone can take ad-\nvantage of the technological revolution under way and access\nits fruits, notably in terms of innovation and knowledge.\u201d\n6. Concluding Remarks\nThe use of large language models in education is a promising\narea of research that offers many opportunities to enhance the\nlearning experience for students and support the work of teach-\ners. However, to unleash their full potential for education, it is\ncrucial to approach the use of these models with caution and\nto critically evaluate their limitations and potential biases. In-\ntegrating large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 0,
          "char_end": 2363,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 10/13 5. Further Issues Related to User Interfaces and Fair Access Appropriate user interfaces. For the integration of large language models into educational workflows, further research on Human-Computer Interaction and User I...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 10/13\n5. Further Issues Related to User\nInterfaces and Fair Access\nAppropriate user interfaces.\nFor the integration of large\nlanguage models into educational workflows, further research\non Human-Computer Interaction and User Interface Design is\nnecessary.\nIn this work, we have discussed several potential use cases\nfor learners of different age \u2013 from children to adults. While\ncreating such AI-based assistants, we should take into account\nthe degree of psychological maturity, fine motor skills, and\ntechnical abilities of the potential users. Thus, the user in-\nterface should be appropriate for the task, but may also have\nvarying degrees of human imitation \u2013 for instance, for chil-\ndren it might be better to hide machinery artifacts in generated\ntext and use gamified interaction and learning approaches\nas much as possible so as to enable a smooth and engaging\ninteraction with such technologies, whereas for older learn-\ners the machine-based content could be exploited to promote\nproblem-solving, critical thinking and fact-checking abilities.\nIn general, the design of user interfaces for AI-based as-\nsistance and learning tools should promote the development\nof 21st century learning and problem-solving skills [66], espe-\ncially, critical thinking, creativity, communication, and collab-\noration, for which further evidence-based research is needed.\nIn this context, a crucial aspect is the appropriate age- and\nbackground-related integration of AI-based assistance to max-\nimize its benefits and minimize any potential drawbacks.\nMultilingualism and fair access.\nWhile the majority of\nthe research in large language models is done for the En-\nglish language, there is still a gap of research in this field\nfor other languages. This can potentially make education for\nEnglish-speaking users easier and more efficient than for other\nusers, causing unfair access to such education technologies\nfor non-English speaking users. Despite the efforts of various\nresearch communities to address multilingualism fairness for\nAI technologies, there is still much room for improvement.\nLastly, the unfairness related to financial means for access-\ning, training and maintaining large language models may need\nto be regulated by governmental organisations with the aim"
        }
      ]
    },
    {
      "id": "i0002",
      "topic": "What is wrong with the world?",
      "claim_ids": [
        "c0003",
        "c0004",
        "c0001"
      ],
      "summary": "Ensuring the accuracy and responsible use of LLMs in education hinges on robust verification processes and a balanced approach with human expertise.",
      "text": "The accuracy and integrity of information provided by LLMs are paramount, requiring verification through multiple authoritative sources and human expertise, such as teachers or subject matter experts (c0003). While LLMs can offer valuable assistance by providing resources, summaries, and explanations of new teaching methodologies (c0004), their outputs must be reviewed and validated by humans (c0003). The claim that LLMs can negatively impact critical thinking and problem-solving skills is supported, indicating a need for further detail on mitigation strategies (c0001). Responsible use necessitates clear protocols and standards for fact-checking and corroborating LLM-generated information (c0003), and LLMs should be used in conjunction with, rather than as a replacement for, human instruction and the development of critical thinking (c0004).",
      "confidence": 0.85,
      "provenance": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 9,
          "char_start": 2010,
          "char_end": 4288,
          "quote": "it is providing up-to-date and accurate information \u2022 Use of multiple authoritative sources to verify the in- formation provided by the model to ensure correctness and integrity \u2022 Use of the model in conjunction with human expertise, e.g., teachers or subject matter experts, who review and validate the information p...",
          "chunk_id": "1-ChatGPT_for_Good:p0009:c0001",
          "chunk_text": "it is providing up-to-date and\naccurate information\n\u2022 Use of multiple authoritative sources to verify the in-\nformation provided by the model to ensure correctness\nand integrity\n\u2022 Use of the model in conjunction with human expertise,\ne.g., teachers or subject matter experts, who review and\nvalidate the information provided by the model\n\u2022 Development of protocol and standards for fact-checking\nand corroborating information provided by the model\n\u2022 Provide clear and transparent information on the model\u2019s\nperformance, what it is or is not capable of, and the con-\nditions under which it operates.\n\u2022 Training and resources for educators and learners on\nhow to use the model, interpret its results and evaluate\nthe information provided\n\u2022 Regular review and evaluation of the model with trans-\nparent reporting on the model\u2019s performance, i.e., what\nit is or is not capable of and the identification of con-\nditions under which inaccuracies or other issues may\narise\nDifficulty to distinguish between real knowledge and con-\nvincingly written but unverified model output.\nThe abil-\nity of large language models to generate human-like text can\nmake it difficult for students to distinguish between real knowl-\nedge and unverified information. This can lead to students\naccepting false or misleading information as true, without\nquestioning its validity.\nTo mitigate this risk, in addition to the above verification-\nand integrity-related mitigation strategy, it is important to pro-\nvide education on how information can be evaluated critically\nand teach students exploration, investigation, verification, and\ncorroboration strategies.\nLack of adaptability.\nLarge language models are not able to\nadapt to the diverse needs of students and teachers, and may\nnot be able to provide the level of personalization required for\neffective learning. This is a limitation of the current technol-\nogy, but it is conceivable that with more advanced models, the\nadaptability will increase.\nMore specifically, a sensible mitigation strategy would be\ncomprised of:\n\u2022 Use of adaptive learning technologies to personalize the\noutput of the model to the needs of individual students\nby using student data (e.g., about learning style, prior\nknowledge, and performance, etc.)\n\u2022 Customization of the"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 9,
          "char_start": 3895,
          "char_end": 5102,
          "quote": "ogy, but it is conceivable that with more advanced models, the adaptability will increase. More specifically, a sensible mitigation strategy would be comprised of: \u2022 Use of adaptive learning technologies to personalize the output of the model to the needs of individual students by using student data (e.g., about lea...",
          "chunk_id": "1-ChatGPT_for_Good:p0009:c0002",
          "chunk_text": "ogy, but it is conceivable that with more advanced models, the\nadaptability will increase.\nMore specifically, a sensible mitigation strategy would be\ncomprised of:\n\u2022 Use of adaptive learning technologies to personalize the\noutput of the model to the needs of individual students\nby using student data (e.g., about learning style, prior\nknowledge, and performance, etc.)\n\u2022 Customization of the language model\u2019s output to align\nwith the teaching style and curriculum (by using data\nprovided by the teacher)\n\u2022 Use of multi-modal learning and teaching approaches,\nwhich combine text, audio, video, and experimentation\nto provide a more engaging and personalized experience\nfor students and teachers\n\u2022 Use of hybrid approaches, which combine the strengths\nof both human teachers and language models to gener-\nate targeted and personalized learning materials (based\non feedback, guidance, and support provided by the\nteachers)\n\u2022 Regular review of the model and continual improve-\nment for curriculum-related uses cases to ensure ade-\nquate and accurate functioning for education purposes\n\u2022 Research and development to create more advanced\nmodels that can better adapt to the diverse needs of\nstudents and teachers"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 3847,
          "char_end": 5202,
          "quote": "in their teaching [56]. This particularly applies to the use and integration of large language models into teaching practice. Educational theory has long since suggested ways of integrating novel tools into educational practice (e.g., [57]). As with any other technological innovation, integrating large language mode...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0002",
          "chunk_text": "in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to effectively use\nthem to supplement or enhance specific learning processes.\nThere are several ways to address these challenges and\nencounter this risk:\n\u2022 Research on the challenges of large language models in\neducation by investigating existing educational models\nof technology integration, students\u2019 learning processes\nand transfer them to the context of large language mod-\nels, as well as developing a new educational theory\nspecifically for the context of large language models\n\u2022 Assessing the needs of the educators and students and\nprovide case-based guidance (e.g., for the secure ethical\nuse of large language models in education scenarios)\n\u2022 Demand-oriented Training and professional develop-\nment opportunities for educators and institutions to\nlearn about the capabilities and potential uses of large\nlanguage models in education, as well as providing\nbest practices for integrating them into their teaching\nmethods"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 5772,
          "char_end": 6441,
          "quote": "as speech therapists, educators, and other specialists that can adapt the technology to the specific needs of the learner\u2019s disabilities. For professional training, large language models can assist in the development of language skills that are specific to a particular field of work. They can also assist in the deve...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0003",
          "chunk_text": "as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision making and problem-solving.\nFor example, large language models can be fine-tuned on\na domain-specific corpus (e.g. legal, medical, IT) in order\nto generate domain-specific language and assist learners in\nwriting technical reports, legal documents, medical records etc."
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 0,
          "char_end": 2323,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 2/13 efficiently adapted to down-stream tasks or even other seem- ingly unrelated tasks (e.g., as in transfer learning) has been empirically observed and studied for various natural-language tasks [6], e.g., more recently in t...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 2/13\nefficiently adapted to down-stream tasks or even other seem-\ningly unrelated tasks (e.g., as in transfer learning) has been\nempirically observed and studied for various natural-language\ntasks [6], e.g., more recently in the context of generating\nsynthetic and yet realistic heterogeneous tabular data [7].\nRecent advancements also include GPT-3 [1] and Chat-\nGPT [8], which were trained on a much larger datasets, i.e.,\ntexts from a very large web corpus, and have demonstrated\nstate-of-the-art performance on a wide range of natural-language\ntasks ranging from translation to question answering, writ-\ning coherent essays, and computer programs. Additionally,\nextensive research has been conducted on fine-tuning these\nmodels on smaller datasets and applying transfer learning to\nnew problems. This allows for improved performance on\nspecific tasks with smaller amount of data.\nWhile large language models have made great strides in\nrecent years, there are still many limitations that need to be\naddressed. One major limitation is the lack of interpretabil-\nity, as it is difficult to understand the reasoning behind the\nmodel\u2019s predictions. There are ethical considerations, such\nas concerns about bias and the impact of these models, e.g.,\non employment, risks of misuse and inadequate or unethical\ndeployment, loss of integrity, and many more. Overall, large\nlanguage models will continue to push the boundaries of what\nis possible in natural language processing. However, there\nis still much work to be done in terms of addressing their\nlimitations and the related ethical considerations.\n1.1 Opportunities for Learning\nThe use of large language models in education has been iden-\ntified as a potential area of interest due to the diverse range of\napplications they offer. Through the utilization of these mod-\nels, opportunities for enhancement of learning and teaching\nexperiences may be possible for individuals at all levels of edu-\ncation, including primary, secondary, tertiary and professional\ndevelopment.\nFor elementary school students, large language models\ncan assist in the development of reading and writing skills\n(e.g., by suggesting syntactic and grammatical corrections), as\nwell as in the development of"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 1,
          "char_start": 2039,
          "char_end": 4249,
          "quote": "students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education. Keywords Large language models \u2014 Artificial Intelligence \u2014 Educati...",
          "chunk_id": "1-ChatGPT_for_Good:p0001:c0001",
          "chunk_text": "students early on with potential\nsocietal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address\nthese challenges and ensure that such models are used in a responsible and ethical manner in education.\nKeywords\nLarge language models \u2014 Artificial Intelligence \u2014 Education \u2014 Educational Technologies\n1Technical University of Munich, Germany\n2Ludwig-Maximilians-Universit\u00a8at M\u00a8unchen, Germany\n3University of T\u00a8ubingen, Germany\n*Corresponding author: Enkelejda.Kasneci@tum.de\n1. Introduction\nLarge language models, such as GPT-3 [1], have made signifi-\ncant advancements in natural language processing (NLP) in\nrecent years. These models are trained on massive amounts\nof text data and are able to generate human-like text, answer\nquestions, and complete other language-related tasks with\nhigh accuracy.\nOne key development in the area is the use of trans-\nformer architectures [2, 3] and the underlying attention mech-\nanism [4], which have greatly improved the ability of auto-\nregressive1 self-supervised2 language models to handle long-\n1Auto-regressive because the model uses its previous predictions as input\nfor new predictions.\n2Self-supervised because they learn from the data itself, rather than being\nexplicitly provided with correct answers as in supervised learning.\nrange dependencies in natural-language texts. The transformer\narchitecture, introduced in [4], uses the self-attention mecha-\nnism to determine the relevance of different parts of the input\nwhen generating predictions. This allows the model to better\nunderstand the relationships between words in a sentence, re-\ngardless of their position.\nAnother important development is the use of pre-training,\nwhere a model is first trained on a large dataset before being\nfine-tuned on a specific task. This has proven to be an effec-\ntive technique for improving performance on a wide range of\nlanguage tasks [5]. For example, BERT [2] is a pre-trained\ntransformer-based encoder model that can be fine-tuned on\nvarious NLP tasks, such as sentence classification, question\nanswering and named entity recognition. In fact, the so-called\nfew-shot learning capability of large language models to be"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 13,
          "char_start": 2063,
          "char_end": 3495,
          "quote": "Luo, and Alexander T. Pearson. Comparing scientific abstracts generated by ChatGPT to original abstracts using an ar- tificial intelligence output detector, plagiarism detector, and blinded human reviewers. bioRxiv, 2022. [60] Debby R.E. Cotton, Peter A. Cotton, and J.Reuben Ship- way. Chatting and Cheating. Ensurin...",
          "chunk_id": "1-ChatGPT_for_Good:p0013:c0001",
          "chunk_text": "Luo, and\nAlexander T. Pearson. Comparing scientific abstracts\ngenerated by ChatGPT to original abstracts using an ar-\ntificial intelligence output detector, plagiarism detector,\nand blinded human reviewers. bioRxiv, 2022.\n[60] Debby R.E. Cotton, Peter A. Cotton, and J.Reuben Ship-\nway. Chatting and Cheating. Ensuring academic integrity\nin the era of ChatGPT. EdArXiv, 2023.\n[61] Dehouche Nassim. Plagiarism in the age of massive\nGenerative Pre-trained Transformers (GPT-3). Ethics in\nScience and Environmental Politics, 21:17\u201323, 2021.\n[62] Kalhan Rosenblatt (NBC News).\nChatGPT banned\nfrom New York City public schools\u2019 devices and net-\nworks. https://nbcnews.to/3iTE0t6, January\n2023. Accessed: 22.01.2023.\n[63] Edward Tian. GPTZero. https://gptzero.me/,\n2023. Accessed: 22.01.2023.\n[64] Chenxi Gu, Chengsong Huang, Xiaoqing Zheng, Kai-Wei\nChang, and Cho-Jui Hsieh. Watermarking Pre-trained\nLanguage Models with Backdooring.\narXiv preprint\narXiv:2210.07543, 2022.\n[65] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan\nKatz, Ian Miers, and Tom Goldstein.\nA Water-\nmark for Large Language Models.\narXiv preprint\narXiv:2301.10226v1, 2023.\n[66] Carol C Kuhlthau, Leslie K Maniotes, and Ann K Caspari.\nGuided inquiry: Learning in the 21st century: Learning\nin the 21st century. Abc-Clio, 2015.\n[67] UNESCO.\nEducation 2030 Agenda.\nhttps://\nwww.unesco.org/en/digital-education/\nartificial-intelligence, 2023.\nAccessed:\n22.01.2023."
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 6,
          "char_start": 3861,
          "char_end": 5568,
          "quote": "con- tent \u2022 Inheritance and detailed terms of use for the content generated by the model \u2022 Informing and raising awareness of the users about these policies Bias and fairness. Large language models can perpetuate and amplify existing biases and unfairness in society, which can negatively impact teaching and learning...",
          "chunk_id": "1-ChatGPT_for_Good:p0006:c0002",
          "chunk_text": "con-\ntent\n\u2022 Inheritance and detailed terms of use for the content\ngenerated by the model\n\u2022 Informing and raising awareness of the users about\nthese policies\nBias and fairness.\nLarge language models can perpetuate\nand amplify existing biases and unfairness in society, which\ncan negatively impact teaching and learning processes and\noutcomes. For example, if a model is trained on data that\nis biased towards certain groups of people, it may produce\nresults that are unfair or discriminatory towards those groups\n(e.g., local knowledge about minorities such as small ethnic\ngroups or cultures can fade into the background). Thus, it is\nimportant to ensure that the training data or the data used for\nfine-tuning on down-stream tasks for the model is diverse and\nrepresentative of different groups of people. Regular monitor-\ning and testing of the model\u2019s performance on different groups\nof people can help identify and address any biases early on.\nHence, human oversight in the process is indispensable and\ncritical for the mitigation of bias and beneficial application of\nlarge language models in education.\nMore specifically, a responsible mitigation strategy would\nfocus on the following key aspects:\n\u2022 A diverse set of data to train or fine-tune the model, to\nensure that it is not biased towards any particular group\n\u2022 Regular monitoring and evaluation of the model\u2019s per-\nformance (on diverse groups of people) to identify and\naddress any biases that may arise\n\u2022 Fairness measures and bias-correction techniques, such\nas pre-processing or post-processing methods\n\u2022 Transparency mechanisms that enable users to compre-\nhend the model\u2019s output, and the data and assumptions\nthat were used to generate it"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 3836,
          "char_end": 5925,
          "quote": "large language models into education must therefore meet stringent privacy, security, and - for sustainable scal- ing - environmental, regulatory and ethical requirements, and must be done in conjunction with ongoing human monitoring, guidance, and critical thinking. While this position paper reflects the optimism o...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0002",
          "chunk_text": "large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in education, it also underscores\nthe need for further research to explore best practices for inte-\ngrating large language models into education and to mitigate\nthe risks identified.\nWe believe that despite many difficulties and challenges,\nthe discussed risks are manageable and should be addressed to\nprovide trustworthy and fair access to large language models\nfor education. Towards this goal, the mitigation strategies\nproposed in this position paper could serve as a starting point.\nReferences\n[1] Luciano Floridi and Massimo Chiriatti. GPT-3: Its nature,\nscope, limits, and consequences. Minds and Machines,\n30(4):681\u2013694, 2020.\n[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. BERT: Pre-training of Deep Bidirec-\ntional Transformers for Language Understanding. arXiv\npreprint arXiv:1810.04805, 2018.\n[3] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Met-\nzler. Efficient transformers: A survey. ACM Computing\nSurveys, 55(6):1\u201328, 2022.\n[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. Advances\nin neural information processing systems, 30, 2017.\n[5] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben\nVeyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre,\nIlana Heinz, and Dan Roth. Recent advances in natural\nlanguage processing via large pre-trained language mod-\nels: A survey. arXiv preprint arXiv:2111.01243, 2021.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-\nbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\net al. Language models are few-shot learners. Advances"
        }
      ]
    },
    {
      "id": "i0003",
      "topic": "What is wrong with the world?",
      "claim_ids": [
        "c0004",
        "c0003"
      ],
      "summary": "The potential benefits of LLMs in education are substantial, offering personalized learning and support for educators, but require careful implementation.",
      "text": "LLMs possess the capability to assist teachers by providing resources, summaries, and explanations of new teaching methodologies and technologies, thereby helping educators stay current (c0004). These models can be adapted to specific learner needs, including those with disabilities, and can aid in developing domain-specific language skills for professional training (c0004). Moreover, LLMs can support the development of crucial skills such as programming, report writing, project management, decision making, and problem-solving (c0004). Adaptive learning technologies can further personalize LLM outputs to individual student needs, considering factors like learning style, prior knowledge, and performance (c0003). The adaptability of LLMs allows them to be fine-tuned on domain-specific corpora to generate relevant language and assist learners in specialized fields (c0004).",
      "confidence": 0.95,
      "provenance": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 5772,
          "char_end": 6441,
          "quote": "as speech therapists, educators, and other specialists that can adapt the technology to the specific needs of the learner\u2019s disabilities. For professional training, large language models can assist in the development of language skills that are specific to a particular field of work. They can also assist in the deve...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0003",
          "chunk_text": "as speech\ntherapists, educators, and other specialists that can adapt the\ntechnology to the specific needs of the learner\u2019s disabilities.\nFor professional training, large language models can\nassist in the development of language skills that are specific\nto a particular field of work. They can also assist in the\ndevelopment of skills such as programming, report writing,\nproject management, decision making and problem-solving.\nFor example, large language models can be fine-tuned on\na domain-specific corpus (e.g. legal, medical, IT) in order\nto generate domain-specific language and assist learners in\nwriting technical reports, legal documents, medical records etc."
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 2,
          "char_start": 0,
          "char_end": 2323,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 2/13 efficiently adapted to down-stream tasks or even other seem- ingly unrelated tasks (e.g., as in transfer learning) has been empirically observed and studied for various natural-language tasks [6], e.g., more recently in t...",
          "chunk_id": "1-ChatGPT_for_Good:p0002:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 2/13\nefficiently adapted to down-stream tasks or even other seem-\ningly unrelated tasks (e.g., as in transfer learning) has been\nempirically observed and studied for various natural-language\ntasks [6], e.g., more recently in the context of generating\nsynthetic and yet realistic heterogeneous tabular data [7].\nRecent advancements also include GPT-3 [1] and Chat-\nGPT [8], which were trained on a much larger datasets, i.e.,\ntexts from a very large web corpus, and have demonstrated\nstate-of-the-art performance on a wide range of natural-language\ntasks ranging from translation to question answering, writ-\ning coherent essays, and computer programs. Additionally,\nextensive research has been conducted on fine-tuning these\nmodels on smaller datasets and applying transfer learning to\nnew problems. This allows for improved performance on\nspecific tasks with smaller amount of data.\nWhile large language models have made great strides in\nrecent years, there are still many limitations that need to be\naddressed. One major limitation is the lack of interpretabil-\nity, as it is difficult to understand the reasoning behind the\nmodel\u2019s predictions. There are ethical considerations, such\nas concerns about bias and the impact of these models, e.g.,\non employment, risks of misuse and inadequate or unethical\ndeployment, loss of integrity, and many more. Overall, large\nlanguage models will continue to push the boundaries of what\nis possible in natural language processing. However, there\nis still much work to be done in terms of addressing their\nlimitations and the related ethical considerations.\n1.1 Opportunities for Learning\nThe use of large language models in education has been iden-\ntified as a potential area of interest due to the diverse range of\napplications they offer. Through the utilization of these mod-\nels, opportunities for enhancement of learning and teaching\nexperiences may be possible for individuals at all levels of edu-\ncation, including primary, secondary, tertiary and professional\ndevelopment.\nFor elementary school students, large language models\ncan assist in the development of reading and writing skills\n(e.g., by suggesting syntactic and grammatical corrections), as\nwell as in the development of"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 9,
          "char_start": 2010,
          "char_end": 4288,
          "quote": "it is providing up-to-date and accurate information \u2022 Use of multiple authoritative sources to verify the in- formation provided by the model to ensure correctness and integrity \u2022 Use of the model in conjunction with human expertise, e.g., teachers or subject matter experts, who review and validate the information p...",
          "chunk_id": "1-ChatGPT_for_Good:p0009:c0001",
          "chunk_text": "it is providing up-to-date and\naccurate information\n\u2022 Use of multiple authoritative sources to verify the in-\nformation provided by the model to ensure correctness\nand integrity\n\u2022 Use of the model in conjunction with human expertise,\ne.g., teachers or subject matter experts, who review and\nvalidate the information provided by the model\n\u2022 Development of protocol and standards for fact-checking\nand corroborating information provided by the model\n\u2022 Provide clear and transparent information on the model\u2019s\nperformance, what it is or is not capable of, and the con-\nditions under which it operates.\n\u2022 Training and resources for educators and learners on\nhow to use the model, interpret its results and evaluate\nthe information provided\n\u2022 Regular review and evaluation of the model with trans-\nparent reporting on the model\u2019s performance, i.e., what\nit is or is not capable of and the identification of con-\nditions under which inaccuracies or other issues may\narise\nDifficulty to distinguish between real knowledge and con-\nvincingly written but unverified model output.\nThe abil-\nity of large language models to generate human-like text can\nmake it difficult for students to distinguish between real knowl-\nedge and unverified information. This can lead to students\naccepting false or misleading information as true, without\nquestioning its validity.\nTo mitigate this risk, in addition to the above verification-\nand integrity-related mitigation strategy, it is important to pro-\nvide education on how information can be evaluated critically\nand teach students exploration, investigation, verification, and\ncorroboration strategies.\nLack of adaptability.\nLarge language models are not able to\nadapt to the diverse needs of students and teachers, and may\nnot be able to provide the level of personalization required for\neffective learning. This is a limitation of the current technol-\nogy, but it is conceivable that with more advanced models, the\nadaptability will increase.\nMore specifically, a sensible mitigation strategy would be\ncomprised of:\n\u2022 Use of adaptive learning technologies to personalize the\noutput of the model to the needs of individual students\nby using student data (e.g., about learning style, prior\nknowledge, and performance, etc.)\n\u2022 Customization of the"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 9,
          "char_start": 3895,
          "char_end": 5102,
          "quote": "ogy, but it is conceivable that with more advanced models, the adaptability will increase. More specifically, a sensible mitigation strategy would be comprised of: \u2022 Use of adaptive learning technologies to personalize the output of the model to the needs of individual students by using student data (e.g., about lea...",
          "chunk_id": "1-ChatGPT_for_Good:p0009:c0002",
          "chunk_text": "ogy, but it is conceivable that with more advanced models, the\nadaptability will increase.\nMore specifically, a sensible mitigation strategy would be\ncomprised of:\n\u2022 Use of adaptive learning technologies to personalize the\noutput of the model to the needs of individual students\nby using student data (e.g., about learning style, prior\nknowledge, and performance, etc.)\n\u2022 Customization of the language model\u2019s output to align\nwith the teaching style and curriculum (by using data\nprovided by the teacher)\n\u2022 Use of multi-modal learning and teaching approaches,\nwhich combine text, audio, video, and experimentation\nto provide a more engaging and personalized experience\nfor students and teachers\n\u2022 Use of hybrid approaches, which combine the strengths\nof both human teachers and language models to gener-\nate targeted and personalized learning materials (based\non feedback, guidance, and support provided by the\nteachers)\n\u2022 Regular review of the model and continual improve-\nment for curriculum-related uses cases to ensure ade-\nquate and accurate functioning for education purposes\n\u2022 Research and development to create more advanced\nmodels that can better adapt to the diverse needs of\nstudents and teachers"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 3847,
          "char_end": 5202,
          "quote": "in their teaching [56]. This particularly applies to the use and integration of large language models into teaching practice. Educational theory has long since suggested ways of integrating novel tools into educational practice (e.g., [57]). As with any other technological innovation, integrating large language mode...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0002",
          "chunk_text": "in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to effectively use\nthem to supplement or enhance specific learning processes.\nThere are several ways to address these challenges and\nencounter this risk:\n\u2022 Research on the challenges of large language models in\neducation by investigating existing educational models\nof technology integration, students\u2019 learning processes\nand transfer them to the context of large language mod-\nels, as well as developing a new educational theory\nspecifically for the context of large language models\n\u2022 Assessing the needs of the educators and students and\nprovide case-based guidance (e.g., for the secure ethical\nuse of large language models in education scenarios)\n\u2022 Demand-oriented Training and professional develop-\nment opportunities for educators and institutions to\nlearn about the capabilities and potential uses of large\nlanguage models in education, as well as providing\nbest practices for integrating them into their teaching\nmethods"
        }
      ]
    }
  ],
  "actions": [
    {
      "id": "a0001",
      "topic": "What is wrong with the world?",
      "title": "Develop a Framework for Equitable LLM Access and Training",
      "detail": "Given the financial burdens associated with LLM training and maintenance (c0002) and the potential for exacerbating inequalities for non-English speakers and those with limited financial resources (c0001), we need to explore models for subsidized access or open-source alternatives for educational institutions. This could involve investigating public-private partnerships, grant programs, or the development of more resource-efficient LLM architectures specifically for educational use.",
      "tag": "Hypothesis",
      "related_claims": [
        "c0002",
        "c0001"
      ]
    },
    {
      "id": "a0002",
      "topic": "What is wrong with the world?",
      "title": "Investigate the Nuances of LLM Impact on Critical Thinking and Problem-Solving",
      "detail": "While LLMs can assist in developing skills like problem-solving (c0004), there's a challenge that the extent and mitigation strategies for their negative impact on critical thinking require further detail (c0001 challenge). We need to conduct research to understand *how* LLMs might hinder critical thinking and identify specific pedagogical approaches and LLM usage guidelines that foster, rather than diminish, these skills. This could involve comparative studies of student outcomes with different LLM integration strategies.",
      "tag": "NextStep",
      "related_claims": [
        "c0004",
        "c0001"
      ]
    },
    {
      "id": "a0003",
      "topic": "What is wrong with the world?",
      "title": "Clarify the Practical Implementation of LLM Verification Protocols",
      "detail": "The claim emphasizes the need for human oversight and verification of LLM outputs (c0003), but the evidence primarily focuses on benefits without detailing the verification process (c0003 challenge). We need to develop and pilot concrete, actionable protocols for educators and students to fact-check and corroborate LLM-generated information. This could include creating checklists, training modules on critical evaluation of AI outputs, and identifying authoritative sources for cross-referencing.",
      "tag": "Clarification",
      "related_claims": [
        "c0003",
        "c0004"
      ]
    },
    {
      "id": "a0004",
      "topic": "What is wrong with the world?",
      "title": "Explore LLM Adaptability for Diverse Learning Needs Beyond Language",
      "detail": "LLMs can be adapted for specific learner needs, including those with disabilities, and for domain-specific language skills (c0004). We should hypothesize and test the extent to which LLMs can be effectively fine-tuned to support a wider range of diverse learning needs, such as different cognitive styles, learning paces, and socio-cultural backgrounds, beyond just language barriers. This would involve developing and evaluating specialized LLM models or prompt engineering techniques for these specific contexts.",
      "tag": "Hypothesis",
      "related_claims": [
        "c0004"
      ]
    }
  ],
  "challenges": [
    {
      "id": "r0001",
      "topic": "What is wrong with the world?",
      "claim_id": "c0001",
      "claim_text": "LLMs can amplify existing biases present in their training data, leading to unfair or discriminatory outputs that negatively impact teaching and learning processes. The ability of LLMs to generate human-like text raises concerns about academic integrity, as evidenced by issues like plagiarism in the age of generative AI. Educational institutions must proactively address these risks by educating students about the potential societal biases and ethical considerations associated with AI applications. The integration of LLMs into education requires careful consideration of their limitations and the development of strategies to mitigate risks, such as bias and unfairness.",
      "summary": "LLMs can exacerbate educational inequalities by creating barriers for non-English speakers and those lacking financial resources.",
      "detail": "Evidence E2 highlights that LLMs can lead to unfair access to educational technologies for non-English speaking users, and that financial disparities in accessing, training, and maintaining these models could widen the education gap. This contradicts the general positive framing of LLMs in education by pointing to a significant accessibility and equity issue that needs governmental regulation to ensure fair access for all educational entities.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 1938,
          "char_end": 4252,
          "quote": "users, causing unfair access to such education technologies for non-English speaking users. Despite the efforts of various research communities to address multilingualism fairness for AI technologies, there is still much room for improvement. Lastly, the unfairness related to financial means for access- ing, trainin...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0001",
          "chunk_text": "users, causing unfair access to such education technologies\nfor non-English speaking users. Despite the efforts of various\nresearch communities to address multilingualism fairness for\nAI technologies, there is still much room for improvement.\nLastly, the unfairness related to financial means for access-\ning, training and maintaining large language models may need\nto be regulated by governmental organisations with the aim\nto provide equity-oriented means to all educational entities\ninterested in using these modern technologies. Without fair\naccess, this AI technology may seriously widen the education\ngap like no other technology before it.\nWe therefore conclude with UNESCO\u2019s call to ensure that\nAI does not widen the technological and educational divides\nwithin and between countries, and recommended important\nstrategies for the use of AI in a responsible and fair way to\nreduce this existing gap instead. According to the UNESCO\neducation 2030 Agenda [67]: \u201cUNESCO\u2019s mandate calls in-\nherently for a human-centred approach to AI. It aims to shift\nthe conversation to include AI\u2019s role in addressing current\ninequalities regarding access to knowledge, research and the\ndiversity of cultural expressions and to ensure AI does not\nwiden the technological divides within and between countries.\nThe promise of \u201cAI for all\u201d must be that everyone can take ad-\nvantage of the technological revolution under way and access\nits fruits, notably in terms of innovation and knowledge.\u201d\n6. Concluding Remarks\nThe use of large language models in education is a promising\narea of research that offers many opportunities to enhance the\nlearning experience for students and support the work of teach-\ners. However, to unleash their full potential for education, it is\ncrucial to approach the use of these models with caution and\nto critically evaluate their limitations and potential biases. In-\ntegrating large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in"
        }
      ],
      "severity": "High",
      "actions": [
        "Investigate specific examples of LLM-driven educational tools that disadvantage non-English speakers.",
        "Research existing or proposed governmental regulations aimed at ensuring equitable access to AI in education.",
        "Explore the financial models and costs associated with developing and deploying LLMs for educational purposes."
      ]
    },
    {
      "id": "r0003",
      "topic": "What is wrong with the world?",
      "claim_id": "c0002",
      "claim_text": "Financial burdens associated with training and maintaining LLMs can create disparities in access for educational institutions with limited budgets. Fair access to LLM technologies is crucial, and governmental organizations may need to intervene to provide equitable means for all educational entities. Further research into Human-Computer Interaction and User Interface Design is necessary to create effective AI-based assistants for learners of all ages. Incentives for collaboration and community building among educators can facilitate the sharing of knowledge and experience in using LLMs in teaching.",
      "summary": "The claim focuses on financial burdens and access disparities for educational institutions, while the evidence highlights energy consumption and environmental sustainability as key challenges for LLMs.",
      "detail": "The claim (c0002) asserts that the financial burdens of training and maintaining LLMs create disparities in access for educational institutions with limited budgets, suggesting governmental intervention. However, the provided evidence (E1) focuses on the high computational demands of LLMs leading to significant energy consumption and the need for sustainable operation through energy-efficient hardware and renewable energy infrastructure. While both touch on the practicalities of LLM deployment, the core concern of financial access versus environmental impact is not directly addressed in relation to each other.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 9,
          "char_start": 0,
          "char_end": 2392,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 9/13 Sustainable usage. Large language models have high com- putational demands, which can result in high energy consump- tion. Hence, energy-efficient hardware and shared (e.g., cloud) infrastructure based on renewable energy...",
          "chunk_id": "1-ChatGPT_for_Good:p0009:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 9/13\nSustainable usage.\nLarge language models have high com-\nputational demands, which can result in high energy consump-\ntion. Hence, energy-efficient hardware and shared (e.g., cloud)\ninfrastructure based on renewable energy are crucial for their\nenvironmentally sustainable operation and scaling needed in\nthe context of education.\nFor model training and updates, only data that has been\ncollected and annotated in a regulatory compliant and ethical\nway should be considered. Therefore, governance frameworks\nthat include policies, procedures, and controls to ensure such\nappropriate use of such models are key to their successful\nadoption.\nLikewise, for the long-term trustworthy and responsible\nuse of the models, transparency, bias mitigation, and ongoing\nmonitoring are indispensable.\nIn summary, the mitigation strategy for this risk would\ninclude:\n\u2022 Energy-efficient hardware and shared infrastructure\nbased on renewable energy as well as research on reduc-\ning the cost of training and maintenance (i.e., efficient\nalgorithms, representation, and storage)\n\u2022 Collection, annotation, storage, and processing of data\nin a regulatory compliant and ethical way\n\u2022 Transparency and explanation techniques to identify\nand mitigate biases and prevent unfairness\n\u2022 Governance frameworks that include policies, proce-\ndures, and controls to ensure the above points and the\nappropriate use in education\nCost to verify information and maintain integrity.\nIt is\nimportant to verify the information provided by the model by\nconsulting external authoritative sources to ensure accuracy\nand integrity. Additionally, there may be financial costs asso-\nciated with maintaining and updating the model to ensure it is\nproviding accurate up-to-date information.\nA responsible mitigation strategy for this risk would con-\nsider the following key aspects:\n\u2022 Regularly updates of the model with new and accurate\ninformation to ensure it is providing up-to-date and\naccurate information\n\u2022 Use of multiple authoritative sources to verify the in-\nformation provided by the model to ensure correctness\nand integrity\n\u2022 Use of the model in conjunction with human expertise,\ne.g., teachers or subject matter experts, who review and\nvalidate the information provided by the model\n\u2022 Development of protocol and standards for"
        }
      ],
      "severity": "High",
      "actions": [
        "Investigate the relationship between the financial costs of LLMs and their environmental impact.",
        "Explore how energy-efficient LLM solutions could mitigate both financial and environmental burdens for educational institutions."
      ]
    },
    {
      "id": "r0005",
      "topic": "What is wrong with the world?",
      "claim_id": "c0003",
      "claim_text": "Verifying information provided by LLMs through multiple authoritative sources and human expertise is essential to ensure correctness and integrity. LLMs should be used in conjunction with human expertise, such as teachers or subject matter experts, who can review and validate the generated information. Adaptive learning technologies can personalize LLM outputs to individual student needs, considering factors like learning style, prior knowledge, and performance. Clear protocols and standards for fact-checking and corroborating information from LLMs are necessary for responsible use in educational settings.",
      "summary": "The claim emphasizes the need for human oversight and verification of LLM outputs, but the evidence primarily focuses on the benefits and potential uses of LLMs in education without detailing the verification process.",
      "detail": "The claim (c0003) strongly advocates for verifying LLM-generated information through authoritative sources and human expertise, and using LLMs as a supplement rather than a replacement for human instruction. However, the provided evidence snippets (E1, E2, E3, E4, E5) predominantly highlight the positive aspects and potential applications of LLMs in education, such as assisting teachers with professional development, content generation, and semi-automating grading. While E3 and E5 touch upon the risk of over-reliance and the need for LLMs to be complementary, they do not elaborate on the specific mechanisms or protocols for verification that the claim deems essential. The evidence does not offer concrete examples or strategies for how teachers or experts would conduct this verification, nor does it detail the 'clear protocols and standards' mentioned in the claim.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 3,
          "char_start": 3872,
          "char_end": 6237,
          "quote": "is helpful for further deep dive and understanding of the content in question. For professional development, large language models can also assist teachers by providing them with resources, summaries, and explanations of new teaching methodologies, technologies, and materials. This can help teachers stay up-to- date...",
          "chunk_id": "1-ChatGPT_for_Good:p0003:c0002",
          "chunk_text": "is helpful for further deep dive and understanding of the\ncontent in question.\nFor professional development, large language models\ncan also assist teachers by providing them with resources,\nsummaries, and explanations of new teaching methodologies,\ntechnologies, and materials. This can help teachers stay up-to-\ndate with the latest developments and techniques in education,\nand contribute to the effectiveness of their teaching. They can\nbe used to improve the clarity of the teaching materials, locate\ninformation or resources that professionals may be in need for\nas they learn on the job, as well as used for on-the-job training\nmodules that require presentation and communication skills.\nFor assessment and evaluation, teachers can use large\nlanguage models to semi-automate the grading of student work\nby highlighting potential strengths and weakness of the work\nin question, e.g., essays, research papers, and other writing\nassignments. This can save teachers a significant amount of\ntime for tasks related to individualized feedback to students.\nFurthermore, large language models can also be used to check\nfor plagiarism, which can help to prevent cheating. Hence,\nlarge language models can help teachers to identify areas\nwhere students are struggling, which adds to a more accurate\nassessments of student learning development and challenges.\nTargeted instruction provided by the models can be used to\nhelp students excel and to provide opportunities for further\ndevelopment.\nThe acquaintance of students with AI challenges related\nto the potential bias in the output, the need for continuous hu-\nman oversight, and the potential for misuse of large language\nmodels are not unique to education. In fact, these challenges\nare inherent to transformative digital technologies. Thus, we\nbelieve that, if handled sensibly by the teacher, these chal-\nlenges can be insightful in learning and education scenarios to\nacquaint students early on with potential societal biases, and\nrisks of AI application.\nIn conclusion, large language models have the potential\nto revolutionize teaching from a teacher\u2019s perspective by pro-\nviding teachers with a wide range of tools and resources that\ncan assist with lesson planning, personalized content creation,\ndifferentiation and personalized instruction, assessment, and\nprofessional development. Overall, large language"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 5,
          "char_start": 3704,
          "char_end": 5972,
          "quote": "teachers attitudes towards chatbots in education were reported in [34]: perceiving the AI chatbot as easy-to- use and useful leads to greater acceptance of the chatbot. As for the chatbots\u2019 features, formal language by a chatbot leads to a higher intention of using it. As it seems that teachers\u2019 perspectives on the ...",
          "chunk_id": "1-ChatGPT_for_Good:p0005:c0002",
          "chunk_text": "teachers attitudes towards chatbots in education\nwere reported in [34]: perceiving the AI chatbot as easy-to-\nuse and useful leads to greater acceptance of the chatbot. As\nfor the chatbots\u2019 features, formal language by a chatbot leads\nto a higher intention of using it.\nAs it seems that teachers\u2019 perspectives on the general use\nof AI in education have a lot in common with the mentioned at-\ntitude towards chatbots in particular, a responsible integration\nof AI into education by involving the expertise of different\ncommunities is crucial [35].\nRecent works addressing the use of large language models\nfrom the teacher\u2019s perspective have focused on the automated\nassessment of student answers, adaptive feedback, and the\ngeneration of teaching content.\nFor example, a recent work by Moore et al. [36] employed\na fine-tuned GPT-3 model to evaluate student-generated an-\nswers in a learning environment for chemistry education [36].\nThe authors argue that large language models might (espe-\ncially when fine-tuned to the specific domain) be a powerful\ntool to assist teachers in the quality and pedagogical evalua-\ntion of student answers [36]. In addition, the following studies\nexamined NLP-based models for generating automatic adap-\ntive feedback: Zhu et al. [37] examined an AI-based feedback\nsystem incorporating automated scoring technologies in the\ncontext of a high school climate activity task. The results show\nthat the feedback helped students revise their scientific argu-\nments. Sailer et al. [38] used NLP-based adaptive feedback\nin the context of diagnosing students\u2019 learning difficulties in\nteacher education. In their experimental study, they found that\npre-service teachers who received adaptive feedback were\nbetter able to justify their diagnoses than prospective teachers\nwho received static feedback. Bernius et al. [39] used NLP-\nbased models to generate feedback for textual student answers\nin large courses, where grading effort could be reduced by\nup to 85% with a high precision and an improved quality\nperceived by the students.\nLarge language models can not only support the assess-\nment of student\u2019s solutions but also assist in the automatic\ngeneration of exercises. Using few-shot learning, [40] showed\nthat the OpenAI Codex model is"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 10,
          "char_start": 3836,
          "char_end": 5925,
          "quote": "large language models into education must therefore meet stringent privacy, security, and - for sustainable scal- ing - environmental, regulatory and ethical requirements, and must be done in conjunction with ongoing human monitoring, guidance, and critical thinking. While this position paper reflects the optimism o...",
          "chunk_id": "1-ChatGPT_for_Good:p0010:c0002",
          "chunk_text": "large language models into education must therefore\nmeet stringent privacy, security, and - for sustainable scal-\ning - environmental, regulatory and ethical requirements, and\nmust be done in conjunction with ongoing human monitoring,\nguidance, and critical thinking.\nWhile this position paper reflects the optimism of the au-\nthors about the opportunities of large language models as a\ntransformative technology in education, it also underscores\nthe need for further research to explore best practices for inte-\ngrating large language models into education and to mitigate\nthe risks identified.\nWe believe that despite many difficulties and challenges,\nthe discussed risks are manageable and should be addressed to\nprovide trustworthy and fair access to large language models\nfor education. Towards this goal, the mitigation strategies\nproposed in this position paper could serve as a starting point.\nReferences\n[1] Luciano Floridi and Massimo Chiriatti. GPT-3: Its nature,\nscope, limits, and consequences. Minds and Machines,\n30(4):681\u2013694, 2020.\n[2] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. BERT: Pre-training of Deep Bidirec-\ntional Transformers for Language Understanding. arXiv\npreprint arXiv:1810.04805, 2018.\n[3] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Met-\nzler. Efficient transformers: A survey. ACM Computing\nSurveys, 55(6):1\u201328, 2022.\n[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser,\nand Illia Polosukhin. Attention is all you need. Advances\nin neural information processing systems, 30, 2017.\n[5] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben\nVeyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre,\nIlana Heinz, and Dan Roth. Recent advances in natural\nlanguage processing via large pre-trained language mod-\nels: A survey. arXiv preprint arXiv:2111.01243, 2021.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-\nbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\net al. Language models are few-shot learners. Advances"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 0,
          "char_end": 2297,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13 \u2022 Professional training and resources to educators on how to recognize and address potential biases and other fail- ures in the model\u2019s output \u2022 Continuous updates of the model with diverse, unbiased data, and supervision...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13\n\u2022 Professional training and resources to educators on how\nto recognize and address potential biases and other fail-\nures in the model\u2019s output\n\u2022 Continuous updates of the model with diverse, unbiased\ndata, and supervision of human experts to review the\nresults\nLearners may rely too heavily on the model.\nThe effort-\nlessly generated information could negatively impact their\ncritical thinking and problem-solving skills. This is because\nthe model simplifies the acquisition of answers or informa-\ntion, which can amplify laziness and counteract the learners\u2019\ninterest to conduct their own investigations and come to their\nown conclusions or solutions.\nTo encounter this risk, it is important to be aware of the\nlimitations of large language models and use them only as\na tool to support and enhance learning [55], rather than as\na replacement for human authorities and other authoritative\nsources. Thus a responsible mitigation strategy would focus\non the following key aspects:\n\u2022 Raising awareness of the limitations and unexpected\nbrittleness of large language models and AI systems in\ngeneral (i.e., experimenting with the model to build an\nown understanding of the workings and limitations)\n\u2022 Using language models to generate hypotheses and ex-\nplore different perspectives, rather than just to generate\nanswers\n\u2022 Strategies to use other educational resources (e.g., books,\narticles) and other authoritative sources to evaluate and\ncorroborate the factual correctness of the information\nprovided by the model (i.e., encouraging learners to\nquestion the generated content)\n\u2022 Incorporating critical thinking and problem-solving ac-\ntivities into the curriculum, to help students develop\nthese skills\n\u2022 Incorporating human expertise and teachers to review,\nvalidate and explain the information provided by the\nmodel\nIt is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand"
        }
      ],
      "severity": "High",
      "actions": [
        "Investigate evidence that details specific methods or protocols for verifying LLM outputs in educational settings.",
        "Seek evidence that discusses the challenges or limitations of human expertise in verifying LLM-generated content.",
        "Explore evidence that quantifies the effectiveness of LLM verification strategies."
      ]
    },
    {
      "id": "r0007",
      "topic": "What is wrong with the world?",
      "claim_id": "c0004",
      "claim_text": "LLMs can assist teachers by providing resources, summaries, and explanations of new teaching methodologies and technologies, helping them stay current. These models can be adapted to specific learner needs, including those with disabilities, and can assist in developing domain-specific language skills for professional training. LLMs can aid in the development of crucial skills such as programming, report writing, project management, decision making, and problem-solving. The adaptability of LLMs allows them to be fine-tuned on domain-specific corpora to generate relevant language and assist learners in specialized fields.",
      "summary": "The claim overstates LLMs' ability to replace human instruction and develop critical thinking skills.",
      "detail": "While the claim suggests LLMs can aid in developing crucial skills like problem-solving and decision-making, evidence E3 explicitly states that LLMs cannot replace the creativity, critical thinking, and problem-solving skills developed through human instruction. It emphasizes that LLMs should be used as a supplement, not a replacement, and warns against teachers becoming too reliant on them. Evidence E4 further supports this by highlighting the need to understand LLMs' limitations and use them to supplement learning processes, rather than as a sole source of skill development.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 3847,
          "char_end": 5202,
          "quote": "in their teaching [56]. This particularly applies to the use and integration of large language models into teaching practice. Educational theory has long since suggested ways of integrating novel tools into educational practice (e.g., [57]). As with any other technological innovation, integrating large language mode...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0002",
          "chunk_text": "in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to effectively use\nthem to supplement or enhance specific learning processes.\nThere are several ways to address these challenges and\nencounter this risk:\n\u2022 Research on the challenges of large language models in\neducation by investigating existing educational models\nof technology integration, students\u2019 learning processes\nand transfer them to the context of large language mod-\nels, as well as developing a new educational theory\nspecifically for the context of large language models\n\u2022 Assessing the needs of the educators and students and\nprovide case-based guidance (e.g., for the secure ethical\nuse of large language models in education scenarios)\n\u2022 Demand-oriented Training and professional develop-\nment opportunities for educators and institutions to\nlearn about the capabilities and potential uses of large\nlanguage models in education, as well as providing\nbest practices for integrating them into their teaching\nmethods"
        }
      ],
      "severity": "High",
      "actions": [
        "Clarify that LLMs are assistive tools and cannot fully replace human educators in fostering critical thinking and creativity.",
        "Emphasize the importance of human oversight and the development of these skills through traditional pedagogical methods alongside LLM integration."
      ]
    },
    {
      "id": "r0002",
      "topic": "What is wrong with the world?",
      "claim_id": "c0001",
      "claim_text": "LLMs can amplify existing biases present in their training data, leading to unfair or discriminatory outputs that negatively impact teaching and learning processes. The ability of LLMs to generate human-like text raises concerns about academic integrity, as evidenced by issues like plagiarism in the age of generative AI. Educational institutions must proactively address these risks by educating students about the potential societal biases and ethical considerations associated with AI applications. The integration of LLMs into education requires careful consideration of their limitations and the development of strategies to mitigate risks, such as bias and unfairness.",
      "summary": "The claim that LLMs can negatively impact critical thinking and problem-solving skills is supported, but the extent and mitigation strategies require further detail.",
      "detail": "Evidence E3 directly supports the claim that learners may rely too heavily on LLMs, leading to a negative impact on critical thinking and problem-solving skills due to the effortless acquisition of information. However, the claim also mentions the need for educational institutions to proactively address these risks. While E3 suggests awareness and E4 suggests using LLMs as a supplement, the practical implementation and effectiveness of these mitigation strategies in truly counteracting the potential negative impact on cognitive skills remain an unanswered question.",
      "evidence": [
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 0,
          "char_end": 2297,
          "quote": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13 \u2022 Professional training and resources to educators on how to recognize and address potential biases and other fail- ures in the model\u2019s output \u2022 Continuous updates of the model with diverse, unbiased data, and supervision...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0000",
          "chunk_text": "ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education \u2014 7/13\n\u2022 Professional training and resources to educators on how\nto recognize and address potential biases and other fail-\nures in the model\u2019s output\n\u2022 Continuous updates of the model with diverse, unbiased\ndata, and supervision of human experts to review the\nresults\nLearners may rely too heavily on the model.\nThe effort-\nlessly generated information could negatively impact their\ncritical thinking and problem-solving skills. This is because\nthe model simplifies the acquisition of answers or informa-\ntion, which can amplify laziness and counteract the learners\u2019\ninterest to conduct their own investigations and come to their\nown conclusions or solutions.\nTo encounter this risk, it is important to be aware of the\nlimitations of large language models and use them only as\na tool to support and enhance learning [55], rather than as\na replacement for human authorities and other authoritative\nsources. Thus a responsible mitigation strategy would focus\non the following key aspects:\n\u2022 Raising awareness of the limitations and unexpected\nbrittleness of large language models and AI systems in\ngeneral (i.e., experimenting with the model to build an\nown understanding of the workings and limitations)\n\u2022 Using language models to generate hypotheses and ex-\nplore different perspectives, rather than just to generate\nanswers\n\u2022 Strategies to use other educational resources (e.g., books,\narticles) and other authoritative sources to evaluate and\ncorroborate the factual correctness of the information\nprovided by the model (i.e., encouraging learners to\nquestion the generated content)\n\u2022 Incorporating critical thinking and problem-solving ac-\ntivities into the curriculum, to help students develop\nthese skills\n\u2022 Incorporating human expertise and teachers to review,\nvalidate and explain the information provided by the\nmodel\nIt is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand"
        },
        {
          "source_id": "1-ChatGPT_for_Good",
          "page": 7,
          "char_start": 1918,
          "char_end": 4277,
          "quote": "is important to note that the use of large language models should be integrated into the curriculum in a way that com- plements and enhances the learning experience, rather than replacing it. Teachers may become too reliant on the models. Using large language models can provide accurate and relevant infor- mation, b...",
          "chunk_id": "1-ChatGPT_for_Good:p0007:c0001",
          "chunk_text": "is important to note that the use of large language models\nshould be integrated into the curriculum in a way that com-\nplements and enhances the learning experience, rather than\nreplacing it.\nTeachers may become too reliant on the models.\nUsing\nlarge language models can provide accurate and relevant infor-\nmation, but they cannot replace the creativity, critical thinking,\nand problem-solving skills that are developed through human\ninstruction. It is therefore important for teachers to use these\nmodels as a supplement to their instruction, rather than a\nreplacement. Thus, crucial aspects to mitigate the risk of\nbecoming too reliant on large language models are:\n\u2022 The use of language models only as as a complementary\nsupplement to the generation of instructions\n\u2022 Ongoing training and professional development for\nteachers, enabling them to stay up-to-date on the best-\npractise use of language models in the classroom to\nelicit and promote creativity and critical thinking\n\u2022 Critical thinking and problem-solving activities through\nthe assistance of digital technologies as an integral part\nof the curriculum to ensure that students are developing\nthese skills\n\u2022 Engagement of students in creative and independent\nprojects that allow them to develop their own ideas and\nsolutions\n\u2022 Monitoring and evaluating the use of language models\nin the classroom to ensure that they are being used ef-\nfectively and not negatively impacting student learning\n\u2022 Incentives for teachers and schools to develop (inclu-\nsive, collaborative, and personalized) teaching strate-\ngies based on large language models and engage stu-\ndents in problem-solving processes such as retrieving\nand evaluating course/assignment-relevant information\nusing the models and other sources\nLack of understanding and expertise.\nMany educators and\neducational institutions may not have the knowledge or exper-\ntise to effectively integrate new technologies in their teaching\n[56]. This particularly applies to the use and integration of\nlarge language models into teaching practice. Educational\ntheory has long since suggested ways of integrating novel\ntools into educational practice (e.g., [57]). As with any other\ntechnological innovation, integrating large language models\ninto effective teaching practice requires understanding their\ncapabilities and limitations, as well as how to"
        }
      ],
      "severity": "Medium",
      "actions": [
        "Examine pedagogical approaches that actively encourage critical thinking alongside LLM use.",
        "Seek studies that measure the actual impact of LLM reliance on student critical thinking and problem-solving abilities.",
        "Identify best practices for training educators to effectively integrate LLMs without diminishing student cognitive development."
      ]
    }
  ]
}